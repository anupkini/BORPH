From 6ce29f4e4032f6e5e1e8b965e481521631b243e6 Mon Sep 17 00:00:00 2001
From: Brandon Hamilton <brandon.hamilton@gmail.com>
Date: Thu, 20 Oct 2011 00:32:48 +0200
Subject: [PATCH] Applied BORPH patch

---
 arch/x86/Kconfig             |   31 +
 fs/Makefile                  |    1 +
 fs/binfmt_bof.c              |  132 ++
 fs/proc/Makefile             |    1 +
 fs/proc/base.c               |   59 +-
 fs/proc/internal.h           |   35 +
 fs/proc/proc_borph.c         |  765 +++++++++++
 include/linux/bof.h          |   78 ++
 include/linux/borph.h        |  147 +++
 include/linux/hdebug.h       |   37 +
 include/linux/kselectmap.h   |  211 +++
 include/linux/proc_fs.h      |    1 +
 include/linux/sched.h        |    7 +
 init/main.c                  |    8 +
 kernel/Makefile              |   10 +
 kernel/bkexecd.c             |  373 ++++++
 kernel/borph.c               |  120 ++
 kernel/exit.c                |    5 +-
 kernel/hwr/Makefile          |   10 +
 kernel/hwr/common.c          |  259 ++++
 kernel/hwr/hwrtype_b2fpga.c  |  402 ++++++
 kernel/hwr/hwrtype_netfpga.c | 2955 ++++++++++++++++++++++++++++++++++++++++++
 kernel/hwr/hwrtype_rhino.c   |  677 ++++++++++
 kernel/hwr/hwrtype_roach.c   |  560 ++++++++
 kernel/hwr/nf2.h             |  458 +++++++
 kernel/hwr/nf2kernel.h       |  279 ++++
 kernel/mkd.c                 | 1392 ++++++++++++++++++++
 27 files changed, 8973 insertions(+), 40 deletions(-)
 create mode 100644 fs/binfmt_bof.c
 create mode 100644 fs/proc/proc_borph.c
 create mode 100644 include/linux/bof.h
 create mode 100644 include/linux/borph.h
 create mode 100644 include/linux/hdebug.h
 create mode 100644 include/linux/kselectmap.h
 create mode 100644 kernel/bkexecd.c
 create mode 100644 kernel/borph.c
 create mode 100644 kernel/hwr/Makefile
 create mode 100644 kernel/hwr/common.c
 create mode 100644 kernel/hwr/hwrtype_b2fpga.c
 create mode 100644 kernel/hwr/hwrtype_netfpga.c
 create mode 100644 kernel/hwr/hwrtype_rhino.c
 create mode 100644 kernel/hwr/hwrtype_roach.c
 create mode 100644 kernel/hwr/nf2.h
 create mode 100644 kernel/hwr/nf2kernel.h
 create mode 100644 kernel/mkd.c

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 6a47bb2..15d5d2d 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -250,6 +250,37 @@ config ARCH_CPU_PROBE_RELEASE
 	def_bool y
 	depends on HOTPLUG_CPU
 
+menu "BORPH setup"
+
+config BORPH
+	bool "Configure BORPH"
+choice
+	prompt "BORPH Hardware Platform"
+	depends on BORPH
+	default NETFPGA
+
+config NETFPGA
+	bool "NETFPGA"
+
+endchoice
+
+config HWR_NETFPGA
+	depends on NETFPGA
+	tristate "NetFPGA hardware region support"
+
+config BKEXECD
+	depends on BORPH
+	tristate "HW exec daemon (use module w/ extreme care)"
+
+config MKD
+	depends on BORPH
+	tristate "mk daemon (use module w/ extreme care)"
+
+config BINFMT_BOF
+	depends on BORPH
+	tristate "BOF file format support"
+endmenu
+
 source "init/Kconfig"
 source "kernel/Kconfig.freezer"
 
diff --git a/fs/Makefile b/fs/Makefile
index afc1096..bf02065 100644
--- a/fs/Makefile
+++ b/fs/Makefile
@@ -41,6 +41,7 @@ obj-$(CONFIG_COMPAT_BINFMT_ELF)	+= compat_binfmt_elf.o
 obj-$(CONFIG_BINFMT_ELF_FDPIC)	+= binfmt_elf_fdpic.o
 obj-$(CONFIG_BINFMT_SOM)	+= binfmt_som.o
 obj-$(CONFIG_BINFMT_FLAT)	+= binfmt_flat.o
+obj-$(CONFIG_BINFMT_BOF)	+= binfmt_bof.o
 
 obj-$(CONFIG_FS_MBCACHE)	+= mbcache.o
 obj-$(CONFIG_FS_POSIX_ACL)	+= posix_acl.o xattr_acl.o
diff --git a/fs/binfmt_bof.c b/fs/binfmt_bof.c
new file mode 100644
index 0000000..870f38a
--- /dev/null
+++ b/fs/binfmt_bof.c
@@ -0,0 +1,132 @@
+/*********************************************************************
+ * fs/binfmt_bof.c
+ * Author: Hayden Kwok-Hay So, Brandon Hamilton
+ *
+ * Description:
+ *   Thie file describes a new binary format to be loaded by a Linux
+ * kernel, the BORPH Object File (BOF) format.  A file in BOF format
+ * encapsulates both an ELF image and a configuration information for
+ * one or more FPGA.
+ *   The actual FPGA configuration is handled by bkexecd
+ *
+ * Ported to kernel 2.6: 2008/11/03
+ *********************************************************************/
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/binfmts.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/elf.h>
+#include <linux/fs.h>
+
+#include <linux/bof.h>
+#include <linux/borph.h>
+#define HDEBUG
+#define HDBG_NAME "binfmt_bof"
+#define HDBG_LVL  9
+#include <linux/hdebug.h>
+
+extern struct bkexecd_info bked_info;
+
+static inline int bof_has_fpga(struct bofhdr* bhdr) {
+	return (bhdr->b_numchip > 0);
+}
+
+static int load_bof_binary(struct linux_binprm *bprm, struct  pt_regs *regs)
+{
+	int retval;
+	struct bofhdr bhdr;
+	struct bofhdr * bhdrp;
+	char current_b_machine;
+	char current_elfmachine;
+
+	bhdr = *((struct bofhdr *) bprm->buf);
+	if (bhdr.ident[0] != 0x19 || bhdr.ident[1] != 'B' ||
+	    bhdr.ident[2] != 'O' || bhdr.ident[3] != 'F') {
+		return -ENOEXEC;
+	}
+
+	// check machine
+	current_b_machine  = BM_RHINO;
+	current_elfmachine = EM_ARM;
+
+	if ( bhdr.b_machine != current_b_machine || bhdr.b_elfmachine != current_elfmachine ) {
+		PDEBUG(9, "Wrong b_machine (expecting 0x%x) or b_elfmachine (expecting 0x%x)!\n", current_b_machine, current_elfmachine);
+		return -ENOEXEC;
+	}
+
+	// only handle version 6
+	if (bhdr.b_version != 6) {
+		return -ENOEXEC;
+	}
+
+	// bof file is valid
+	if (bof_has_fpga(&bhdr)) {    
+		struct execq_item* execq_item;
+		unsigned long flags;
+		// HHH should change to slab
+
+		execq_item = kmalloc(sizeof(struct execq_item), GFP_KERNEL);
+		execq_item->bprm = bprm;
+		execq_item->task = current;
+    
+		spin_lock_irqsave(&bked_info.execq_lock, flags);
+		list_add_tail(&(execq_item->list), &bked_info.execq_list);
+		spin_unlock_irqrestore(&bked_info.execq_lock, flags);
+		
+		//wake_up_sync(&bked_info.more_exec);
+		wake_up(&bked_info.more_exec);
+
+		/* Sleep till our fpga partner is done.
+		 * It is less efficient but save me trouble for synching 
+		 * the 2 sides */
+		set_current_state(TASK_INTERRUPTIBLE);
+		schedule();
+	}
+
+	/* hw should have been loaded by now...  I spent all my time
+	 * to setup bkexecd to do the hw loading but now I realize
+	 * there's no way to notify binfmt if it fails... bummer... so
+	 * right now I'll just use a byte in bofhdr (in brpm->buf) to
+	 * store the return value...
+	 * To fix it?  Note that for "simplicity" sake, hw loading is
+	 * synchronous to sw, thus I could have eliminated bkexecd all
+	 * together as a thread.  Instead, just all the functions
+	 * directly here.
+	 */
+	bhdrp = (struct bofhdr*) (bprm->buf);
+	if (bhdrp->load_err) {
+		PDEBUG(5, "hw load error\n");
+		return bhdrp->load_err;
+	}
+
+	// make it looks like an ELF and start over
+	retval = kernel_read(bprm->file, bhdr.b_elfoff, bprm->buf, BINPRM_BUF_SIZE);
+	if (retval < 0) {
+		PDEBUG(5, "kernel_read failed\n");
+		return -ENOEXEC;
+	}
+
+	return search_binary_handler(bprm,regs);
+}
+
+static struct linux_binfmt bof_format = {
+	.module		= THIS_MODULE,
+	.load_binary	= load_bof_binary,
+};
+
+static int __init init_bof_binfmt (void) {
+	PDEBUG(0, "binfmt_bof v4 loaded\n");
+	return register_binfmt(&bof_format);
+}
+
+static void __exit exit_bof_binfmt(void) {
+	PDEBUG(0, "binfmt_bof v4 unloaded\n");
+	unregister_binfmt(&bof_format);
+}
+
+
+core_initcall(init_bof_binfmt);
+module_exit(exit_bof_binfmt);
+MODULE_AUTHOR("Hayden Kwok-Hay So");
+MODULE_LICENSE("GPL");
diff --git a/fs/proc/Makefile b/fs/proc/Makefile
index c1c7293..e19c660 100644
--- a/fs/proc/Makefile
+++ b/fs/proc/Makefile
@@ -28,3 +28,4 @@ proc-$(CONFIG_PROC_VMCORE)	+= vmcore.o
 proc-$(CONFIG_PROC_DEVICETREE)	+= proc_devtree.o
 proc-$(CONFIG_PRINTK)	+= kmsg.o
 proc-$(CONFIG_PROC_PAGE_MONITOR)	+= page.o
+proc-$(CONFIG_BORPH)	+= proc_borph.o
diff --git a/fs/proc/base.c b/fs/proc/base.c
index 5eb0206..7246622 100644
--- a/fs/proc/base.c
+++ b/fs/proc/base.c
@@ -81,6 +81,14 @@
 #include <linux/oom.h>
 #include <linux/elf.h>
 #include <linux/pid_namespace.h>
+#ifdef CONFIG_BORPH
+  #define HDEBUG
+  // #undef HDEBUG
+  #define HDBG_LVL mkd_info->dbg_lvl
+  #define HDBG_NAME "proc"
+  #include <linux/hdebug.h>
+  #include <linux/borph.h>
+#endif
 #include <linux/fs_struct.h>
 #include <linux/slab.h>
 #ifdef CONFIG_HARDWALL
@@ -98,41 +106,6 @@
  *	in /proc for a task before it execs a suid executable.
  */
 
-struct pid_entry {
-	char *name;
-	int len;
-	mode_t mode;
-	const struct inode_operations *iop;
-	const struct file_operations *fop;
-	union proc_op op;
-};
-
-#define NOD(NAME, MODE, IOP, FOP, OP) {			\
-	.name = (NAME),					\
-	.len  = sizeof(NAME) - 1,			\
-	.mode = MODE,					\
-	.iop  = IOP,					\
-	.fop  = FOP,					\
-	.op   = OP,					\
-}
-
-#define DIR(NAME, MODE, iops, fops)	\
-	NOD(NAME, (S_IFDIR|(MODE)), &iops, &fops, {} )
-#define LNK(NAME, get_link)					\
-	NOD(NAME, (S_IFLNK|S_IRWXUGO),				\
-		&proc_pid_link_inode_operations, NULL,		\
-		{ .proc_get_link = get_link } )
-#define REG(NAME, MODE, fops)				\
-	NOD(NAME, (S_IFREG|(MODE)), NULL, &fops, {})
-#define INF(NAME, MODE, read)				\
-	NOD(NAME, (S_IFREG|(MODE)), 			\
-		NULL, &proc_info_file_operations,	\
-		{ .proc_read = read } )
-#define ONE(NAME, MODE, show)				\
-	NOD(NAME, (S_IFREG|(MODE)), 			\
-		NULL, &proc_single_file_operations,	\
-		{ .proc_show = show } )
-
 /*
  * Count the number of hardlinks for the pid_entry table, excluding the .
  * and .. links.
@@ -747,7 +720,7 @@ static const struct file_operations proc_mountstats_operations = {
 
 #define PROC_BLOCK_SIZE	(3*1024)		/* 4K page size but our output routines use some slack for overruns */
 
-static ssize_t proc_info_read(struct file * file, char __user * buf,
+ssize_t proc_info_read(struct file * file, char __user * buf,
 			  size_t count, loff_t *ppos)
 {
 	struct inode * inode = file->f_path.dentry->d_inode;
@@ -777,7 +750,7 @@ out_no_task:
 	return length;
 }
 
-static const struct file_operations proc_info_file_operations = {
+const struct file_operations proc_info_file_operations = {
 	.read		= proc_info_read,
 	.llseek		= generic_file_llseek,
 };
@@ -2276,7 +2249,7 @@ out:
 	return error;
 }
 
-static struct dentry *proc_pident_lookup(struct inode *dir, 
+struct dentry *proc_pident_lookup(struct inode *dir, 
 					 struct dentry *dentry,
 					 const struct pid_entry *ents,
 					 unsigned int nents)
@@ -2318,7 +2291,7 @@ static int proc_pident_fill_cache(struct file *filp, void *dirent,
 				proc_pident_instantiate, task, p);
 }
 
-static int proc_pident_readdir(struct file *filp,
+int proc_pident_readdir(struct file *filp,
 		void *dirent, filldir_t filldir,
 		const struct pid_entry *ents, unsigned int nents)
 {
@@ -2782,6 +2755,11 @@ static int proc_pid_personality(struct seq_file *m, struct pid_namespace *ns,
 static const struct file_operations proc_task_operations;
 static const struct inode_operations proc_task_inode_operations;
 
+#ifdef CONFIG_BORPH
+extern const struct inode_operations proc_bphhw_inode_operations;
+extern const struct file_operations proc_bphhw_operations;
+#endif
+
 static const struct pid_entry tgid_base_stuff[] = {
 	DIR("task",       S_IRUGO|S_IXUGO, proc_task_inode_operations, proc_task_operations),
 	DIR("fd",         S_IRUSR|S_IXUSR, proc_fd_inode_operations, proc_fd_operations),
@@ -2861,6 +2839,9 @@ static const struct pid_entry tgid_base_stuff[] = {
 #ifdef CONFIG_TASK_IO_ACCOUNTING
 	INF("io",	S_IRUSR, proc_tgid_io_accounting),
 #endif
+#ifdef CONFIG_BORPH
+	DIR("hw", S_IRUGO|S_IXUGO|S_IWUSR, proc_bphhw_inode_operations, proc_bphhw_operations),
+#endif
 #ifdef CONFIG_HARDWALL
 	INF("hardwall",   S_IRUGO, proc_pid_hardwall),
 #endif
diff --git a/fs/proc/internal.h b/fs/proc/internal.h
index 7838e5c..c085845 100644
--- a/fs/proc/internal.h
+++ b/fs/proc/internal.h
@@ -91,6 +91,41 @@ struct dentry *proc_lookup_de(struct proc_dir_entry *de, struct inode *ino,
 int proc_readdir_de(struct proc_dir_entry *de, struct file *filp, void *dirent,
 		filldir_t filldir);
 
+struct pid_entry {
+	char *name;
+	int len;
+	mode_t mode;
+	const struct inode_operations *iop;
+	const struct file_operations *fop;
+	union proc_op op;
+};
+
+#define NOD(NAME, MODE, IOP, FOP, OP) {			\
+	.name = (NAME),					\
+	.len  = sizeof(NAME) - 1,			\
+	.mode = MODE,					\
+	.iop  = IOP,					\
+	.fop  = FOP,					\
+	.op   = OP,					\
+}
+
+#define DIR(NAME, MODE, iops, fops)	\
+	NOD(NAME, (S_IFDIR|(MODE)), &iops, &fops, {} )
+#define LNK(NAME, get_link)					\
+	NOD(NAME, (S_IFLNK|S_IRWXUGO),				\
+		&proc_pid_link_inode_operations, NULL,		\
+		{ .proc_get_link = get_link } )
+#define REG(NAME, MODE, fops)				\
+	NOD(NAME, (S_IFREG|(MODE)), NULL, &fops, {})
+#define INF(NAME, MODE, read)				\
+	NOD(NAME, (S_IFREG|(MODE)), 			\
+		NULL, &proc_info_file_operations,	\
+		{ .proc_read = read } )
+#define ONE(NAME, MODE, show)				\
+	NOD(NAME, (S_IFREG|(MODE)), 			\
+		NULL, &proc_single_file_operations,	\
+		{ .proc_show = show } )
+
 struct pde_opener {
 	struct inode *inode;
 	struct file *file;
diff --git a/fs/proc/proc_borph.c b/fs/proc/proc_borph.c
new file mode 100644
index 0000000..c2aacb1
--- /dev/null
+++ b/fs/proc/proc_borph.c
@@ -0,0 +1,765 @@
+/*
+ * linux/fs/proc/proc_borph.c
+ *
+ * Copyright (C) 2008 Hayden So
+ * Author: Hayden Kwok-Hay So, Brandon Hamilton
+ * Description:
+ *   proc ioreg functions
+ *
+ */
+#include <asm/uaccess.h>
+
+#include <linux/errno.h>
+#include <linux/time.h>
+#include <linux/proc_fs.h>
+#include <linux/stat.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/bitops.h>
+#include <linux/smp_lock.h>
+#include <linux/mount.h>
+#include <linux/nsproxy.h>
+#include <net/net_namespace.h>
+#include <linux/seq_file.h>
+
+#define HDEBUG
+#define HDBG_NAME "proc_borph"
+#ifdef CONFIG_MKD
+# define HDBG_LVL mkd_info->dbg_lvl
+#else
+# define HDBG_LVL 9
+#endif
+#include <linux/hdebug.h>
+#include <linux/borph.h>
+#include "internal.h"
+/* The following helpler functions were originally defined "static"
+ * within base.c.  I need to use them here so they are not 
+ * defined "static" anymore
+ */
+typedef struct dentry *instantiate_t(struct inode *, struct dentry *,
+               struct task_struct *, const void *);
+
+extern struct dentry *proc_pident_lookup(struct inode *dir, 
+                    struct dentry *dentry,
+                    const struct pid_entry *ents,
+                    unsigned int nents);
+extern int proc_pident_readdir(struct file *filp,
+                  void *dirent, filldir_t filldir,
+                  const struct pid_entry *ents, 
+                  unsigned int nents);
+extern ssize_t proc_info_read(struct file * file, char __user * buf,
+                 size_t count, loff_t *ppos);
+extern struct file_operations proc_info_file_operations;
+extern struct inode *proc_pid_make_inode(struct super_block * sb, struct task_struct *task);
+extern struct dentry_operations pid_dentry_operations;
+extern int pid_revalidate(struct dentry *dentry, struct nameidata *nd);
+extern int proc_fill_cache(struct file *filp, void *dirent, filldir_t filldir,
+              char *name, int len,
+              instantiate_t instantiate, struct task_struct *task, const void *ptr);
+// End extern
+
+/**** begin /proc/<pid>/hw/ioreg/ content ****/
+static inline ssize_t to_ascii(buf_t* buf, ssize_t length)
+{
+   u32 val;
+   char* cbuf = (char*) buf;
+   int j, m;
+   //PDEBUG(9, "to_ascii: buf[0] = %d, length=%d\n", buf[0], length);
+   /* I only convert 1 word at most */
+   if (length != 4) return -EINVAL;
+
+   /* by default, I like hex. In fact, it will only work for hex
+    * for now, because having a dec values give me variable
+    * length to return, and thus I cannot return to user if I
+    * see a *fpos being too big without reading the actual 
+    * hardware, which wasted time */
+   val = *((__u32*) buf);
+   j = 8;  // always 8 characters long
+   do {
+       m = (val & 0xF);
+       cbuf[--j] = ((m >= 10)?('A'-10):'0') + m;
+   } while (val >>= 4);
+   for (j = j-1; j >= 0; j--) {
+       cbuf[j] = '0';
+   }
+   cbuf[8] = '\n';
+   return 9;
+}
+
+static ssize_t ioreg_reg_read(struct file *filp, char __user *buf,
+                  size_t fcount, loff_t *fpos)
+{
+   int retval = 0;
+   int i;
+
+   struct dentry *dentry = filp->f_path.dentry;
+   struct inode *inode = dentry->d_inode;
+   struct borph_ioreg* reg = (struct borph_ioreg*) PROC_I(inode)->data;
+   struct hwr_operations *hwrops;
+   struct task_struct *task;
+   struct hwr_iobuf *iobuf;
+   struct borph_info *bi;
+   ssize_t regblen;
+
+   if (!reg)
+       goto out_no_task;
+
+// PDEBUG(5, "reading from ioreg name=%s, mode=0x%x loc=0x%x, len=%d, fcount=%d, *fpos=%llu\n", reg->name, reg->mode, reg->loc, reg->len, fcount, *fpos);
+
+   if (reg->mode & IORM_PIPE && fpos != &filp->f_pos) {
+       retval = -ESPIPE;
+       goto out_no_task;
+   }
+
+   task = get_proc_task(inode);
+   if (!task)
+       goto out_no_task;
+   bi = task->borph_info;
+   if (!bi)
+       goto out_no_hwrops;
+
+   if (bi->ioreg_mode == 0) { /* ascii hex */
+       regblen = reg->len << 1;
+   } else { /* raw */
+       regblen = reg->len;
+   }
+
+   if (*fpos + fcount > regblen) {
+       if (*fpos >= regblen) 
+           goto out_no_hwrops;
+       fcount = (regblen - *fpos);
+   }
+
+   /* for now, let me cap myself at 900 bytes */
+   if (fcount > (PAGE_SIZE - offsetof(struct hwr_iobuf, data))) {
+       fcount = PAGE_SIZE - offsetof(struct hwr_iobuf, data);
+   }
+
+   hwrops = get_hwrops(reg->hwraddr);
+   if (!hwrops)
+       goto out_no_hwrops;
+   if (!hwrops->get_iobuf || !hwrops->recv_iobuf || !hwrops->put_iobuf)
+       goto out;
+
+   /* Construct iobuf to get data */
+   iobuf = hwrops->get_iobuf();
+   if (!iobuf)
+       goto out;
+
+   iobuf->cmd = PP_CMD_READ;
+   iobuf->location = reg->loc;
+   iobuf->offset = *fpos;
+   // Only read the required number of bytes
+        //iobuf->size = reg->len;
+        iobuf->size = bi->ioreg_mode?fcount:fcount>>1;
+   retval = hwrops->recv_iobuf(iobuf);
+   if (retval < 0) {
+       goto out_put_iobuf;
+   }
+
+// PDEBUG(9, "Data received from FPGA (%d bytes)\n", retval);
+
+   // Print out data for debugging
+        // for (i = 0; i < retval; i++)
+   //  PDEBUG(9, "0x%x ", iobuf->data[i]);
+
+// PDEBUG(9, "\n");
+
+   if (bi->ioreg_mode == 0) { /* ascii mode required */
+//     PDEBUG(9, "Converting to ASCII\n");
+       retval = to_ascii(iobuf->data, retval);
+       if (retval < 0) {
+           goto out_put_iobuf;
+       }
+   }
+
+// PDEBUG(9, "Copying to user buffer\n");
+
+   /* Write the data from the iobuf into the file pointer */
+   copy_to_user(buf, iobuf->data, retval);
+
+   if (reg->mode & IORM_PIPE) {
+       *fpos = 0;
+   } else {
+       *fpos += retval;
+   }
+
+// PDEBUG(9, "ioreg reading completed\n");
+
+ out_put_iobuf:
+   hwrops->put_iobuf(iobuf);
+ out:
+   put_hwrops(reg->hwraddr);
+ out_no_hwrops:
+   put_task_struct(task);
+ out_no_task:
+   return retval;
+}
+
+/* convert_input: Convert the first *cnt* bytes from *buf* into its
+ *                numerical value
+ * Note: All invalid character from buf will be happily ignored 
+ * instead of generating error.  It is useful so that if a user input
+ * "123\n", it will return the value 123 and consumes the \n at the end
+ * gracefully.
+ */
+static int convert_input(char* buf, int cnt) {
+   int retval = -EINVAL;
+   char c;
+   int num = 0;
+   if (buf[0] == 'x') {  // hex input
+//     PDEBUG(9, "converting hexadecimal\n");
+       if (cnt < 2) goto out;
+       buf += 1;
+       while (cnt > 0) {
+           c = *buf;
+           if (c != '\n') {
+               num *= 16;
+               if (c >= 'a' && c <= 'f') {
+                   num += c - 'a';
+               } else if (c >= 'A' && c <= 'F') {
+                   num += c - 'A';
+               } else if (c >= '0' && c <= '9') {
+                   num += c - '0';
+               }
+           }
+           buf += 1;
+           cnt -= 1;
+       }
+   } else if (buf[0] == 'b') { // binary number input
+//     PDEBUG(9, "converting binary\n");
+       if (cnt < 2) goto out;
+       buf += 1;
+       while (cnt > 0) {
+           c = *buf;
+           if (c != '\n') {
+               num *= 2;
+               if (c >= '0' && c <= '1') {
+                   num += c - '0';
+               } else {
+                   goto out;
+               }
+           }
+           buf += 1;
+           cnt -= 1;
+       }
+   } else { // assume decimal number
+//     PDEBUG(9, "converting decimal\n");
+       while (cnt > 0) {
+           c = *buf;
+//         PDEBUG(9, "c = 0x%02X\n", c);
+           if (c >= '0' && c <='9')  {
+               num *= 10;
+               num += c - '0';
+           }
+           buf += 1;
+           cnt -= 1;
+       }
+   }
+   retval = num;
+ out:
+   return retval;
+}
+
+#define NUMTMPBUF 12
+static struct hwr_iobuf* ioreg_reg_cp_udata_ascii(struct borph_ioreg* reg,
+                         const char __user *ubuf,
+                         size_t fcount, loff_t *fpos, 
+                         hwr_getiobuf_t get_iobuf)
+{
+   int datacnt = fcount;
+   struct hwr_iobuf *retval = ERR_PTR(-EINVAL);
+   struct hwr_iobuf *iobuf;
+
+   /* at most 12 characters for 2^32 (plus base+newline)  */
+   char tmpbuf[NUMTMPBUF]; 
+   int num;
+
+   /* ascii mode is only for simple register with no seeking, so *fpos
+    * should really be 0 all the time (at least when I am lazy)*/
+   if (*fpos != 0) {
+       retval = ERR_PTR(-ESPIPE);
+       goto out;
+   }
+
+   if (datacnt > NUMTMPBUF) {
+       retval = ERR_PTR(-EINVAL);
+       goto out;
+   }
+
+   if (copy_from_user(tmpbuf, ubuf, datacnt)) {
+       retval = ERR_PTR(-EFAULT);
+       goto out;
+   }
+// PDEBUG(9, "converting num: tmpbuf=[%02X %02X %02X %02X %02X ... ]\n", tmpbuf[0],tmpbuf[1],tmpbuf[2],tmpbuf[3],tmpbuf[4]);
+   num = convert_input(tmpbuf, datacnt);
+// PDEBUG(5, "num returned as %d\n", num);
+   if (num < 0) {
+       retval = ERR_PTR(-EINVAL);
+       goto out;
+   }
+
+   /* Get I/O buffer from the specific hwr */
+   iobuf = get_iobuf();
+
+   // In ASCII mode, I don't want anything strange
+   if (!iobuf || iobuf->size < datacnt)
+       goto out;
+
+   if (!memcpy(iobuf->data, &num, sizeof(num))) {
+       retval = ERR_PTR(-EFAULT);
+       goto out;
+   }
+   iobuf->size = sizeof(num);
+   retval = iobuf;
+ out:
+   return retval;
+}
+
+/* ioreg_reg_cp_udata_raw:
+ *  Implements the actual writing process of an ioreg file when 
+ * ioreg_mode is set to 1
+ *  Relies on hwrops->get_iobuf as kernel buffer in which user
+ * data is copied.  Usually hwrops->get_iobuf will give a pointer
+ * into the middle of the entire buffer s.t. it can put header in
+ * the front and still be able to make it preperly aligned for better
+ * (e.g. DMA) transfer.
+ * return:
+ *   non-NULL : a hwr_iobuf filled with data+cnt to send
+ *   ERR_PTR : error
+ */
+static struct hwr_iobuf* ioreg_reg_cp_udata_raw(struct borph_ioreg* reg, 
+                       const char __user *ubuf,
+                       size_t fcount, loff_t *fpos, 
+                       hwr_getiobuf_t get_iobuf)
+{
+   int datacnt = fcount;
+   struct hwr_iobuf* retval = ERR_PTR(-EINVAL);
+   struct hwr_iobuf* iobuf;
+
+   int len_in_byte;
+ 
+   len_in_byte = reg->len;
+
+   /* non aligned access */
+/* if (*fpos % 4 || fcount % 4) {
+       PDEBUG(9, "raw_write: unaligned write\n");
+       return -EINVAL;
+   }
+*/
+   /* datacnt = min(len-*fpos, fcount) */
+   if (datacnt > (len_in_byte - *fpos)) {
+       datacnt = len_in_byte - *fpos;
+   }
+
+   /* cap fcount to 1 page */
+   /* I used to have 900 as a temp hack, now trying to reuse PAGE_SIZE
+    *  H,S. 1/30/08 
+    * This is needed so that we won't overflow kbuf (H.S. 7/25/08)
+    */
+   if (datacnt > PAGE_SIZE)
+       datacnt = PAGE_SIZE;
+
+   iobuf = get_iobuf();
+   if (!iobuf || !iobuf->size)
+       goto out;
+
+   if (iobuf->size < datacnt)
+       datacnt = iobuf->size;
+
+// PDEBUG(9, "copy %d bytes from user\n", datacnt);
+   if (copy_from_user(iobuf->data, ubuf, datacnt)) {
+       retval = ERR_PTR(-EFAULT);
+       goto out;
+   }
+   {
+       unsigned char* p = iobuf->data;
+//     PDEBUG(5, "ioreg_cp_valid_user_data: copied bytes[0-7]: %02X %02X %02X %02X %02X %02X %02X %02X\n",  p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7]);
+   }
+   iobuf->size = datacnt;
+
+   retval = iobuf;
+
+ out:
+   return retval;
+}
+
+static ssize_t ioreg_reg_write(struct file *filp, const char __user *buf,
+                  size_t fcount, loff_t *fpos)
+{
+   struct dentry *dentry = filp->f_path.dentry;
+   struct inode *inode = dentry->d_inode;
+   struct borph_ioreg* reg = (struct borph_ioreg*) PROC_I(inode)->data;
+   struct task_struct *task;
+   struct hwr_operations *hwrops;
+   struct borph_info *bi;
+   struct hwr_iobuf *iobuf;
+   int retval = -EINVAL;
+
+   if (!reg)
+       goto out_no_task;
+
+// PDEBUG(5, "writing to ioreg name=%s, mode=0x%x loc=0x%x, len=%d, fcount=%d, *fpos=%llu\n", reg->name, reg->mode, reg->loc, reg->len, fcount, *fpos);
+
+   if (reg->mode & IORM_PIPE && fpos != &filp->f_pos) {
+       retval = -ESPIPE;
+       goto out_no_task;
+   }
+   /* no appending */
+   if (*fpos >= reg->len) {
+       retval = fcount;
+       goto out_no_task;
+   }
+
+   task = get_proc_task(inode);
+   if (!task)
+       goto out_no_task;
+   bi = task->borph_info;
+   if (!bi)
+       goto out_no_hwrops;
+
+   hwrops = get_hwrops(reg->hwraddr);
+   if (!hwrops)
+       goto out_no_hwrops;
+   if (!hwrops->get_iobuf || !hwrops->send_iobuf || !hwrops->put_iobuf)
+       goto out;
+
+   if (bi->ioreg_mode == 1) {
+       iobuf = ioreg_reg_cp_udata_raw(reg, buf, fcount, fpos, 
+                       hwrops->get_iobuf);
+   } else {
+       iobuf = ioreg_reg_cp_udata_ascii(reg, buf, fcount, fpos,
+                        hwrops->get_iobuf);
+   }
+   if (IS_ERR(iobuf))
+       goto out;
+
+   /* Set the iobuf parameters */
+   iobuf->cmd = PP_CMD_WRITE;
+   iobuf->offset = *fpos;
+   iobuf->location = reg->loc;
+
+   retval = hwrops->send_iobuf(iobuf);
+   if (retval <= 0)
+       goto out_with_iobuf;
+
+   if (reg->mode & IORM_PIPE) {
+       *fpos = 0;
+   } else {
+       *fpos += retval;
+   }
+
+// PDEBUG(9, "ioreg writing completed\n");
+
+ out_with_iobuf:
+   hwrops->put_iobuf(iobuf);
+ out:
+   put_hwrops(reg->hwraddr);
+ out_no_hwrops:
+   put_task_struct(task);
+ out_no_task:
+   return retval;
+}
+
+static loff_t ioreg_reg_lseek(struct file *filp, loff_t off, int whence)
+{
+   struct dentry *dentry = filp->f_path.dentry;
+   struct inode *inode = dentry->d_inode;
+   struct borph_ioreg* reg;
+   loff_t newpos;
+
+   reg = (struct borph_ioreg*) PROC_I(inode)->data;
+   if (!reg)
+       return -EINVAL;
+   if (reg->mode & IORM_PIPE)
+       return -ESPIPE; /* unseekable */
+
+   switch(whence) {
+   case 0: /* SEEK_SET */
+       newpos = off;
+       break;
+   case 1: /* SEEK_CUR */
+       newpos = filp->f_pos + off;
+       break;
+   case 2: /* SEEK_END */
+       newpos = reg->len + off;
+       break;
+   default:
+       return -EINVAL;
+   }
+   if (newpos < 0) return -EINVAL;
+   filp->f_pos = newpos;
+   return newpos;
+}
+
+static const struct file_operations ioreg_reg_fops = {
+   .read       = ioreg_reg_read,
+   .write      = ioreg_reg_write,
+   .llseek     = ioreg_reg_lseek,
+};
+
+/**** end /proc/<pid>/hw/ioreg/ content ****/
+
+/**** begin /proc/<pid>/hw/ioreg directory ****/
+static struct dentry *proc_ioreg_instantiate(struct inode *dir,
+   struct dentry *dentry, struct task_struct *task, const void *ptr)
+{
+   const struct borph_ioreg *reg = ptr;
+   struct inode *inode;
+   struct proc_inode *ei;
+   struct dentry *error = ERR_PTR(-EINVAL);
+
+   inode = proc_pid_make_inode(dir->i_sb, task);
+   if (!inode)
+       goto out;
+
+   ei = PROC_I(inode);
+   ei->data = (void*) reg;
+
+   if (reg->mode & IORM_PIPE) {
+       inode->i_mode = S_IFIFO;
+   } else {
+       inode->i_mode = S_IFREG;
+   }
+   inode->i_mode |= (reg->mode&IORM_READ)?S_IRUGO:0;
+   inode->i_mode |= (reg->mode&IORM_WRITE)?S_IWUGO:0;
+   inode->i_size = reg->len;
+   inode->i_fop = &ioreg_reg_fops;
+
+   dentry->d_op = &pid_dentry_operations;
+   d_add(dentry, inode);
+
+   /* Close the race of the process dying before we return the dentry */
+   if (pid_revalidate(dentry, NULL))
+       error = NULL;
+out:
+   return error;
+}
+
+static struct dentry *proc_ioreg_lookup(struct inode *dir,
+                   struct dentry *dentry,
+                   struct nameidata *nd)
+{
+   struct task_struct *task = get_proc_task(dir);
+   struct borph_info* bi;
+   struct borph_ioreg* reg;
+   struct dentry *retval;
+   int regnamelen;
+   int i;
+
+   retval = ERR_PTR(-EINVAL);
+   if (!task)
+       goto out_no_task;
+
+   bi = task->borph_info;
+   if (!bi)
+       goto out;
+
+   retval = ERR_PTR(-ENOENT);
+   i = 2;
+   list_for_each_entry(reg, &bi->ioreg, list) {
+       regnamelen = strlen(reg->name);
+       if (dentry->d_name.len == regnamelen &&
+           !memcmp(dentry->d_name.name,reg->name,regnamelen)) {
+           retval = NULL;
+           break;
+       }
+       i += 1;
+   }
+   if (retval) goto out;
+
+   retval = proc_ioreg_instantiate(dir, dentry, task, reg);
+
+ out:
+   put_task_struct(task);
+ out_no_task:
+   return retval;
+}
+
+static int proc_ioreg_fill_cache(struct file *filp, void *dirent,
+   filldir_t filldir, struct task_struct *task, const struct borph_ioreg *reg)
+{
+   return proc_fill_cache(filp, dirent, filldir, reg->name, strlen(reg->name),
+               proc_ioreg_instantiate, task, reg);
+}
+
+static int proc_ioreg_readdir(struct file * filp, void * dirent, filldir_t filldir)
+{
+   struct dentry *dentry = filp->f_path.dentry;
+   struct inode *inode = dentry->d_inode;
+   struct task_struct *task = get_proc_task(inode);
+   unsigned int pos, pid, i;
+   ino_t ino;
+   int retval;
+   struct borph_info *bi;
+   struct borph_ioreg *reg;
+
+
+   retval = -ENOENT;
+   if (!task)
+       goto out_no_task;
+
+   pid = task->pid;
+   if (!pid)
+       goto out;
+
+   retval = 0;
+   pos = filp->f_pos;
+   switch (pos) {
+   case 0:
+       ino = inode->i_ino;
+       if (filldir(dirent, ".", 1, 0, ino, DT_DIR) < 0)
+           goto out;
+       filp->f_pos++;
+       /* fall through */
+   case 1:
+       ino = parent_ino(dentry);
+       if (filldir(dirent, "..", 2, 1, ino, DT_DIR) < 0)
+           goto out;
+       filp->f_pos++;
+       /* fall through */
+   default:
+       /* nothing in hw directory if not a borph process */
+       bi = task->borph_info;
+       if (!bi) {
+           retval = 1;
+           goto out;
+       }
+       i = 2;
+       list_for_each_entry(reg, &bi->ioreg, list) {
+           if (i >= pos) {
+               if (proc_ioreg_fill_cache(filp, dirent, 
+                             filldir, task, reg) < 0)
+                   goto out;
+               filp->f_pos++;
+           }
+           i += 1;
+       }
+   }
+   retval = 1;
+ out:
+   put_task_struct(task);
+
+ out_no_task:
+   return retval;
+}
+
+static struct inode_operations proc_ioreg_inode_operations = {
+   .lookup     = proc_ioreg_lookup,
+};
+
+static struct file_operations proc_ioreg_operations = {
+   .read       = generic_read_dir,
+   .readdir    = proc_ioreg_readdir,
+};
+/**** end /proc/<pid>/hw/ioreg directory ****/
+
+
+/**** begin /proc/<pid>/hw/ content ****/
+// /proc/<pid>/hw/ioreg_mode
+static ssize_t proc_ioregmode_read(struct task_struct *task, char *buffer)
+{
+   struct borph_info *bi = task->borph_info;
+   if (!bi) return -EINVAL;
+   buffer[0] = '0' + bi->ioreg_mode;
+   buffer[1] = '\n';
+   return 2;
+}
+
+static ssize_t ioregmode_read(struct file * file, char __user * buf,
+                 size_t count, loff_t *ppos)
+{
+   return proc_info_read(file, buf, count, ppos);
+}
+
+static ssize_t ioregmode_write(struct file *filp, const char *buf,
+                  size_t fcount, loff_t *fpos)
+{
+   struct dentry *dentry = filp->f_path.dentry;
+   struct inode *inode = dentry->d_inode;
+   struct task_struct *task = get_proc_task(inode);
+   struct borph_info *bi = task->borph_info;
+   int retval;
+
+   if (!bi) return -EINVAL;
+   if (fcount) {
+       char c;
+       if ((retval = get_user(c, buf)) < 0) return retval;
+       if (c < '0' || c > '9') return -EINVAL;
+       bi->ioreg_mode = (c - '0');
+   }
+   return fcount;
+}
+
+static const struct file_operations proc_ioregmode_file_operations = {
+   .read       = ioregmode_read,
+   .write      = ioregmode_write,
+};
+
+// /proc/<pid>/hw/hwregion
+static ssize_t proc_hwregion_read(struct task_struct *task, char *buffer)
+{
+   int len, i;
+   struct borph_hw_region *region, *tmp;
+   struct borph_info *bi;
+
+   if (!(bi = task->borph_info)) {
+       return -EINVAL;
+   }
+   i = 0;
+   len = 0;
+   list_for_each_entry_safe(region, tmp, &bi->hw_region, list) {
+       len = sprintf(buffer, "HW Region %d\n Address: 0x%X\n", i, region->addr.addr);
+   }
+   return len;
+}
+
+/**** end /proc/<pid>/hw/ content ****/
+
+/**** begin /proc/<pid>/hw directory ****/
+const struct inode_operations proc_bphhw_inode_operations;
+const struct file_operations proc_bphhw_operations;
+
+static const struct pid_entry bphhw_stuff[] = {
+   DIR("ioreg",    S_IRUGO|S_IXUGO, proc_ioreg_inode_operations, proc_ioreg_operations),
+   NOD("ioreg_mode", S_IFREG|S_IRUSR|S_IWUSR, 
+       NULL, &proc_ioregmode_file_operations,
+       { .proc_read = &proc_ioregmode_read } ),
+   INF("hwregion", S_IRUSR, &proc_hwregion_read),
+};
+
+static struct dentry *proc_tgid_bphhw_lookup(struct inode *dir, 
+                        struct dentry *dentry,
+                        struct nameidata *nd)
+{
+   return proc_pident_lookup(dir, dentry,
+                 bphhw_stuff, ARRAY_SIZE(bphhw_stuff));
+}
+
+static int proc_tgid_bphhw_readdir(struct file * filp, 
+                  void * dirent, filldir_t filldir)
+{
+   struct dentry *dentry = filp->f_path.dentry;
+   struct inode *inode = dentry->d_inode;
+   struct task_struct *task = get_proc_task(inode);
+   /* nothing in "hw" directory if not a hw process */
+   if (!task->borph_info) {
+       return 1;
+   }
+   return proc_pident_readdir(filp,dirent,filldir,
+                  bphhw_stuff,ARRAY_SIZE(bphhw_stuff));
+}
+
+/* iop -- named according to DIR() macro */
+const struct inode_operations proc_bphhw_inode_operations = {
+   .lookup = proc_tgid_bphhw_lookup,
+};
+
+/* fop -- named according to DIR() macro */
+const struct file_operations proc_bphhw_operations = {
+   .read = generic_read_dir,
+   .readdir = proc_tgid_bphhw_readdir,
+};
+
+/**** end /proc/<pid>/hw directory ****/
diff --git a/include/linux/bof.h b/include/linux/bof.h
new file mode 100644
index 0000000..18fb61dd
--- /dev/null
+++ b/include/linux/bof.h
@@ -0,0 +1,78 @@
+/**************************************************
+ * File  : bof.h
+ * Author: Hayden So, Brandon Hamilton
+ * Date  : 06/11/2009
+ * Description:
+ *    header file for the BOF file format
+ **************************************************/
+#ifndef _BOF_H_
+#define _BOF_H_
+
+/******************** Main BOF header ******************
+ * It MUST be at most 52 bytes long.  i.e. it MUST be the exact
+ * same size as a elf header Elf32_EHdr
+ *******************************************************/
+struct bofhdr {
+	unsigned char ident[16];
+	uint32_t b_version;
+	uint16_t b_machine;
+	uint16_t b_elfmachine;
+	uint32_t b_numchip;
+	uint32_t b_elfoff;  // offset of elf header from beginning of file
+	uint32_t b_hwoff;   // offset of the 1st hwregion from beginning of file
+	int32_t load_err;
+	uint32_t b_ekver;   // embedded kernel version
+	uint32_t pad[2];
+};
+
+/* position of various misc identifying info within ident */
+#define BI_ENDIAN 5
+#define BOFDATA2LSB 1
+#define BOFDATA2MSB 2
+
+/* legal values for b_machine */
+#define BM_BEE2		2
+#define BM_ROACH	3
+#define BM_NETFPGA	4
+#define BM_RHINO	5
+
+/***********************
+ * header per hw region
+ ***********************/
+struct hwr_addr {
+	uint16_t class;
+	uint16_t addr;
+};
+
+#define HAC_BEE2FPGA 0x1
+#define HAC_PRMOD    0x2
+#define HAC_ROACHV5  0x3
+#define HAC_NETFPGA  0x4
+#define HAC_RHINO	 0x5
+
+/* hwrhdr flags */
+#define HFG_PLACED   0x1
+#define HFG_NOCONFIG   0x2
+struct hwrhdr {
+	uint32_t flag;
+	struct hwr_addr addr;    /* address of placed */
+	uint32_t pl_off;         /* payload offset */
+	uint32_t pl_len;         /* payload len */
+	uint32_t nr_symbol;
+	uint32_t strtab_off;     /* string table offset */
+	uint32_t next_hwr;       /* next hw_region on file */
+	// HHH and more info about register mapping, etc
+};
+
+#define IORM_READ 1
+#define IORM_WRITE 2
+#define IORM_READWRITE 3
+#define IORM_PIPE 4
+struct bofioreg {
+	uint16_t name;     //offset into strtab where this name can be found
+	uint16_t mode;
+	uint32_t loc;
+	uint32_t len;
+};
+
+#endif /* _BOF_H_ */
diff --git a/include/linux/borph.h b/include/linux/borph.h
new file mode 100644
index 0000000..47f5530
--- /dev/null
+++ b/include/linux/borph.h
@@ -0,0 +1,147 @@
+/**************************************************
+ * File  : borph.h
+ * Author: Hayden So, Brandon Hamilton
+ * Date  : 06/11/2009
+ * Description:
+ *    Top level header file for all BORPH related files
+ **************************************************/
+#ifndef _BORPH_H_
+#define _BORPH_H_
+
+#include <linux/slab.h>
+#include <linux/sched.h>
+#include <linux/bof.h>
+#include <linux/file.h>
+#include <linux/fdtable.h>
+
+typedef unsigned char buf_t;
+
+/* a file to be exec-ed to FPGA */
+struct execq_item {
+    struct list_head list;
+    struct linux_binprm *bprm;
+    struct task_struct *task;
+};
+
+/* all info for communicating to/from bkexecd
+ * It has much resemblance to workqueue in 2.6 kernel */
+struct bkexecd_info {
+    wait_queue_head_t more_exec;  /* bkexecd to be awaken */
+    wait_queue_head_t exec_done;  /* exec-er to be notified done exec */
+    spinlock_t execq_lock;
+    struct list_head execq_list;  /* list of execq_item */
+};
+
+/* function exported to the rest of kernel */
+extern void borph_exit_fpga(struct task_struct* tsk);
+
+/* each reconfigurable region in BORPH is represented by a 
+ * struct borph_hw_region */
+struct borph_hw_region {
+	struct hwr_addr addr;
+	char* strtab;
+	struct list_head list;
+};
+
+/*
+ * each reconfigurable region can have zero or more ioreg
+ */
+struct borph_ioreg {
+	char* name;
+	uint32_t mode;
+	uint32_t loc;
+	uint32_t len;
+	struct hwr_addr* hwraddr;
+	struct list_head list;
+	struct borph_info *bi;
+};
+
+/* A dummy struct so that we can create a task_list list without
+ * messing with the actual structure of task_list */
+struct task_list {
+	struct task_struct* tsk;
+	rwlock_t data_lock;
+	void* data;  // argument for passing to fringe
+	struct list_head tsk_list;
+};
+
+extern struct kmem_cache* task_list_cachep;
+
+/* borph_info contains all hardware specific information in a
+ * task_struct.  */
+struct borph_info {
+	struct list_head hw_region;
+	struct list_head ioreg;
+	int ioreg_mode; 			 // 0 for ascii, 1 for raw
+	unsigned int status;		 // configuration status
+};
+
+/*******************************************
+ * functions to control the hwr device
+ *******************************************/
+
+struct hwr_iobuf {
+	unsigned location;
+	unsigned offset;
+	size_t size;
+	buf_t* data;
+};
+
+typedef struct hwr_iobuf* (*hwr_getiobuf_t) (void);
+
+struct hwr_operations {
+	int (*configure) (struct hwr_addr*, struct file*, uint32_t, uint32_t);
+	int (*unconfigure) (struct hwr_addr*);
+	struct phyhwr* (*reserve_hwr)(struct hwr_addr* a);
+	void (*release_hwr) (struct hwr_addr* a);
+	hwr_getiobuf_t get_iobuf;
+	ssize_t (*put_iobuf) (struct hwr_iobuf* iobuf);
+	ssize_t (*send_iobuf) (struct hwr_iobuf* iobuf);
+	ssize_t (*recv_iobuf) (struct hwr_iobuf* iobuf);
+};
+
+struct hwrtype {
+	char* name;
+	uint16_t type;  		// identical to hwr_addr.class
+	atomic_t count; 		// use count
+	uint16_t num_devs;  	// number of physical devices
+	struct hwr_operations *hwr_ops;
+};
+
+/* each physical hwr is represented by a hwr in kernel */
+struct phyhwr {
+	struct hwr_addr hwraddr;
+	atomic_t count;            	// use count
+	atomic_t active;   			// set to 1 if it is actively running
+	struct task_struct *task;   // task that uses this hwr
+};
+
+#define MAX_HWRTYPES 16
+
+extern struct hwrtype* hwrtypes[MAX_HWRTYPES];
+extern struct phyhwr** phyhwrs[MAX_HWRTYPES];
+
+extern int register_hwrtype(struct hwrtype*);
+extern int unregister_hwrtype(struct hwrtype*);
+extern struct hwr_operations* get_hwrops(struct hwr_addr* a);
+extern void put_hwrops(struct hwr_addr* a);
+extern struct phyhwr* reserve_hwr(struct hwr_addr*);
+extern void release_hwr(struct hwr_addr* a);
+extern struct phyhwr* get_hwr(struct hwr_addr* a);
+extern void put_hwr(struct hwr_addr* a);
+extern void __put_hwr(struct phyhwr* hwr);
+extern struct hwr_iobuf* get_iobuf(struct hwr_addr* a);
+extern ssize_t put_iobuf(struct hwr_addr* a, struct hwr_iobuf* iobuf);
+extern ssize_t send_iobuf(struct hwr_addr* a, struct hwr_iobuf* iobuf);
+extern ssize_t recv_iobuf(struct hwr_addr* a, struct hwr_iobuf* iobuf);
+extern int hwr_inuse(struct hwr_addr* a);
+extern void hwr_activate(struct hwr_addr* a);
+extern void hwr_deactivate(struct hwr_addr* a);
+extern void hwr_init(void);
+
+/************************************************
+ * misc
+ ************************************************/
+extern void borph_init(void);
+extern void borph_exit_fpga(struct task_struct* tsk);
+#endif /* _BORPH_H_ */
diff --git a/include/linux/hdebug.h b/include/linux/hdebug.h
new file mode 100644
index 0000000..5950451
--- /dev/null
+++ b/include/linux/hdebug.h
@@ -0,0 +1,37 @@
+/****************************************************************
+ * $Id: hdebug.h,v 1.1 2006/01/21 20:48:23 skhay Exp $
+ *
+ * Define macro for debugging
+ *
+ * Hayden So
+ ****************************************************************/
+#ifndef HDEBUG_H
+#define HDEBUG_H
+
+/****************************************************************
+ * helper functions
+ ****************************************************************/
+#ifndef HDBG_LVL
+#  define HDBG_LVL 0
+#endif /* defined(HDBG_LVL) */
+
+#ifndef HDBG_NAME
+#  define HDBG_NAME
+#endif /* HDBG_NAME */
+
+#ifdef PDEBUG
+#undef PDEBUG
+#endif
+
+#ifdef HDEBUG
+#  define PDEBUG(lvl, fmt, args...) if (lvl <= HDBG_LVL) printk(KERN_DEBUG HDBG_NAME ": " fmt, ## args)
+#else /* not in debug mode at all */
+#  define PDEBUG(lvl, fmt, args...) /* defined as nothing */
+#endif /* HDEBUG */
+
+#ifndef PMSG
+#define PMSG(fmt, args...) printk(KERN_INFO HDBG_NAME ": " fmt, ## args)
+#endif /* PMSG */
+
+
+#endif /* HDEBUG_H */
diff --git a/include/linux/kselectmap.h b/include/linux/kselectmap.h
new file mode 100644
index 0000000..f321142
--- /dev/null
+++ b/include/linux/kselectmap.h
@@ -0,0 +1,211 @@
+/******************************************************************
+ * SelectMap driver
+ *
+ * A lot of the code in thie file are borrowed from the selectmap device 
+ * driver by Andrew Shultz.  Since the OS is using this selectmap link 
+ * exclusively, there is no need for a device driver with BORPH.  But since
+ * the communication mechanism with the physical hw is essentail the 
+ * same, the code from device driver can be reuse here to a large extent
+ *
+ *
+ * There are two registers, both 32-bits.  The register at base+0 is
+ * the control register which has the following layout: 
+ *
+ *  0-3   4      5       6       7        8-15         16-23    24-31
+ * +------------------------------------------------------------------+
+ * |   | MODE | PROG_B | INIT_B | DONE | RdFifo Cnt | WrFifo Cnt |    |
+ * +------------------------------------------------------------------+
+ *
+ * MODE:
+ * 0 = "Configure" mode, has appropriate timing for config/readback
+ * 1 = "FIFO" mode, has timing for general purpose two-way fifo
+ *
+ * PROG_B:
+ * 0 = PROG pin asserted
+ * 1 = PROG pin deasserted
+ *
+ * INIT_B:
+ * 0 = Init asserted (after prog pulse in config mode)/Interrupt
+ *     deasserted (fifo mode)
+ * 1 = Init deasserted (config mode)/Interrupt asserted (fifo mode)
+ *
+ * DONE:
+ * 0 = Chip unconfigured
+ * 1 = Chip configured
+ *
+ * RdFifo Cnt:
+ * # elements in read fifo
+ *
+ * WrFifo Cnt:
+ * # elements in write fifo (space left is 256 - WrFifo Cnt)
+ *
+ * The other register is base+4 and that is the data register which you
+ * read/write for configuration and for FIFO access.  
+ */
+#ifndef _KSELECTMAP_H_
+#define _KSELECTMAP_H_
+#undef SELECTMAP_WORD_XFER
+
+#include <asm/io.h>        /* in/out functions         */
+#include <asm/types.h>
+#include <linux/semaphore.h>
+
+#define SELECTMAP_NUM_DEVS       5
+#define SELECTMAP_LENGTH         8
+#define SELECTMAP_WIDTH          1
+#define SELECTMAP_FIFO_NUM_WORDS 600
+#define SELECTMAP_FIFO_NUM_BYTES 127
+#define SELECTMAP_FIFO_MAX       255
+#define SELECTMAP_BUFSIZE        (SELECTMAP_WIDTH * SELECTMAP_FIFO_NUM_WORDS)
+
+/*****************************************************************
+ * Data macros
+ *****************************************************************/
+
+#define SELMAP_MODE            0x08
+#define SELMAP_PROG            0x04
+#define SELMAP_INIT            0x02
+#define SELMAP_DONE            0x01
+
+#define SELECTMAP_STATUS(word)    ((u8)((word >> 24) & 0xff))
+#define SELECTMAP_MODE(word)      (u8)(SELECTMAP_STATUS(word) & MODE)
+#define SELECTMAP_PROG(word)      (u8)(SELECTMAP_STATUS(word) & PROG)
+#define SELECTMAP_INIT(word)      (u8)(SELECTMAP_STATUS(word) & INIT)
+#define SELECTMAP_DONE(word)      (u8)(SELECTMAP_STATUS(word) & DONE)
+#define SELECTMAP_RFIFO_CNT(word) (u8)(((word) >> 16) & 0xff)
+#define SELECTMAP_WFIFO_CNT(word) (u8)(((word) >> 8)  & 0xff)
+
+/*****************************************************************
+ * Data structures
+ *****************************************************************/
+typedef unsigned char buf_t;
+typedef struct selectmap {
+    unsigned long base;    /* Base address of memory region   */
+    void *vbase;           /* Virtual base address of region  */
+    buf_t *buf;    /* Read/write buffer               */
+    int id;                /* Identifier                      */
+    struct semaphore sem;
+//    atomic_t available;    /* Single open flag                */
+} selectmap_t;
+
+/*****************************************************************************
+ * debugging fix up
+ ********************/
+/* if we are testing using uml, there's no real (ppc+xilinx specific) i/o */
+#if defined(__arch_um__) || defined(CONFIG_ROACH)
+static inline void um_out_be32(volatile unsigned *addr, int val)
+{
+   printk("out_be32(%p, 0x%x)\n", addr, val);
+}
+
+static inline void um_out_8(volatile unsigned *addr, uint8_t val)
+{
+   printk("out_8(%p, 0x%x)\n", addr, val);
+}
+
+#if 0
+#endif /* 0 */
+static inline unsigned um_in_be32(volatile unsigned *addr)
+{
+   unsigned retval;
+   static unsigned fakeval[4] = { 
+       0x0F027f00, 0x0F027f00, 0x0F027f00 , 0x0F027f00,
+//     0x00000000, 0x04007f00, 0x02000200, 0x0d2e7f00
+   };
+   static int idx = 0;
+   retval = fakeval[idx];
+   idx += 1;
+   if (idx == 4) {
+       idx = 0;
+   }
+   printk("um_in_be32 returns 0x%p, 0x%x\n", addr, retval);
+   return retval;
+}
+
+static inline unsigned char um_in_8(volatile unsigned *addr)
+{
+   unsigned retval;
+#define FAKEVALSIZE 46
+   static unsigned char fakeval[FAKEVALSIZE] = { 
+       2, 0, 0x42, 0, 0, 0, 0, 4, 0xFF, 0xAB, 0x12, 0x34, /*12*/
+       2, 0, 0x42, 0, 0, 0, 0, 1, 0x7,                    /*9*/
+       3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0x64,         /*13*/
+       2, 0, 0x42, 0, 0, 0, 0, 4, 0xDE, 0xAD, 0xBE, 0xEF, /*12*/
+   };
+   static int idx = 0;
+   retval = fakeval[idx];
+   idx += 1;
+   if (idx == FAKEVALSIZE) {
+       idx = 1;
+   }
+   printk("um_in_8 returns 0x%x\n", retval);
+   return retval;
+}
+
+#define out_be32(a, v) um_out_be32(a, v)
+//#define in_be32(a) (0x0F027f00)
+#define in_be32(a) um_in_be32(a)
+#define out_8(a, v) um_out_8(a, v)
+//#define in_8(a) (0xF4)
+#define in_8(a) um_in_8(a)
+#define iounmap(a)
+#define ioremap(a, len) NULL
+#define XPAR_OPB_SELECTMAP_0_BASEADDR 0
+#define XPAR_OPB_INTC_0_OPB_SELECTMAP_0_IP2INTC_IRPT_INTR 0
+#endif /* __arch_um__ || CONFIG_ROACH*/
+/*****************************************************************************/
+#ifdef SELECTMAP_WORD_XFER
+#define selectmap_out_data(dev, val) \
+  do {out_be32((dev)->vbase+4, val); wmb();} while (0)
+#define selectmap_in_data(dev, val) \
+  do {val = in_be32((dev)->vbase+4); rmb();} while (0)
+#define selectmap_out_status(dev, val) \
+  do {out_be32((dev)->vbase, val); wmb();} while (0)
+#define selectmap_in_status(dev, val) \
+  do {val = in_be32(dev->vbase); rmb();} while (0)
+
+#define selectmap_set_fifomode(dev) \
+  do {u32 s = in_be32((dev)->vbase); rmb(); out_be32((dev)->vbase, s|0x08000000); wmb();} while (0)
+#define selectmap_set_cfgmode(dev) \
+  do {u32 s = in_be32((dev)->vbase); rmb(); out_be32((dev)->vbase, s&~0x08000000); wmb();} while (0)
+#else  /* byte transfer */
+#define selectmap_out_data(dev, bval) \
+  do {out_8((dev)->vbase+4, bval); wmb();} while (0)
+#define selectmap_in_data(dev, val) \
+  do {val = in_8((dev)->vbase+4); rmb();} while (0)
+
+#define selectmap_out_status(dev, val) \
+  do {out_be32((dev)->vbase, val); wmb();} while (0)
+#define selectmap_in_status(dev, val) \
+  do {val = in_be32(dev->vbase); rmb();} while (0)
+
+#define selectmap_set_fifomode(dev) \
+  do {u32 s = in_be32((dev)->vbase); rmb(); out_be32((dev)->vbase, s|0x08000000); wmb();} while (0)
+#define selectmap_set_cfgmode(dev) \
+  do {u32 s = in_be32((dev)->vbase); rmb(); out_be32((dev)->vbase, s&~0x08000000); wmb();} while (0)
+
+#endif /* SELECTMAP_WORD_XFER */
+
+/*************************************************************************
+ * interrupt stuff 
+ *************************************************************************/
+#define SELECTMAP_IRQ (31 - XPAR_OPB_INTC_0_OPB_SELECTMAP_0_IP2INTC_IRPT_INTR)
+#define SELMAP_INTR_DISR mkd_info->intrreg
+#define SELMAP_INTR_DIPR (mkd_info->intrreg + 0x4)
+#define SELMAP_INTR_DIER (mkd_info->intrreg + 0x8)
+#define SELMAP_INTR_DIIR (mkd_info->intrreg + 0x18)
+#define SELMAP_INTR_DGIER (mkd_info->intrreg + 0x1c)
+#define SELMAP_INTR_IPISR (mkd_info->intrreg + 0x20)
+#define SELMAP_INTR_IPIER (mkd_info->intrreg + 0x28)
+
+#define out_intr_reg(reg, val) \
+  do {out_be32((reg), val); wmb();} while (0)
+#define in_intr_reg(reg, val) \
+  do {(val) = in_be32(reg); rmb();} while (0)
+
+
+/* helper functions defined in kselectmap.c */
+extern selectmap_t* get_selmapdev(int addr);
+extern void put_selmapdev(selectmap_t* dev);
+extern int kselectmap_init(void);
+#endif
\ No newline at end of file
diff --git a/include/linux/proc_fs.h b/include/linux/proc_fs.h
index 643b96c..ac9c5b5 100644
--- a/include/linux/proc_fs.h
+++ b/include/linux/proc_fs.h
@@ -273,6 +273,7 @@ struct proc_inode {
 	void *ns;
 	const struct proc_ns_operations *ns_ops;
 	struct inode vfs_inode;
+	void* data;
 };
 
 static inline struct proc_inode *PROC_I(const struct inode *inode)
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 41d0237..0324b7d 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -93,6 +93,9 @@ struct sched_param {
 
 #include <asm/processor.h>
 
+#ifdef CONFIG_BORPH
+struct borph_info;
+#endif
 struct exec_domain;
 struct futex_pi_state;
 struct robust_list_head;
@@ -1529,6 +1532,10 @@ struct task_struct {
 	int latency_record_count;
 	struct latency_record latency_record[LT_SAVECOUNT];
 #endif
+#ifdef CONFIG_BORPH
+	/* BORPH specific fpga region info */
+	struct borph_info *borph_info;
+#endif
 	/*
 	 * time slack values; these are used to round up poll() and
 	 * select() etc timeout values. These are in nanoseconds.
diff --git a/init/main.c b/init/main.c
index 03b408d..361026b 100644
--- a/init/main.c
+++ b/init/main.c
@@ -79,6 +79,10 @@
 #include <asm/smp.h>
 #endif
 
+#ifdef CONFIG_BORPH
+extern void borph_init(void);
+#endif
+
 static int kernel_init(void *);
 
 extern void init_IRQ(void);
@@ -636,6 +640,10 @@ asmlinkage void __init start_kernel(void)
 
 	ftrace_init();
 
+#ifdef CONFIG_BORPH
+	borph_init();
+#endif
+
 	/* Do the rest non-__init'ed, we're now alive */
 	rest_init();
 }
diff --git a/kernel/Makefile b/kernel/Makefile
index eca595e..4b1d52d 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -109,6 +109,16 @@ obj-$(CONFIG_PADATA) += padata.o
 obj-$(CONFIG_CRASH_DUMP) += crash_dump.o
 obj-$(CONFIG_JUMP_LABEL) += jump_label.o
 
+####################################################
+# BORPH configuration
+ifeq ($(CONFIG_BORPH),y)
+obj-$(CONFIG_BORPH)   += borph.o
+obj-$(CONFIG_BORPH)   += hwr/
+obj-$(CONFIG_MKD)     += mkd.o
+obj-$(CONFIG_BKEXECD) += bkexecd.o
+endif
+####################################################
+
 ifneq ($(CONFIG_SCHED_OMIT_FRAME_POINTER),y)
 # According to Alan Modra <alan@linuxcare.com.au>, the -fno-omit-frame-pointer is
 # needed for x86 only.  Why this used to be enabled for all architectures is beyond
diff --git a/kernel/bkexecd.c b/kernel/bkexecd.c
new file mode 100644
index 0000000..28b56f8
--- /dev/null
+++ b/kernel/bkexecd.c
@@ -0,0 +1,373 @@
+/*********************************************************************
+ * $Id: bkexecd.c,v 1.1 2006/10/31 07:28:57 skhay Exp $
+ * File  : bkexecd.c
+ * Author: Hayden Kwok-Hay So, Brandon Hamilton
+ * Date  : 12/09/2005
+ * Modified: 18/02/2011
+ * Description:
+ *   This is the main code for bkexecd. It is responsible for
+ * configuring and de-configure FPGA as part of a BORPH process
+ *
+ *  bkexecd is responsible for all communication to "user
+ * fpga" via the platform specific code in hwr/ directory.
+ * A FPGA is configured during exec of
+ * a bof file.  Therefore. bkexecd simply sleep upon start up and wait
+ * forever until a bof file is exec-ed and binfmt_bof wakes it up.
+ *********************************************************************/
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/borph.h>
+#include <linux/bof.h>
+#include <linux/init.h>
+#include <linux/highmem.h>
+#include <linux/binfmts.h>
+#include <linux/gfp.h>
+
+#ifdef CONFIG_RHINO
+	#define HAC_TYPE HAC_RHINO
+#else
+#ifdef CONFIG_ROACH
+	#define HAC_TYPE HAC_ROACH
+#else
+#ifdef CONFIG_NETFPGA
+	#define HAC_TYPE HAC_NETFPGA
+#else
+	#define HAC_TYPE HAC_BEE2FPGA
+	#ifdef CONFIG_MKD
+		#include <linux/kselectmap.h>
+		// HHH move me to mkd.c
+		int mkdbuf_reset(struct hwr_addr* a) {
+			if (!a || a->class != HAC_TYPE) return -ENOEXEC;
+			if (a->addr >= SELECTMAP_NUM_DEVS ) return -ENOEXEC;
+			mkd_info->mkd_bufs[a->addr] = mkd_info->mkd_bufe[a->addr];
+			return 0;
+		}
+	#endif
+#endif
+#endif
+#endif
+
+#define HDEBUG
+#define HDBG_NAME "bkexecd"
+#define HDBG_LVL 6
+#include <linux/hdebug.h>
+
+struct bkexecd_info bked_info;
+static pid_t bked_pid;
+
+static size_t get_args(char* buf, struct linux_binprm* bprm, size_t size) {
+	char* bptr = buf;
+	char* kaddr;
+	size_t ret = 0;
+	unsigned long offset, len, p;
+	struct page* page;
+	int argc;
+
+	if (!buf || !bprm || !size) return -EINVAL;
+
+	argc = bprm->argc;
+	p = bprm->p;
+
+	while (argc && (ret < size)) {
+		offset = p % PAGE_SIZE;
+		len = PAGE_SIZE - offset;
+
+#ifdef CONFIG_MMU
+		get_user_pages(current, bprm->mm, p, 1, 0, 1, &page, NULL);
+#else
+		page = bprm->page[p / PAGE_SIZE];
+#endif
+		kaddr = kmap(page) + offset;
+		
+		if (ret + len > size) {
+			len = size - ret;
+		}
+
+		while (len-- && argc) {
+			char c;
+			*bptr++ = c = *kaddr++;
+			if (!c) {
+				argc -= 1;
+			}
+			p += 1;
+			ret += 1;
+		}
+		kunmap(page);
+	}
+
+	return ret;
+}
+
+static inline struct phyhwr* bpr_nextfree(struct hwr_addr* a)
+{
+	int i;
+	struct phyhwr* retval;
+
+	if (!a || a->class != HAC_TYPE) return NULL;
+	/* Make sure it never checks control FPGA */
+	
+	for (i = 0; i < 4; i++) {
+		a->addr = i;
+		retval = reserve_hwr(a);
+		if (retval) {
+			return retval;
+		}
+	}
+	return NULL;
+}
+
+static inline int borph_load_hw(struct execq_item *execq_item)
+{
+	struct borph_info* bi;
+	struct borph_hw_region* region;
+	struct bofhdr bofhdr;
+	struct hwr_operations* hwrops;
+	uint32_t cur_foff;
+	int retval;
+	struct hwrhdr hwrhdr;
+	char task_id[10];
+
+	PDEBUG(9, "configure from file: %s\n", execq_item->bprm->filename);
+
+	// SHOULD USE SLAB!!!
+	bi = kmalloc(sizeof(struct borph_info), GFP_KERNEL);
+	memset(bi, 0, sizeof(struct borph_info));
+	INIT_LIST_HEAD(&bi->hw_region);
+	INIT_LIST_HEAD(&bi->ioreg);
+	
+	// Set binary as default mode
+	bi->ioreg_mode = 1;
+	bi->status = 0;
+
+	execq_item->task->borph_info = bi;
+
+	retval = -EIO;
+        bofhdr = *((struct bofhdr *) execq_item->bprm->buf);
+
+	PDEBUG(9, "version=%d, numchip=%d, elf_off=0x%x, hw_off=0x%x, ekver=0x%x\n",
+	       bofhdr.b_version, bofhdr.b_numchip, bofhdr.b_elfoff, 
+	       bofhdr.b_hwoff, bofhdr.b_ekver);
+	cur_foff = bofhdr.b_hwoff;
+	while (bofhdr.b_numchip--) {
+		struct phyhwr* hwr;
+		char* strtab = NULL;
+		uint32_t strtab_len = 0;
+		uint32_t strtab_foff;
+
+		if (cur_foff == 0) {
+			PDEBUG(9, "invalid bof file\n");
+			goto out_delregion;
+		}
+		retval = kernel_read(execq_item->bprm->file, cur_foff, 
+				     (char*) &hwrhdr, sizeof(struct hwrhdr));
+		if (retval < 0) {
+			goto out_delregion;
+		}
+		cur_foff += sizeof(struct hwrhdr);
+
+		PDEBUG(9, "hwrhdr: flag=0x%x, pl_off=0x%x, pl_len=0x%x," 
+		       " next_hwr=0x%x, strtab_off=0x%x, nr_symbol=%d\n", 
+		       hwrhdr.flag, hwrhdr.pl_off, hwrhdr.pl_len, 
+		       hwrhdr.next_hwr, hwrhdr.strtab_off, hwrhdr.nr_symbol);
+
+		retval = -EBUSY;
+		if (hwrhdr.flag & HFG_PLACED) {
+			hwr = reserve_hwr(&hwrhdr.addr);
+
+			if (!hwr ){
+				goto out_delregion;
+			}
+		} else {
+			// need P&R
+			hwr = bpr_nextfree(&hwrhdr.addr);
+			if (!hwr) {
+				goto out_delregion;
+			}
+		}
+		hwr->task = execq_item->task;
+		
+		PDEBUG(5, "Configuring FPGA %d\n", hwrhdr.addr.addr);
+		/* strtab */
+		retval = -ENOEXEC;
+		strtab_foff = 
+			cur_foff + hwrhdr.nr_symbol * sizeof(struct bofioreg);
+		strtab_len = hwrhdr.pl_off - hwrhdr.strtab_off;
+		if (!strtab_len && hwrhdr.nr_symbol) {
+			PDEBUG(0, "0 length string table\n");
+			goto out_delregion;
+		}
+		strtab = kmalloc(strtab_len, GFP_KERNEL);
+		if (!strtab) {
+		    PDEBUG(9, "kmalloc strtab failed\n");
+		    goto out_delregion;
+		}
+		retval = kernel_read(execq_item->bprm->file, strtab_foff,
+				     (char*) strtab, strtab_len);
+		if (retval < 0) goto out_delregion;
+
+		/* region */
+		// should use slab
+		region = kmalloc(sizeof(struct borph_hw_region), GFP_KERNEL);
+		if (!region) {
+			PDEBUG(9, "kmalloc region failed\n");
+		} else {
+			PDEBUG(9, "got region\n");
+		}
+		region->addr = hwrhdr.addr;
+		region->strtab = strtab;
+		list_add(&(region->list), &(bi->hw_region));
+
+		/* ioreg */
+		PDEBUG(9, "Loading %d IOREG\n", hwrhdr.nr_symbol);
+		while (hwrhdr.nr_symbol--) {
+			struct borph_ioreg *reg;
+			struct bofioreg bof_ioreg;
+
+			// should use slab
+			reg = kmalloc(sizeof(struct borph_ioreg), GFP_KERNEL);
+			if (!reg) {
+				PDEBUG(9, "kmalloc borph_ioreg failed\n");
+			}
+			retval = kernel_read(execq_item->bprm->file, cur_foff,
+					     (char*) &bof_ioreg, 
+					     sizeof(struct bofioreg));
+			if (retval < 0) {
+				goto out_delregion;
+			}
+			cur_foff += sizeof(struct bofioreg);
+		    
+			reg->name = strtab + bof_ioreg.name;
+			reg->mode = bof_ioreg.mode;
+			reg->loc = bof_ioreg.loc;
+			reg->len = bof_ioreg.len;
+			reg->hwraddr = &region->addr;
+			list_add(&(reg->list), &(bi->ioreg));
+		}
+
+		hwrops = get_hwrops(&hwrhdr.addr);
+		if (hwrops && hwrops->configure) {
+			retval = hwrops->configure(&(hwrhdr.addr), 
+							   execq_item->bprm->file, 
+							   hwrhdr.pl_off,
+							   hwrhdr.pl_len);
+
+		} else {
+			printk(KERN_INFO "no hwrops from hwr class %d\n",
+			       hwrhdr.addr.class);
+			retval = -ENOEXEC;
+			goto out_delregion;
+		}
+		put_hwrops(&hwrhdr.addr);
+		if (retval < 0) {
+			goto out_delregion;
+		}
+		/* done with all the configuration for this chip
+		 * tell the rest of the kernel about it */
+		hwr_activate(&(hwrhdr.addr));
+		/* prepare for next hardware region */
+		cur_foff = hwrhdr.next_hwr;
+	}
+	bi->status |= 1;
+	//done
+	PDEBUG(5, "FPGA configuration completed\n");
+	return 0;
+ out_delregion:
+	borph_exit_fpga(execq_item->task);
+	return retval;
+}
+
+/* program FPGA according to execq_item until no more item on
+   execq_list */
+static inline void run_execq(void)
+{
+	unsigned long flags;
+	int retval;
+
+	spin_lock_irqsave(&bked_info.execq_lock, flags);
+	while (!list_empty(&bked_info.execq_list)) {
+		struct execq_item* execq_item;
+		struct bofhdr* bhdr;
+		execq_item = list_entry(bked_info.execq_list.next, 
+					struct execq_item, list);
+		list_del_init(bked_info.execq_list.next);
+		spin_unlock_irqrestore(&bked_info.execq_lock, flags);
+
+		/***** actual fpga configuration *****/
+		retval = borph_load_hw(execq_item);
+		bhdr = (struct bofhdr*) (execq_item->bprm->buf);
+		bhdr->load_err = retval;
+
+		wake_up_process(execq_item->task);
+		/***** end fpga configuration *****/
+		kfree(execq_item);  // HHH return to slab
+
+		// get lock in preparation for list_empty check
+		spin_lock_irqsave(&bked_info.execq_lock, flags);
+		wake_up_interruptible(&bked_info.exec_done);
+	}
+	spin_unlock_irqrestore(&bked_info.execq_lock, flags);
+}
+
+static int bkexecd(void *dummy)
+{
+	DECLARE_WAITQUEUE(wait, current);
+
+	/* initialize bked_info */
+	INIT_LIST_HEAD(&bked_info.execq_list);
+	spin_lock_init(&bked_info.execq_lock);
+	init_waitqueue_head(&bked_info.more_exec);
+	init_waitqueue_head(&bked_info.exec_done);
+
+	/* detach myself from calling process (e.g. insmod) */
+	daemonize("bkexecd");
+	
+	/* my info */
+	sprintf(current->comm, "bkexecd");
+
+	/* Block all signals except SIGKILL and SIGSTOP */
+	spin_lock_irq(&current->sighand->siglock);
+	siginitsetinv(&current->blocked, sigmask(SIGKILL) | sigmask(SIGSTOP) );
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+
+
+	// loop forever until we have any signal (SIGKILL | SIGSTOP)
+	for(;;) {
+		set_current_state(TASK_INTERRUPTIBLE);
+		add_wait_queue(&bked_info.more_exec, &wait);
+		if (list_empty(&bked_info.execq_list)) {
+			schedule();
+		}
+		__set_current_state(TASK_RUNNING);
+		remove_wait_queue(&bked_info.more_exec, &wait);
+
+		if (signal_pending(current)) {
+			// we got SIGKILL | SIGSTOP
+			break;
+		}
+
+		if (!list_empty(&bked_info.execq_list)) {
+			run_execq();
+		}
+	}
+	PDEBUG(9, "Shutting down BORPH execution thread\n");
+	return 0;
+}
+
+static __init int bkexecd_init(void)
+{
+	bked_pid = kernel_thread(bkexecd, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGHAND);
+	return 0;
+}
+
+static __exit void bkexecd_exit(void) {
+//	kill_proc(bked_pid, SIGKILL, 0);
+}
+
+EXPORT_SYMBOL(bked_info);
+
+module_init(bkexecd_init);
+module_exit(bkexecd_exit);
+MODULE_LICENSE("GPL");
diff --git a/kernel/borph.c b/kernel/borph.c
new file mode 100644
index 0000000..e96c1d1
--- /dev/null
+++ b/kernel/borph.c
@@ -0,0 +1,120 @@
+/*********************************************************************
+ * $Id: borph.c,v 1.10 2006/10/31 07:28:57 skhay Exp $
+ * File  : borph.c
+ * Author: Hayden Kwok-Hay So
+ * Date  : 12/14/2005
+ * Description:
+ *   Main entry point for BORPH + Linux
+ *********************************************************************/
+#include <linux/borph.h>
+#include <linux/slab.h>
+#include <linux/init.h>    // needed for __init
+#include <linux/module.h>
+#define HDEBUG
+#define HDBG_NAME "borph"
+#define HDBG_LVL 9l
+#include <linux/hdebug.h>
+
+/*
+ * borph_exit_fpga()
+ * De-configure fpga associated with @tsk
+ */
+void borph_exit_fpga(struct task_struct *tsk)
+{
+	struct borph_hw_region *region, *tmp;
+	struct borph_ioreg *reg, *tmpreg;
+	struct task_list *tl, *tmptl;
+	struct borph_info *bi;
+	struct hwr_operations *hwrops;
+
+	if (!(bi = tsk->borph_info)) {
+	    goto exit;
+	}
+
+	/* HHH Race between /proc/<pid>/hw and here... */
+	PDEBUG(0,"BORPH: exiting FPGA: closing ioreg access\n");
+
+	if (!list_empty(&bi->ioreg)) {
+		list_for_each_entry_safe(reg, tmpreg, &bi->ioreg, list) {
+			list_del(&reg->list);
+			kfree(reg);
+		}
+	}
+	PDEBUG(0,"BORPH: exiting FPGA: checking hardware region\n");
+
+	if (!list_empty(&bi->hw_region)) {
+		list_for_each_entry_safe(region, tmp, &bi->hw_region, list) {
+			PDEBUG(0,"kill fpga process at region 0x%X\n", region->addr.addr);
+			kfree(region->strtab);
+			PDEBUG(0,"BORPH: exiting FPGA: deactivating region\n");
+			hwr_deactivate(&region->addr);
+#ifdef CONFIG_MKD
+			    uint32_t d, mask;
+			    mask = 1UL << region->addr.addr;
+			    in_intr_reg(SELMAP_INTR_IPIER, d);
+			    out_intr_reg(SELMAP_INTR_IPIER, d & ~mask);
+
+			    /* If mkd died, there's no point for us to do 
+			     * anything...  This is bad... but
+			     * hopefully only happens because we are
+			     * shutting down. */
+
+			    if (mkd_info) {
+				mkd_info->selectmap_pending &= ~mask;
+				mkd_info->fifo_pending &= ~mask;
+				// HHH check address class
+				mkd_info->mkd_bufs[region->addr.addr] = 
+				    mkd_info->mkd_bufe[region->addr.addr];
+			    }
+#endif
+			hwrops = get_hwrops(&region->addr);
+			PDEBUG(0,"BORPH: exiting FPGA: calling device unconfigure method\n");
+			if (hwrops && hwrops->unconfigure) {
+				hwrops->unconfigure(&region->addr);
+			} else {
+				printk("unknown hwr type %d\n", region->addr.class);
+			}
+			put_hwrops(&region->addr);
+
+			PDEBUG(0,"BORPH: exiting FPGA: releasing region memory\n");
+			release_hwr(&region->addr);
+			list_del(&region->list);
+			kfree(region);
+		}
+	}
+	PDEBUG(0,"BORPH: exiting FPGA: Free kernel memory\n");
+	kfree(tsk->borph_info);
+	tsk->borph_info = NULL;
+ exit:
+	return;
+}
+
+#ifdef CONFIG_MKD
+/**************************************
+ * mkd related functions
+ **************************************/
+struct mkd_struct *mkd_info = NULL;
+#endif
+
+/**************************************
+ * Slab
+ **************************************/
+struct kmem_cache* task_list_cachep;
+
+/**************************************
+ * Initialization specific to BORPH 
+ **************************************/
+void __init borph_init(void)
+{
+	hwr_init();
+
+	task_list_cachep = kmem_cache_create("task_list", 
+					     sizeof(struct task_list),
+					     0, 0, NULL);
+	if (!task_list_cachep) {
+	    return;
+	}
+
+	printk("BORPH initialized\n");
+	return;
+}
diff --git a/kernel/exit.c b/kernel/exit.c
index 2913b35..0dbb4ff 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -56,6 +56,7 @@
 #include <asm/unistd.h>
 #include <asm/pgtable.h>
 #include <asm/mmu_context.h>
+#include <linux/borph.h>
 
 static void exit_mm(struct task_struct * tsk);
 
@@ -972,7 +973,9 @@ NORET_TYPE void do_exit(long code)
 
 	tsk->exit_code = code;
 	taskstats_exit(tsk, group_dead);
-
+#ifdef CONFIG_BORPH
+	borph_exit_fpga(tsk);
+#endif
 	exit_mm(tsk);
 
 	if (group_dead)
diff --git a/kernel/hwr/Makefile b/kernel/hwr/Makefile
new file mode 100644
index 0000000..22381e5
--- /dev/null
+++ b/kernel/hwr/Makefile
@@ -0,0 +1,10 @@
+#
+# Makefile for the BORPH hardware regions.
+#
+
+obj-$(CONFIG_BORPH) 	+= hwr.o common.o
+
+hwr-$(CONFIG_HWR_RHINO) += hwrtype_rhino.o
+hwr-$(CONFIG_HWR_BEE2) += hwrtype_b2fpga.o
+hwr-$(CONFIG_HWR_ROACHV5) += hwrtype_roach.o
+hwr-$(CONFIG_HWR_NETFPGA) += hwrtype_netfpga.o
diff --git a/kernel/hwr/common.c b/kernel/hwr/common.c
new file mode 100644
index 0000000..d80b08f
--- /dev/null
+++ b/kernel/hwr/common.c
@@ -0,0 +1,259 @@
+/*********************************************************************
+ * File  : kernel/hwr/common.c
+ * Author: Brandon Hamilton, Hayden Kwok-Hay So
+ * Date  : 8/29/2008
+ * Description:
+ *   Common code needed to handle different hwrtypes
+ *********************************************************************/
+#include <linux/borph.h>
+#define HDEBUG
+#define HDBG_NAME "borph"
+#define HDBG_LVL 9 //mkd_info->dbg_lvl
+#include <linux/hdebug.h>
+
+
+struct hwrtype* hwrtypes[MAX_HWRTYPES];
+
+/*
+ * BKH: a 2 Dimensional array, where the first
+ *      dimension is the hwrtype, which will determine the
+ *      length of the second dimension of phyhwr (allocated
+ *      on registration of the hwrtype).
+ */
+struct phyhwr** phyhwrs[MAX_HWRTYPES];
+
+struct hwr_operations* get_hwrops(struct hwr_addr* a)
+{
+	struct hwrtype* ht = NULL;
+	if (a->class >= MAX_HWRTYPES) {
+		return NULL;
+	}
+	ht = hwrtypes[a->class];
+	if (!ht) {
+		return NULL;
+	}
+	atomic_inc(&ht->count);
+	return ht->hwr_ops;
+}
+
+void put_hwrops(struct hwr_addr* a)
+{
+	struct hwrtype* ht = NULL;
+	if (a->class >= MAX_HWRTYPES) {
+		return;
+	}
+	ht = hwrtypes[a->class];
+	if (!ht) {
+		return;
+	}
+	atomic_dec(&ht->count);
+	return;
+}
+
+/*
+ * reserve_hwr checks if hwr addressed by hwr_addr is free
+ * if so, return a pointer to that hwr
+ * returns NULL otherwise.
+ * 
+ * It is like an atomic version of test and get_hwr
+ */
+struct phyhwr* reserve_hwr(struct hwr_addr* a)
+{
+        struct phyhwr *ret = NULL;
+	struct hwr_operations *ops = get_hwrops(a);
+	if (!ops) {
+	        return NULL;
+	}
+	ret = ops->reserve_hwr(a);
+	put_hwrops(a);
+        return ret;
+}
+
+void release_hwr(struct hwr_addr* a)
+{
+	struct hwr_operations *ops = get_hwrops(a);
+	if (!ops) {
+		return;
+	}
+	ops->release_hwr(a);
+	put_hwrops(a);
+	return;
+}
+
+struct hwr_iobuf* get_iobuf(struct hwr_addr* a)
+{
+        struct hwr_iobuf *ret = NULL;
+	struct hwr_operations *ops = get_hwrops(a);
+	if (!ops) {
+	        return NULL;
+	}
+	ret = ops->get_iobuf();
+	put_hwrops(a);
+        return ret;
+}
+
+ssize_t put_iobuf(struct hwr_addr* a, struct hwr_iobuf* iobuf)
+{
+        ssize_t ret = 0;
+	struct hwr_operations *ops = get_hwrops(a);
+	if (!ops) {
+	        return 0;
+	}
+	ret = ops->put_iobuf(iobuf);
+	put_hwrops(a);
+        return ret;
+}
+
+ssize_t send_iobuf(struct hwr_addr* a, struct hwr_iobuf* iobuf)
+{
+        ssize_t ret = 0;
+	struct hwr_operations *ops = get_hwrops(a);
+	if (!ops) {
+	        return 0;
+	}
+	ret = ops->send_iobuf(iobuf);
+	put_hwrops(a);
+        return ret;
+}
+
+ssize_t recv_iobuf(struct hwr_addr* a, struct hwr_iobuf* iobuf)
+{
+        ssize_t ret = 0;
+	struct hwr_operations *ops = get_hwrops(a);
+	if (!ops) {
+	        return 0;
+	}
+	ret = ops->recv_iobuf(iobuf);
+	put_hwrops(a);
+        return ret;
+}
+
+struct phyhwr* get_hwr(struct hwr_addr* a)
+{
+        /* Use global array to get phyhwr for this 
+         * class of hwr 
+         */
+	struct phyhwr* ret;
+	if (!a || a->class >= MAX_HWRTYPES) return NULL;
+	if (!hwrtypes[a->class] || a->addr >= hwrtypes[a->class]->num_devs) return NULL;
+	ret = phyhwrs[a->class][a->addr];
+	atomic_inc(&ret->count);
+	return ret;
+}
+
+void put_hwr(struct hwr_addr* a)
+{
+	struct phyhwr* hwr;
+	if (a && a->class >= MAX_HWRTYPES)
+		return;
+        if (!hwrtypes[a->class] || a->addr >= hwrtypes[a->class]->num_devs) 
+                return;
+
+	hwr = phyhwrs[a->class][a->addr];
+	if (atomic_dec_and_test(&hwr->count)) {
+		hwr->task = NULL;
+		atomic_set(&hwr->count, -1);
+	}
+}
+
+int hwr_inuse(struct hwr_addr* a)
+{
+	int ret;
+	struct phyhwr* hwr = get_hwr(a);
+	ret = (atomic_read(&hwr->active) > 0);
+	put_hwr(a);
+	return ret;
+}
+
+void hwr_activate(struct hwr_addr* a)
+{
+	struct phyhwr* hwr = get_hwr(a);
+	if (!hwr)
+		return;
+	atomic_set(&hwr->active, 1);
+	put_hwr(a);
+}
+
+void hwr_deactivate(struct hwr_addr* a)
+{
+	struct phyhwr* hwr = get_hwr(a);
+	if (!hwr)
+		return;
+	atomic_set(&hwr->active, 0);
+	put_hwr(a);
+}
+
+int register_hwrtype(struct hwrtype* ht)
+{
+	struct hwrtype* ct;
+        uint16_t i;
+
+	if (ht->type > MAX_HWRTYPES) {
+		return -1;
+	}
+	ct = hwrtypes[ht->type];
+	if (!ct) {
+	        /* Initialize phyhwr array for this hwrtype */
+                if (!phyhwrs[ht->type]) {
+		          phyhwrs[ht->type] = (struct phyhwr**) kmalloc(sizeof(struct phywr*), GFP_KERNEL);
+			  if (!phyhwrs[ht->type]) goto nomem;
+			  /* Create a phyhwr struct for each device */
+                          for (i = 0; i < ht->num_devs; i++) {
+			          phyhwrs[ht->type][i] = (struct phyhwr*) kmalloc(sizeof(struct phyhwr), GFP_KERNEL);
+			          if (!phyhwrs[ht->type][i]) goto nomem_free;		   
+			  }
+		}
+	        hwrtypes[ht->type] = ht;
+		atomic_inc(&ht->count);
+		return 0;
+	}
+	printk("register_hwrtype: type %d already registered\n", ht->type);
+        goto leave;
+ nomem_free:
+	while (i-- > 0) {
+	         if (phyhwrs[ht->type][i])
+	                 kfree(phyhwrs[ht->type][i]);
+	}
+        kfree(phyhwrs[ht->type]);
+        phyhwrs[ht->type] = NULL;
+ nomem:
+	printk("register_hwrtype: no memory to allocate phyhwr for type %d\n", ht->type);
+ leave:
+	return -1;
+}
+// EXPORT_SYMBOL(register_hwrtype);
+
+int unregister_hwrtype(struct hwrtype* ht)
+{
+	struct hwrtype* ct;
+        uint16_t i;
+
+	ct = hwrtypes[ht->type];
+	if (ct && ct->type == ht->type) {
+		if (atomic_dec_and_test(&ht->count)) {
+			hwrtypes[ht->type] = NULL;
+
+                        /* Free phyhwr memory */
+                        if (phyhwrs[ht->type]) {
+			         for (i = 0; i < ht->num_devs; i++) {
+          				   if (phyhwrs[ht->type][i])
+					            kfree(phyhwrs[ht->type][i]); 
+				 }
+			         kfree(phyhwrs[ht->type]);
+                                 phyhwrs[ht->type] = NULL;
+		        }
+			return 0;
+		}
+	}
+	return -1;
+}
+// EXPORT_SYMBOL(unregister_hwrtype);
+
+void hwr_init(void)
+{
+	/* initialize hwrtypes */
+	memset(&hwrtypes, 0, MAX_HWRTYPES*sizeof(struct hwrtype*));
+
+	/* initialize phyhwrs */
+    memset(&phyhwrs, 0, MAX_HWRTYPES*sizeof(struct phyhwr**));
+}
diff --git a/kernel/hwr/hwrtype_b2fpga.c b/kernel/hwr/hwrtype_b2fpga.c
new file mode 100644
index 0000000..5688f72
--- /dev/null
+++ b/kernel/hwr/hwrtype_b2fpga.c
@@ -0,0 +1,402 @@
+/*********************************************************************
+ * $Id: hwrtype_b2fpga.c,v 1.1 2006/10/31 07:28:57 skhay Exp $
+ * File  : hwrtype_b2fpga.c
+ * Author: Hayden Kwok-Hay So
+ * Date  : 1/16/2006
+ * Description:
+ *   Define hwrtype for BEE2 per FPGA programming
+ *********************************************************************/
+#include <linux/fs.h>
+#include <linux/module.h>
+#include <linux/slab.h>    /* kmalloc/kfree            */
+#include <linux/init.h>
+
+#include <linux/bof.h>
+#include <linux/borph.h>
+#define HDEBUG
+#define HDBG_NAME "hwrtype_b2fpga"
+#ifdef CONFIG_MKD
+# define HDBG_LVL mkd_info->dbg_lvl
+#else
+# define HDBG_LVL 9
+#endif
+#include <linux/hdebug.h>
+#include <linux/kselectmap.h>
+
+/**************************************************************************
+ * helper functions
+ **************************************************************************/
+/*
+ * thse are defined in 2.6.x, but not 2.4.x
+ */
+/*
+ * look like we don't need it in 2.6.x
+static inline void schedule_timeout_interruptible(int j)
+{
+   set_current_state(TASK_INTERRUPTIBLE);
+   schedule_timeout(j);
+}
+*/
+/**************************************************************************
+ * selectmap helper
+ **************************************************************************/
+
+static inline int selectmap_poll(selectmap_t* dev, uint32_t pin, uint32_t val)
+{
+   int count = 4;
+   uint32_t status;
+   do {
+       selectmap_in_status(dev, status);
+       PDEBUG(9, "POLL: status register = 0x%08x\n", status);
+       if ((SELECTMAP_STATUS(status) & pin) == val)
+           break;
+       schedule_timeout_interruptible(0.01*HZ);
+       count--;
+   } while (count);
+   return (count?0:-1);
+}
+
+static inline void selectmap_clear_config(selectmap_t *dev)
+{
+   u32 status;
+   selectmap_in_status(dev, status);
+   selectmap_out_status(dev, status & ~(SELMAP_PROG << 24));
+   schedule_timeout_interruptible(0.01 * HZ);
+   selectmap_out_status(dev, status | (SELMAP_PROG << 24));
+}
+
+/* HHH Old code from borph.c */
+
+#ifndef __arch_um__
+/* as of 2.4.30, asm-ppc/atomic.h doesn't define this */
+#ifndef atmoic_inc_and_test
+#define atomic_inc_and_test(v) (atomic_inc_return(v) == 0)
+#endif
+#endif
+
+/* HAC type */
+#ifdef CONFIG_ROACH
+#define HAC_TYPE HAC_ROACH
+#else
+#define HAC_TYPE HAC_BEE2FPGA
+#endif
+
+
+/*********************************************************************
+ * Hardware Region (HWR) related functions
+ *********************************************************************/
+static struct phyhwr hwr_b2fpga[SELECTMAP_NUM_DEVS];
+
+/* HHH I still have a feeling this should be part of something 
+ * specific to this hwr */
+
+/*
+ * reserve_hwr checks if hwr addressed by hwr_addr is free
+ * if so, return a pointer to that hwr
+ * returns NULL otherwise.
+ * 
+ * It is like an atomic version of test and get_hwr
+ */
+struct phyhwr* b2fpga_reserve_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* ret;
+   // HHH because soon I will move hwr_b2fpga stuff into
+   // hwrtype_b2fpga.c
+   if (a && a->class != HAC_TYPE) return NULL;
+   
+   /* safety check */
+   if (a->addr >= SELECTMAP_NUM_DEVS)
+       return NULL;
+   ret = &hwr_b2fpga[a->addr];
+   if (!atomic_inc_and_test(&ret->count)) {
+       atomic_dec(&ret->count);
+       /* was being used */
+       return NULL;
+   }
+   // count is now a usage count
+   atomic_inc(&ret->count);
+   return ret;
+}
+
+void b2fpga_release_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* hwr;
+   if (a && a->class != HAC_TYPE)
+       return;
+   if (a->addr >= SELECTMAP_NUM_DEVS) 
+       return;
+
+   hwr = &hwr_b2fpga[a->addr];
+   if (atomic_dec_and_test(&hwr->count)) {
+       hwr->task = NULL;
+       atomic_set(&hwr->count, -1);
+   }
+}
+
+struct phyhwr* b2fpga_get_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* ret;
+   if (a->addr >= SELECTMAP_NUM_DEVS)
+       return NULL;
+   ret = &hwr_b2fpga[a->addr];
+   atomic_inc(&ret->count);
+   return ret;
+}
+
+void b2fpga_put_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* hwr;
+   if (a->addr >= SELECTMAP_NUM_DEVS) 
+       return;
+
+   hwr = &hwr_b2fpga[a->addr];
+   if (atomic_dec_and_test(&hwr->count)) {
+       hwr->task = NULL;
+       atomic_set(&hwr->count, -1);
+   }
+}
+
+void __put_hwr(struct phyhwr* hwr)
+{
+   if (atomic_dec_and_test(&hwr->count)) {
+       hwr->task = NULL;
+       atomic_set(&hwr->count, -1);
+   }
+}
+
+/* New code funtions that need to be completed */
+
+static ssize_t b2fpga_send_iobuf (struct hwr_iobuf* iobuf)
+{
+        PDEBUG(9, "B2FPGA send_iobuf");
+   return 0; //HHH
+}
+
+
+static struct hwr_iobuf* b2fpga_get_iobuf(struct borph_ioreg * reg, int size)
+{
+        PDEBUG(9, "B2FPGA get_iobuf");
+   /* If there is different buffer for differ hwr, should
+    * deferentiate them here using *reg* */
+   return iobuf; //HHH
+}
+
+static ssize_t b2fpga_put_iobuf (struct hwr_iobuf* iobuf)
+{
+        PDEBUG(9, "B2FPGA put_iobuf");
+   return 0; //HHH
+}
+
+/* HHH end old code */
+
+/*****************************************************************
+ * functions definitions
+ *****************************************************************/
+#ifdef min
+#undef min
+#endif
+#define min(x, y) (x<y?x:y)
+
+/**************************************************************
+ * bee2 fpga configure/unconfigure routine
+ **************************************************************/
+
+static int configure_b2fpga(struct hwr_addr* addr, struct file* file, uint32_t offset, uint32_t len)
+{
+   selectmap_t *dev;
+   int retval = -EIO;
+   u32 status;
+   int count, i;
+
+   PDEBUG(9, "configuring bee2 fpga %u from (offset %u, len %u) of %s\n",
+          addr->addr, offset, len, file->f_dentry->d_name.name);
+   if (addr->addr >= SELECTMAP_NUM_DEVS) {
+       return -EIO;
+   }
+   if (addr->addr == 4) {
+       // HACK ALERT
+       printk("not configuring control FPGA in this hacky version\n");
+       if ((dev = get_selmapdev(addr->addr)) == NULL) {
+       return -EIO;
+       }
+       retval = 0;
+       goto done_prog;
+   }
+
+   if ((dev = get_selmapdev(addr->addr)) == NULL) {
+       return -EIO;
+   }
+
+   retval = -EIO;
+   PDEBUG(9, "set selectmap to config mode\n");
+   selectmap_set_cfgmode(dev);
+
+   // to configure, first need to cycle assert/deassert PROG_N
+   PDEBUG(9, "pulse prog_n\n");
+   selectmap_clear_config(dev);
+
+   // poll till INIT pin is asserted from FPGA
+   PDEBUG(9, "poll init_n\n");
+   if (selectmap_poll(dev, SELMAP_INIT, SELMAP_INIT) < 0) {
+       goto out;
+   }
+   PDEBUG(9, "done polling init_n\n");
+
+   // now, stream data to selectmap
+   while (len > 0) {
+       buf_t *bufp;
+#if defined(__arch_um__)
+       break;
+#endif
+       count = min(SELECTMAP_BUFSIZE, len);
+       retval = kernel_read(file, offset, dev->buf, count);
+       bufp = dev->buf;
+       if (retval < 0) {
+           goto out;
+       }
+       if (retval != count) {
+           printk("kernel_read returns less than requested...\n");
+           count = retval;
+       }
+
+       len -= count;
+       offset += count;
+
+       /* we have count bytes in dev->buf to write */
+       i = 0; retval = -EIO;
+       selectmap_in_status(dev, status);
+       PDEBUG(10, "count = %d, buf[0 1 2 3]=%02x %02x %02x %02x\n", 
+              count, dev->buf[0], dev->buf[1], dev->buf[2], 
+              dev->buf[3]);
+       while(count > 0) {
+           selectmap_out_data(dev, dev->buf[i]);
+           i++;
+           count -= 1;
+       }
+   }
+
+   // poll till DONE pin is asserted from FPGA
+   PDEBUG(9, "poll done\n");
+   if (selectmap_poll(dev, SELMAP_DONE, SELMAP_DONE) < 0) {
+       PDEBUG(9, "polling done returns error\n");
+       goto out;
+   }
+   PDEBUG(9, "finished polling done\n");
+   retval = 0;
+ done_prog:
+   /* synchronizing read */
+   /*
+   PDEBUG(9, "Synchronizing read. It should work with the new selectmap\n");
+   selectmap_set_fifomode(dev);
+   selectmap_in_data(dev, status);
+   */
+   /* flush fifo, just to be safe
+    * Note that the current version of opb_selectmap v1.01a needs a
+    * synchronizing read too */
+   PDEBUG(9, "flush fifo + synch readnow\n");
+   selectmap_set_fifomode(dev);
+   /* synchronization read */
+   selectmap_in_data(dev, status);
+   /* flushing loop */
+   for (i = 0; i < 10; i++) {
+       selectmap_in_status(dev, status);
+       PDEBUG(9, "status register = 0x%08x\n", status);
+       count = SELECTMAP_RFIFO_CNT(status);
+       if (!count) break;
+       PDEBUG(9, "has %d words in fifo, flush them\n", count);
+       while (count--) {
+       selectmap_in_data(dev, status);
+       }
+   }
+   if (i == 10) {
+       PDEBUG(9, "I have flushed the fifo 10 times yet it still has stuff in it.. what?\n");
+   }
+ out:
+   put_selmapdev(dev);
+   return retval;
+}
+
+static int unconfigure_b2fpga(struct hwr_addr* addr)
+{
+   selectmap_t *dev;
+
+   printk("unconfigure bee2 fpga %u\n", addr->addr);
+   if (addr->addr >= SELECTMAP_NUM_DEVS) {
+       return -EIO;
+   }
+
+   if ((dev = get_selmapdev(addr->addr)) == NULL) {
+       return -EIO;
+   }
+   /* Send Greet message */
+   selectmap_out_data(dev, PP_CMD_BYE);
+   selectmap_out_data(dev, 0x55);
+   selectmap_out_data(dev, 0xAA);
+   selectmap_out_data(dev, 0xFF);
+
+   // HACK ALERT
+   if (addr->addr != 4) {
+       selectmap_clear_config(dev);
+   }
+
+   put_selmapdev(dev);
+
+   return 0;
+}
+
+static struct hwr_operations b2fpga_hwr_operations = {
+   configure: configure_b2fpga,
+   unconfigure: unconfigure_b2fpga,
+        reserve_hwr: b2fpga_reserve_hwr,
+        release_hwr: b2fpga_release_hwr,
+        get_iobuf: b2fpga_get_iobuf,
+        put_iobuf: b2fpga_put_iobuf,
+        send_iobuf: b2fpga_send_iobuf
+};
+
+static struct hwrtype hwrtype_b2fpga = {
+   name: "b2fpga",
+   type: HAC_B2FPGA,
+   count: ATOMIC_INIT(0),
+        num_devs: SELECTMAP_NUM_DEVS,
+   hwr_ops: &b2fpga_hwr_operations,
+};
+
+static int __init hwrtype_b2fpga_init(void)
+{
+   int retval = 0;
+
+   if ((retval = register_hwrtype(&hwrtype_b2fpga)) < 0) {
+       printk("Error registering hwrtype\n");
+       goto out;
+   } else {
+       printk("hwrtype_b2fpga version CVS-$Revision: 1.1 $ registered\n");
+   }
+/** HHH untested below **/
+   /* initialize hwr array */
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       atomic_set(&(hwr_b2fpga[i]).count, -1);
+   }
+
+   if (kselectmap_init()) return;
+/** HHH untested above **/
+
+ out:
+   return retval;
+}
+
+static void __exit hwrtype_b2fpga_exit(void)
+{
+   if (unregister_hwrtype(&hwrtype_b2fpga)) {
+       printk("Error unregistering hwrtyp\n");
+   } else {
+       printk("hwrtype_b2fpga CVS-$Revision: 1.1 $ unregistered\n");
+   }
+}
+
+module_init(hwrtype_b2fpga_init);
+module_exit(hwrtype_b2fpga_exit);
+
+MODULE_AUTHOR("Hayden So");
+MODULE_DESCRIPTION("Add hwrtype b2fpga to program FPGA on B2 as hw process");
+MODULE_LICENSE("GPL");
\ No newline at end of file
diff --git a/kernel/hwr/hwrtype_netfpga.c b/kernel/hwr/hwrtype_netfpga.c
new file mode 100644
index 0000000..79efb1e
--- /dev/null
+++ b/kernel/hwr/hwrtype_netfpga.c
@@ -0,0 +1,2955 @@
+/*********************************************************************
+ * $Id: 
+ * File  : hwrtype_netfpga.c
+ * Author: Brandon Hamilton
+ * Date  : 27 May 2009 
+ * Description:
+ *   Define hwrtype for NetFPGA board
+ *********************************************************************/
+#include <linux/version.h>
+
+#include <linux/fs.h>
+#include <linux/module.h>
+#include <linux/slab.h>    /* kmalloc/kfree            */
+#include <linux/init.h>
+#include <asm/uaccess.h>   /* copy_from_user */
+#include <linux/ioport.h>  /* request_mem_region */
+#include <linux/pci.h>
+
+#include <linux/netdevice.h>   /* struct device, and other headers */
+#include <linux/etherdevice.h> /* eth_type_trans */
+#include <linux/if_ether.h>
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,19))
+#include <asm/semaphore.h>
+#else
+#include <linux/semaphore.h>
+#endif
+
+#include <linux/ioctl.h>
+
+#include <linux/bof.h>
+#include <linux/borph.h>
+#define HDEBUG
+#define HDBG_NAME "hwrtype_netfpga"
+#ifdef CONFIG_MKD
+# define HDBG_LVL mkd_info->dbg_lvl
+#else
+# define HDBG_LVL 9
+#endif
+#include <linux/hdebug.h>
+
+#ifdef CONFIG_RESOURCES_64BIT
+#define RESOURCE_SUFFIX(a) U64_C(a)
+#else
+#define RESOURCE_SUFFIX(a) U32_C(a)
+#endif
+
+#include "nf2.h"
+#include "nf2kernel.h"
+
+#define DEFAULT_IFACE  "nf2c0"
+#define PATHLEN        80
+
+#define READ_BUFFER_SIZE 4096
+#define SUCCESS 0
+#define FAILURE 1
+
+#define CPCI_PROGRAMMING_DATA    0x100
+#define CPCI_PROGRAMMING_STATUS  0x104
+#define CPCI_PROGRAMMING_CONTROL 0x108
+#define CPCI_ERROR               0x010
+#define CPCI_ID                     0x000
+#define CPCI_CTRL                0x008
+
+#define START_PROGRAMMING        0x00000001
+#define DISABLE_RESET            0x00000100
+
+#define VIRTEX_PROGRAM_CTRL_ADDR        0x0440000
+#define VIRTEX_PROGRAM_RAM_BASE_ADDR    0x0480000
+
+#define CPCI_BIN_SIZE            166980
+
+#define VIRTEX_BIN_SIZE_V2_0     1448740
+#define VIRTEX_BIN_SIZE_V2_1     2377668
+
+/* Some device specific definitions */
+
+/*
+ * pci_device_id - table of Vendor and Device IDs for the kernel to match
+ *                 to identify the card(s) supported by this driver
+ */
+static struct pci_device_id ids[] = {
+   { PCI_DEVICE(PCI_VENDOR_ID_STANFORD, PCI_DEVICE_ID_STANFORD_NF2), },
+   { 0, }
+};
+MODULE_DEVICE_TABLE(pci, ids);
+
+/*
+ * A static buffer for data transfer.  It should be expanded to a 
+ * kmem_cache when higher performance is needed.  (Right now, there
+ * can only be one ioreg performing I/O at a time.
+ */
+static buf_t* netfpga_page;
+static struct hwr_iobuf* iobuf;
+
+/* Mutex Semaphore to ensure proper access to page buffer */
+static DECLARE_MUTEX(netfpga_mutex);
+
+/*****************************************************************
+ * parameters
+ *****************************************************************/
+
+/*
+ * Timeout parameter
+ */
+int timeout = NF2_TIMEOUT;
+
+/*
+ * Size of receive buffer pool
+ */
+int rx_pool_size = NUM_RX_BUFFS;
+
+/*
+ * Size of transmit buffer pool
+ */
+int tx_pool_size = NUM_TX_BUFFS;
+
+/*
+ * Major and minor device numbers. Defaults to dynamic allocation.
+ */
+
+int nf2_major = NF2_MAJOR;
+int nf2_minor = 0;
+
+/*
+ * NetFPGA device parameters
+ */
+
+static struct net_device *nf2_dev;
+
+/*****************************************************************
+ * NETFPGA definitions
+ *****************************************************************/
+
+/* ========== CPCI Defines ========== */
+#define CPCI_ID_REG                             0x0000000
+#define CPCI_BOARD_ID_REG                       0x0000004
+#define CPCI_CONTROL_REG                        0x0000008
+#define CPCI_RESET_REG                          0x000000c
+#define CPCI_ERROR_REG                          0x0000010
+
+#define CPCI_DUMMY_REG                          0x0000020
+
+#define CPCI_INTERRUPT_MASK_REG                 0x0000040
+#define CPCI_INTERRUPT_STATUS_REG               0x0000044
+
+#define CPCI_CNET_CLK_SEL_REG                   0x0000050
+
+#define CPCI_REPROG_DATA_REG                    0x0000100
+#define CPCI_REPROG_STATUS_REG                  0x0000104
+#define CPCI_REPROG_CTRL_REG                    0x0000108
+
+#define CPCI_DMA_ADDR_I_REG                     0x0000140
+#define CPCI_DMA_ADDR_E_REG                     0x0000144
+#define CPCI_DMA_SIZE_I_REG                     0x0000148
+#define CPCI_DMA_SIZE_E_REG                     0x000014c
+#define CPCI_DMA_CTRL_I_REG                     0x0000150
+#define CPCI_DMA_CTRL_E_REG                     0x0000154
+#define CPCI_DMA_XFER_TIME_REG                  0x0000180
+#define CPCI_DMA_RETRIES_REG                    0x0000184
+
+#define CPCI_CNET_READ_TIME_REG                 0x0000188
+
+#define CPCI_DMA_INGRESS_PKT_CNT_REG            0x0000400
+#define CPCI_DMA_EGRESS_PKT_CNT_REG             0x0000404
+#define CPCI_CPCI_REG_READ_CNT_REG              0x0000408
+#define CPCI_CPCI_REG_WRITE_CNT_REG             0x000040c
+#define CPCI_CNET_REG_READ_CNT_REG              0x0000410
+#define CPCI_CNET_REG_WRITE_CNT_REG             0x0000414
+
+#define CPCI_CLOCK_CHECK_N_CLK_REG              0x0000500
+#define CPCI_CLOCK_CHECK_P_MAX_REG              0x0000504
+#define CPCI_CLOCK_CHECK_N_EXP_REG              0x0000508
+#define CPCI_PCI_CLK_COUNTER_REG                0x0000510
+#define CPCI_CPCI_RESET_COUNTER_REG             0x0000520
+
+#define CPCI_DMA_XFER_TIME_DEFAULT              0x00000fa0
+#define CPCI_DMA_RETRIES_DEFAULT                0xffff
+#define CPCI_CNET_READ_TIME_DEFAULT             0x00000fa0
+
+
+#define TX_QUEUE_DISABLE_BIT_NUM                            0
+#define RX_QUEUE_DISABLE_BIT_NUM                            1
+#define RESET_MAC_BIT_NUM                                   2
+#define MAC_DISABLE_TX_BIT_NUM                              3
+#define MAC_DISABLE_RX_BIT_NUM                              4
+#define MAC_DIS_JUMBO_TX_BIT_NUM                            5
+#define MAC_DIS_JUMBO_RX_BIT_NUM                            6
+#define MAC_DIS_CRC_CHECK                                   7
+#define MAC_DIS_CRC_GEN                                     8
+
+#define DEVICE_MD5_1_REG                                     0x0400000
+#define DEVICE_MD5_2_REG                                     0x0400004
+#define DEVICE_MD5_3_REG                                     0x0400008
+#define DEVICE_MD5_4_REG                                     0x040000c
+#define DEVICE_ID_REG                                        0x0400010
+#define DEVICE_REVISION_REG                                  0x0400014
+#define DEVICE_CPCI_ID_REG                                   0x0400018
+#define DEVICE_STR_REG                                       0x040001c
+
+#define DEVICE_MD5_1_VAL                                     0x4071736d
+#define DEVICE_MD5_2_VAL                                     0x8a603d2b
+#define DEVICE_MD5_3_VAL                                     0x4d55f629
+#define DEVICE_MD5_4_VAL                                     0x89a73c95
+
+#define SRAM_BASE_ADDR_REG                                   0x1000000
+#define SRAM_ADDR_WIDTH                                           19
+
+#define MAC_GRP_0_CONTROL_REG                                0x0600000
+#define RX_QUEUE_0_NUM_PKTS_STORED_REG                       0x0600004
+#define RX_QUEUE_0_NUM_PKTS_DROPPED_FULL_REG                 0x0600008
+#define RX_QUEUE_0_NUM_PKTS_DROPPED_BAD_REG                  0x060000c
+#define RX_QUEUE_0_NUM_WORDS_PUSHED_REG                      0x0600010
+#define RX_QUEUE_0_NUM_BYTES_PUSHED_REG                      0x0600014
+#define RX_QUEUE_0_NUM_PKTS_DEQUEUED_REG                     0x060002c
+#define RX_QUEUE_0_NUM_PKTS_IN_QUEUE_REG                     0x0600030
+#define TX_QUEUE_0_NUM_PKTS_IN_QUEUE_REG                     0x0600018
+#define TX_QUEUE_0_NUM_PKTS_SENT_REG                         0x060001c
+#define TX_QUEUE_0_NUM_WORDS_PUSHED_REG                      0x0600020
+#define TX_QUEUE_0_NUM_BYTES_PUSHED_REG                      0x0600024
+#define TX_QUEUE_0_NUM_PKTS_ENQUEUED_REG                     0x0600028
+
+#define MAC_GRP_1_CONTROL_REG                                0x0640000
+#define RX_QUEUE_1_NUM_PKTS_STORED_REG                       0x0640004
+#define RX_QUEUE_1_NUM_PKTS_DROPPED_FULL_REG                 0x0640008
+#define RX_QUEUE_1_NUM_PKTS_DROPPED_BAD_REG                  0x064000c
+#define RX_QUEUE_1_NUM_WORDS_PUSHED_REG                      0x0640010
+#define RX_QUEUE_1_NUM_BYTES_PUSHED_REG                      0x0640014
+#define RX_QUEUE_1_NUM_PKTS_DEQUEUED_REG                     0x064002c
+#define RX_QUEUE_1_NUM_PKTS_IN_QUEUE_REG                     0x0640030
+#define TX_QUEUE_1_NUM_PKTS_IN_QUEUE_REG                     0x0640018
+#define TX_QUEUE_1_NUM_PKTS_SENT_REG                         0x064001c
+#define TX_QUEUE_1_NUM_WORDS_PUSHED_REG                      0x0640020
+#define TX_QUEUE_1_NUM_BYTES_PUSHED_REG                      0x0640024
+#define TX_QUEUE_1_NUM_PKTS_ENQUEUED_REG                     0x0640028
+
+#define MAC_GRP_2_CONTROL_REG                                0x0680000
+#define RX_QUEUE_2_NUM_PKTS_STORED_REG                       0x0680004
+#define RX_QUEUE_2_NUM_PKTS_DROPPED_FULL_REG                 0x0680008
+#define RX_QUEUE_2_NUM_PKTS_DROPPED_BAD_REG                  0x068000c
+#define RX_QUEUE_2_NUM_WORDS_PUSHED_REG                      0x0680010
+#define RX_QUEUE_2_NUM_BYTES_PUSHED_REG                      0x0680014
+#define RX_QUEUE_2_NUM_PKTS_DEQUEUED_REG                     0x068002c
+#define RX_QUEUE_2_NUM_PKTS_IN_QUEUE_REG                     0x0680030
+#define TX_QUEUE_2_NUM_PKTS_IN_QUEUE_REG                     0x0680018
+#define TX_QUEUE_2_NUM_PKTS_SENT_REG                         0x068001c
+#define TX_QUEUE_2_NUM_WORDS_PUSHED_REG                      0x0680020
+#define TX_QUEUE_2_NUM_BYTES_PUSHED_REG                      0x0680024
+#define TX_QUEUE_2_NUM_PKTS_ENQUEUED_REG                     0x0680028
+
+#define MAC_GRP_3_CONTROL_REG                                0x06c0000
+#define RX_QUEUE_3_NUM_PKTS_STORED_REG                       0x06c0004
+#define RX_QUEUE_3_NUM_PKTS_DROPPED_FULL_REG                 0x06c0008
+#define RX_QUEUE_3_NUM_PKTS_DROPPED_BAD_REG                  0x06c000c
+#define RX_QUEUE_3_NUM_WORDS_PUSHED_REG                      0x06c0010
+#define RX_QUEUE_3_NUM_BYTES_PUSHED_REG                      0x06c0014
+#define RX_QUEUE_3_NUM_PKTS_DEQUEUED_REG                     0x06c002c
+#define RX_QUEUE_3_NUM_PKTS_IN_QUEUE_REG                     0x06c0030
+#define TX_QUEUE_3_NUM_PKTS_IN_QUEUE_REG                     0x06c0018
+#define TX_QUEUE_3_NUM_PKTS_SENT_REG                         0x06c001c
+#define TX_QUEUE_3_NUM_WORDS_PUSHED_REG                      0x06c0020
+#define TX_QUEUE_3_NUM_BYTES_PUSHED_REG                      0x06c0024
+#define TX_QUEUE_3_NUM_PKTS_ENQUEUED_REG                     0x06c0028
+
+#define CPU_REG_Q_0_WR_DATA_WORD_REG                         0x0700000
+#define CPU_REG_Q_0_WR_CTRL_WORD_REG                         0x0700004
+#define CPU_REG_Q_0_WR_NUM_WORDS_LEFT_REG                    0x0700008
+#define CPU_REG_Q_0_WR_NUM_PKTS_IN_Q_REG                     0x070000c
+#define CPU_REG_Q_0_RD_DATA_WORD_REG                         0x0700010
+#define CPU_REG_Q_0_RD_CTRL_WORD_REG                         0x0700014
+#define CPU_REG_Q_0_RD_NUM_WORDS_AVAIL_REG                   0x0700018
+#define CPU_REG_Q_0_RD_NUM_PKTS_IN_Q_REG                     0x070001c
+#define CPU_REG_Q_0_RX_NUM_PKTS_RCVD_REG                     0x0700020
+#define CPU_REG_Q_0_TX_NUM_PKTS_SENT_REG                     0x0700024
+#define CPU_REG_Q_0_RX_NUM_WORDS_RCVD_REG                    0x0700028
+#define CPU_REG_Q_0_TX_NUM_WORDS_SENT_REG                    0x070002c
+#define CPU_REG_Q_0_RX_NUM_BYTES_RCVD_REG                    0x0700030
+#define CPU_REG_Q_0_TX_NUM_BYTES_SENT_REG                    0x0700034
+
+#define CPU_REG_Q_1_WR_DATA_WORD_REG                         0x0740000
+#define CPU_REG_Q_1_WR_CTRL_WORD_REG                         0x0740004
+#define CPU_REG_Q_1_WR_NUM_WORDS_LEFT_REG                    0x0740008
+#define CPU_REG_Q_1_WR_NUM_PKTS_IN_Q_REG                     0x074000c
+#define CPU_REG_Q_1_RD_DATA_WORD_REG                         0x0740010
+#define CPU_REG_Q_1_RD_CTRL_WORD_REG                         0x0740014
+#define CPU_REG_Q_1_RD_NUM_WORDS_AVAIL_REG                   0x0740018
+#define CPU_REG_Q_1_RD_NUM_PKTS_IN_Q_REG                     0x074001c
+#define CPU_REG_Q_1_RX_NUM_PKTS_RCVD_REG                     0x0740020
+#define CPU_REG_Q_1_TX_NUM_PKTS_SENT_REG                     0x0740024
+#define CPU_REG_Q_1_RX_NUM_WORDS_RCVD_REG                    0x0740028
+#define CPU_REG_Q_1_TX_NUM_WORDS_SENT_REG                    0x074002c
+#define CPU_REG_Q_1_RX_NUM_BYTES_RCVD_REG                    0x0740030
+#define CPU_REG_Q_1_TX_NUM_BYTES_SENT_REG                    0x0740034
+
+#define CPU_REG_Q_2_WR_DATA_WORD_REG                         0x0780000
+#define CPU_REG_Q_2_WR_CTRL_WORD_REG                         0x0780004
+#define CPU_REG_Q_2_WR_NUM_WORDS_LEFT_REG                    0x0780008
+#define CPU_REG_Q_2_WR_NUM_PKTS_IN_Q_REG                     0x078000c
+#define CPU_REG_Q_2_RD_DATA_WORD_REG                         0x0780010
+#define CPU_REG_Q_2_RD_CTRL_WORD_REG                         0x0780014
+#define CPU_REG_Q_2_RD_NUM_WORDS_AVAIL_REG                   0x0780018
+#define CPU_REG_Q_2_RD_NUM_PKTS_IN_Q_REG                     0x078001c
+#define CPU_REG_Q_2_RX_NUM_PKTS_RCVD_REG                     0x0780020
+#define CPU_REG_Q_2_TX_NUM_PKTS_SENT_REG                     0x0780024
+#define CPU_REG_Q_2_RX_NUM_WORDS_RCVD_REG                    0x0780028
+#define CPU_REG_Q_2_TX_NUM_WORDS_SENT_REG                    0x078002c
+#define CPU_REG_Q_2_RX_NUM_BYTES_RCVD_REG                    0x0780030
+#define CPU_REG_Q_2_TX_NUM_BYTES_SENT_REG                    0x0780034
+
+#define CPU_REG_Q_3_WR_DATA_WORD_REG                         0x07c0000
+#define CPU_REG_Q_3_WR_CTRL_WORD_REG                         0x07c0004
+#define CPU_REG_Q_3_WR_NUM_WORDS_LEFT_REG                    0x07c0008
+#define CPU_REG_Q_3_WR_NUM_PKTS_IN_Q_REG                     0x07c000c
+#define CPU_REG_Q_3_RD_DATA_WORD_REG                         0x07c0010
+#define CPU_REG_Q_3_RD_CTRL_WORD_REG                         0x07c0014
+#define CPU_REG_Q_3_RD_NUM_WORDS_AVAIL_REG                   0x07c0018
+#define CPU_REG_Q_3_RD_NUM_PKTS_IN_Q_REG                     0x07c001c
+#define CPU_REG_Q_3_RX_NUM_PKTS_RCVD_REG                     0x07c0020
+#define CPU_REG_Q_3_TX_NUM_PKTS_SENT_REG                     0x07c0024
+#define CPU_REG_Q_3_RX_NUM_WORDS_RCVD_REG                    0x07c0028
+#define CPU_REG_Q_3_TX_NUM_WORDS_SENT_REG                    0x07c002c
+#define CPU_REG_Q_3_RX_NUM_BYTES_RCVD_REG                    0x07c0030
+#define CPU_REG_Q_3_TX_NUM_BYTES_SENT_REG                    0x07c0034
+
+#define CLK_SYN_0_COUNTER_RESET                              0x0500028
+#define CLK_SYN_0_TX_LO_REG                                  0x050002c
+#define CLK_SYN_0_TX_HI_REG                                  0x0500030
+#define CLK_SYN_0_RX_LO_REG                                  0x0500034
+#define CLK_SYN_0_RX_HI_REG                                  0x0500038
+#define CLK_SYN_1_COUNTER_RESET                              0x050003c
+#define CLK_SYN_1_TX_LO_REG                                  0x0500040
+#define CLK_SYN_1_TX_HI_REG                                  0x0500044
+#define CLK_SYN_1_RX_LO_REG                                  0x0500048
+#define CLK_SYN_1_RX_HI_REG                                  0x050004c
+#define CLK_SYN_2_COUNTER_RESET                              0x0500050
+#define CLK_SYN_2_TX_LO_REG                                  0x0500054
+#define CLK_SYN_2_TX_HI_REG                                  0x0500058
+#define CLK_SYN_2_RX_LO_REG                                  0x050005c
+#define CLK_SYN_2_RX_HI_REG                                  0x0500060
+#define CLK_SYN_3_COUNTER_RESET                              0x0500064
+#define CLK_SYN_3_TX_LO_REG                                  0x0500068
+#define CLK_SYN_3_TX_HI_REG                                  0x050006c
+#define CLK_SYN_3_RX_LO_REG                                  0x0500070
+#define CLK_SYN_3_RX_HI_REG                                  0x0500074
+#define PTP_VALID_RX_REG                                     0x0500078
+#define PTP_VALID_TX_REG                                     0x050007c
+#define PTP_ENABLE_MASK_RX_REG                               0x0500080
+#define PTP_ENABLE_MASK_TX_REG                               0x0500084
+#define PTP_MASK_RX_REG                                      0x0500088
+#define PTP_MASK_TX_REG                                      0x050008c
+#define DMA_TX_QUE_0_REG                                     0x0480000
+#define DMA_TX_QUE_0_LAST_1_BYTE_REG                         0x0480004
+#define DMA_TX_QUE_0_LAST_2_BYTE_REG                         0x0480008
+#define DMA_TX_QUE_0_LAST_3_BYTE_REG                         0x048000c
+#define DMA_TX_QUE_0_LAST_4_BYTE_REG                         0x0480010
+
+#define DMA_TX_QUE_1_REG                                     0x0480040
+#define DMA_TX_QUE_1_LAST_1_BYTE_REG                         0x0480044
+#define DMA_TX_QUE_1_LAST_2_BYTE_REG                         0x0480048
+#define DMA_TX_QUE_1_LAST_3_BYTE_REG                         0x048004c
+#define DMA_TX_QUE_1_LAST_4_BYTE_REG                         0x0480050
+
+#define DMA_TX_QUE_2_REG                                     0x0480080
+#define DMA_TX_QUE_2_LAST_1_BYTE_REG                         0x0480084
+#define DMA_TX_QUE_2_LAST_2_BYTE_REG                         0x0480088
+#define DMA_TX_QUE_2_LAST_3_BYTE_REG                         0x048008c
+#define DMA_TX_QUE_2_LAST_4_BYTE_REG                         0x0480090
+
+#define DMA_TX_QUE_3_REG                                     0x04800c0
+#define DMA_TX_QUE_3_LAST_1_BYTE_REG                         0x04800c4
+#define DMA_TX_QUE_3_LAST_2_BYTE_REG                         0x04800c8
+#define DMA_TX_QUE_3_LAST_3_BYTE_REG                         0x04800cc
+#define DMA_TX_QUE_3_LAST_4_BYTE_REG                         0x04800d0
+
+#define MDIO_0_CONTROL_REG                                   0x04c0000
+#define MDIO_0_STATUS_REG                                    0x04c0004
+#define MDIO_0_PHY_ID_0_REG                                  0x04c0008
+#define MDIO_0_PHY_ID_1_REG                                  0x04c000c
+#define MDIO_0_AUTONEGOTIATION_ADVERT_REG                    0x04c0010
+#define MDIO_0_AUTONEG_LINK_PARTNER_BASE_PAGE_ABILITY_REG    0x04c0014
+#define MDIO_0_AUTONEG_EXPANSION_REG                         0x04c0018
+#define MDIO_0_AUTONEG_NEXT_PAGE_TX_REG                      0x04c001c
+#define MDIO_0_AUTONEG_LINK_PARTNER_RCVD_NEXT_PAGE_REG       0x04c0020
+#define MDIO_0_MASTER_SLAVE_CTRL_REG                         0x04c0024
+#define MDIO_0_MASTER_SLAVE_STATUS_REG                       0x04c0028
+#define MDIO_0_PSE_CTRL_REG                                  0x04c002c
+#define MDIO_0_PSE_STATUS_REG                                0x04c0030
+#define MDIO_0_MMD_ACCESS_CTRL_REG                           0x04c0034
+#define MDIO_0_MMD_ACCESS_STATUS_REG                         0x04c0038
+#define MDIO_0_EXTENDED_STATUS_REG                           0x04c003c
+#define MDIO_0_INTERRUPT_MASK_REG                            0x04c006c
+
+#define MDIO_1_CONTROL_REG                                   0x04c0080
+#define MDIO_1_STATUS_REG                                    0x04c0084
+#define MDIO_1_PHY_ID_0_REG                                  0x04c0088
+#define MDIO_1_PHY_ID_1_REG                                  0x04c008c
+#define MDIO_1_AUTONEGOTIATION_ADVERT_REG                    0x04c0090
+#define MDIO_1_AUTONEG_LINK_PARTNER_BASE_PAGE_ABILITY_REG    0x04c0094
+#define MDIO_1_AUTONEG_EXPANSION_REG                         0x04c0098
+#define MDIO_1_AUTONEG_NEXT_PAGE_TX_REG                      0x04c009c
+#define MDIO_1_AUTONEG_LINK_PARTNER_RCVD_NEXT_PAGE_REG       0x04c00a0
+#define MDIO_1_MASTER_SLAVE_CTRL_REG                         0x04c00a4
+#define MDIO_1_MASTER_SLAVE_STATUS_REG                       0x04c00a8
+#define MDIO_1_PSE_CTRL_REG                                  0x04c00ac
+#define MDIO_1_PSE_STATUS_REG                                0x04c00b0
+#define MDIO_1_MMD_ACCESS_CTRL_REG                           0x04c00b4
+#define MDIO_1_MMD_ACCESS_STATUS_REG                         0x04c00b8
+#define MDIO_1_EXTENDED_STATUS_REG                           0x04c00bc
+#define MDIO_1_INTERRUPT_MASK_REG                            0x04c00ec
+
+#define MDIO_2_CONTROL_REG                                   0x04c0100
+#define MDIO_2_STATUS_REG                                    0x04c0104
+#define MDIO_2_PHY_ID_0_REG                                  0x04c0108
+#define MDIO_2_PHY_ID_1_REG                                  0x04c010c
+#define MDIO_2_AUTONEGOTIATION_ADVERT_REG                    0x04c0110
+#define MDIO_2_AUTONEG_LINK_PARTNER_BASE_PAGE_ABILITY_REG    0x04c0114
+#define MDIO_2_AUTONEG_EXPANSION_REG                         0x04c0118
+#define MDIO_2_AUTONEG_NEXT_PAGE_TX_REG                      0x04c011c
+#define MDIO_2_AUTONEG_LINK_PARTNER_RCVD_NEXT_PAGE_REG       0x04c0120
+#define MDIO_2_MASTER_SLAVE_CTRL_REG                         0x04c0124
+#define MDIO_2_MASTER_SLAVE_STATUS_REG                       0x04c0128
+#define MDIO_2_PSE_CTRL_REG                                  0x04c012c
+#define MDIO_2_PSE_STATUS_REG                                0x04c0130
+#define MDIO_2_MMD_ACCESS_CTRL_REG                           0x04c0134
+#define MDIO_2_MMD_ACCESS_STATUS_REG                         0x04c0138
+#define MDIO_2_EXTENDED_STATUS_REG                           0x04c013c
+#define MDIO_2_INTERRUPT_MASK_REG                            0x04c016c
+
+#define MDIO_3_CONTROL_REG                                   0x04c0180
+#define MDIO_3_STATUS_REG                                    0x04c0184
+#define MDIO_3_PHY_ID_0_REG                                  0x04c0188
+#define MDIO_3_PHY_ID_1_REG                                  0x04c018c
+#define MDIO_3_AUTONEGOTIATION_ADVERT_REG                    0x04c0190
+#define MDIO_3_AUTONEG_LINK_PARTNER_BASE_PAGE_ABILITY_REG    0x04c0194
+#define MDIO_3_AUTONEG_EXPANSION_REG                         0x04c0198
+#define MDIO_3_AUTONEG_NEXT_PAGE_TX_REG                      0x04c019c
+#define MDIO_3_AUTONEG_LINK_PARTNER_RCVD_NEXT_PAGE_REG       0x04c01a0
+#define MDIO_3_MASTER_SLAVE_CTRL_REG                         0x04c01a4
+#define MDIO_3_MASTER_SLAVE_STATUS_REG                       0x04c01a8
+#define MDIO_3_PSE_CTRL_REG                                  0x04c01ac
+#define MDIO_3_PSE_STATUS_REG                                0x04c01b0
+#define MDIO_3_MMD_ACCESS_CTRL_REG                           0x04c01b4
+#define MDIO_3_MMD_ACCESS_STATUS_REG                         0x04c01b8
+#define MDIO_3_EXTENDED_STATUS_REG                           0x04c01bc
+#define MDIO_3_INTERRUPT_MASK_REG                            0x04c01ec
+
+#define STAMP_COUNTER_1_REG                                  0x0500000
+#define STAMP_COUNTER_2_REG                                  0x0500004
+#define STAMP_COUNTER_3_REG                                  0x0500008
+#define STAMP_COUNTER_4_REG                                  0x050000c
+#define STAMP_COUNTER_1_2_REG_LOAD                           0x0500010
+#define STAMP_COUNTER_3_4_REG_LOAD                           0x0500014
+
+#define STAMP_COUNTER_READ_ENABLE                            0x0500024
+
+#define STAMP_COUNTER_BIT_95_64                              0x0500018
+
+#define STAMP_COUNTER_BIT_63_32                              0x050001c
+
+#define STAMP_COUNTER_BIT_31_0                               0x0500020
+
+#define PHY_RST_BIT_POS                              15
+#define PHY_LOOPBACK_BIT_POS                         14
+#define PHY_SPEED_SEL_LO_BIT_POS                     13
+#define PHY_AUTONEG_ENABLE_BIT_POS                   12
+#define PHY_PWR_DOWN_BIT_POS                         11
+#define PHY_ISOLATE_BIT_POS                          10
+#define PHY_RESTART_AUTONEG_BIT_POS                   9
+#define PHY_DUPLEX_MODE_BIT_POS                       8
+#define PHY_COLLISION_TEST_BIT_POS                    7
+#define PHY_SPEED_SEL_HI_BIT_POS                      6
+#define PHY_UNIDIR_ENABLE_BIT_POS                     5
+
+#define PHY_100BASE_T4_BIT_POS                       15
+#define PHY_100BASE_X_FULL_DPLX_BIT_POS              14
+#define PHY_100BASE_X_HALF_DPLX_BIT_POS              13
+#define PHY_10MBPS_FULL_DPLX_BIT_POS                 12
+#define PHY_10MBPS_HALF_DPLX_BIT_POS                 11
+#define PHY_100BASE_T2_FULL_DPLX_BIT_POS             10
+#define PHY_100BASE_T2_HALF_DPLX_BIT_POS              9
+#define PHY_EXTENDED_STATUS_BIT_POS                   8
+#define PHY_UNIDIR_ABILITY_BIT_POS                    7
+#define PHY_MF_PREAMBLE_SPRSN_BIT_POS                 6
+#define PHY_AUTONEG_COMPLETE_BIT_POS                  5
+#define PHY_REMOTE_FAULT_BIT_POS                      4
+#define PHY_AUTONEG_ABILITY_BIT_POS                   3
+#define PHY_LINK_STATUS_BIT_POS                       2
+#define PHY_JABBER_DETECT_BIT_POS                     1
+#define PHY_EXTENDED_CAPABILITY_BIT_POS               0
+
+#define CLK_TEST_TICKS_REG                    0x0880000
+#define SERIAL_TEST_CONTROL_0_REG             0x08c0000
+#define SERIAL_TEST_STATUS_0_REG              0x08c0004
+#define SERIAL_TEST_NUM_FRAMES_SENT_0_LO_REG  0x08c0008
+#define SERIAL_TEST_NUM_FRAMES_RCVD_0_LO_REG  0x08c000c
+#define SERIAL_TEST_NUM_FRAMES_SENT_0_HI_REG  0x08c0010
+#define SERIAL_TEST_NUM_FRAMES_RCVD_0_HI_REG  0x08c0014
+#define SERIAL_TEST_CONTROL_1_REG             0x08c0018
+#define SERIAL_TEST_STATUS_1_REG              0x08c001c
+#define SERIAL_TEST_NUM_FRAMES_SENT_1_LO_REG  0x08c0020
+#define SERIAL_TEST_NUM_FRAMES_RCVD_1_LO_REG  0x08c0024
+#define SERIAL_TEST_NUM_FRAMES_SENT_1_HI_REG  0x08c0028
+#define SERIAL_TEST_NUM_FRAMES_RCVD_1_HI_REG  0x08c002c
+
+#define SERIAL_TEST_CTRL_REG                  0x08c0030
+#define SERIAL_TEST_STAT_REG                  0x08c0034
+
+#define SRAM_LSB_1_BASE_ADDR                  0x1000000
+#define SRAM_LSB_2_BASE_ADDR                  0x1800000
+
+#define SRAM_MSB_SRAM1_RD_REG                 0x0940000
+#define SRAM_MSB_SRAM1_WR_REG                 0x0940004
+#define SRAM_MSB_SRAM2_RD_REG                 0x0940008
+#define SRAM_MSB_SRAM2_WR_REG                 0x094000c
+
+#define SRAM_TEST_ERR_CNT_REG                 0x0900000
+#define SRAM_TEST_ITER_NUM_REG                0x0900004
+#define SRAM_TEST_BAD_RUNS_REG                0x0900008
+#define SRAM_TEST_GOOD_RUNS_REG               0x090000c
+#define SRAM_TEST_STATUS_REG                  0x0900010
+#define SRAM_TEST_EN_REG                      0x0900014
+#define SRAM_TEST_CTRL_REG                    0x0900018
+#define SRAM_TEST_RAND_SEED_1_REG             0x090001c
+#define SRAM_TEST_RAND_SEED_2_REG             0x0900020
+
+#define SRAM_TEST_LOG_OFFSET                  0x0000020
+
+#define SRAM_TEST_LOG_ADDR_REG                0x0920000
+#define SRAM_TEST_LOG_EXP_DATA_HI_REG         0x0920004
+#define SRAM_TEST_LOG_EXP_DATA_LO_REG         0x0920008
+#define SRAM_TEST_LOG_RD_DATA_HI_REG          0x092000c
+#define SRAM_TEST_LOG_RD_DATA_LO_REG          0x0920010
+
+#define DRAM_TEST_ERR_CNT_REG                 0x0980000
+#define DRAM_TEST_ITER_NUM_REG                0x0980004
+#define DRAM_TEST_BAD_RUNS_REG                0x0980008
+#define DRAM_TEST_GOOD_RUNS_REG               0x098000c
+#define DRAM_TEST_STATUS_REG                  0x0980010
+#define DRAM_TEST_EN_REG                      0x0980014
+#define DRAM_TEST_CTRL_REG                    0x0980018
+#define DRAM_TEST_RAND_SEED_REG               0x098001c
+
+#define DRAM_TEST_LOG_OFFSET                  0x0000020
+
+#define DRAM_TEST_LOG_ADDR_REG                0x09a0000
+#define DRAM_TEST_LOG_EXP_DATA_HI_REG         0x09a0004
+#define DRAM_TEST_LOG_EXP_DATA_LO_REG         0x09a0008
+#define DRAM_TEST_LOG_RD_DATA_HI_REG          0x09a000c
+#define DRAM_TEST_LOG_RD_DATA_LO_REG          0x09a0010
+
+#define PHY_TEST_PORT_OFFSET                  0x0008000
+
+#define PHY_TEST_STATUS_REG                   0x09c0000
+#define PHY_TEST_CTRL_REG                     0x09c0004
+#define PHY_TEST_SIZE_REG                     0x09c0008
+#define PHY_TEST_PATTERN_REG                  0x09c000c
+#define PHY_TEST_INIT_SEQ_NO_REG              0x09c0010
+
+#define PHY_TEST_PHY_0_TX_STATUS_REG          0x09e0000
+#define PHY_TEST_PHY_0_TX_ITER_CNT_REG        0x09e0004
+#define PHY_TEST_PHY_0_TX_PKT_CNT_REG         0x09e0008
+#define PHY_TEST_PHY_0_TX_SEQ_NO_REG          0x09e000c
+#define PHY_TEST_PHY_0_TX_RAND_SEED_REG       0x09e0010
+#define PHY_TEST_PHY_0_RX_STATUS_REG          0x09e2000
+#define PHY_TEST_PHY_0_RX_GOOD_PKT_CNT_REG    0x09e2004
+#define PHY_TEST_PHY_0_RX_ERR_PKT_CNT_REG     0x09e2008
+#define PHY_TEST_PHY_0_RX_SEQ_NO_REG          0x09e200c
+#define PHY_TEST_PHY_0_RX_CTRL_REG            0x09e2010
+#define PHY_TEST_PHY_0_RX_LOG_STATUS_REG      0x09e4000
+#define PHY_TEST_PHY_0_RX_LOG_EXP_DATA_REG    0x09e4004
+#define PHY_TEST_PHY_0_RX_LOG_RX_DATA_REG     0x09e4008
+#define PHY_TEST_PHY_0_RX_LOG_CTRL_REG        0x09e400c
+
+#define PHY_TEST_PHY_1_TX_STATUS_REG          0x09e8000
+#define PHY_TEST_PHY_1_TX_ITER_CNT_REG        0x09e8004
+#define PHY_TEST_PHY_1_TX_PKT_CNT_REG         0x09e8008
+#define PHY_TEST_PHY_1_TX_SEQ_NO_REG          0x09e800c
+#define PHY_TEST_PHY_1_TX_RAND_SEED_REG       0x09e8010
+#define PHY_TEST_PHY_1_RX_STATUS_REG          0x09ea000
+#define PHY_TEST_PHY_1_RX_GOOD_PKT_CNT_REG    0x09ea004
+#define PHY_TEST_PHY_1_RX_ERR_PKT_CNT_REG     0x09ea008
+#define PHY_TEST_PHY_1_RX_SEQ_NO_REG          0x09ea00c
+#define PHY_TEST_PHY_1_RX_CTRL_REG            0x09ea010
+#define PHY_TEST_PHY_1_RX_LOG_STATUS_REG      0x09ec000
+#define PHY_TEST_PHY_1_RX_LOG_EXP_DATA_REG    0x09ec004
+#define PHY_TEST_PHY_1_RX_LOG_RX_DATA_REG     0x09ec008
+#define PHY_TEST_PHY_1_RX_LOG_CTRL_REG        0x09ec00c
+
+#define PHY_TEST_PHY_2_TX_STATUS_REG          0x09f0000
+#define PHY_TEST_PHY_2_TX_ITER_CNT_REG        0x09f0004
+#define PHY_TEST_PHY_2_TX_PKT_CNT_REG         0x09f0008
+#define PHY_TEST_PHY_2_TX_SEQ_NO_REG          0x09f000c
+#define PHY_TEST_PHY_2_TX_RAND_SEED_REG       0x09f0010
+#define PHY_TEST_PHY_2_RX_STATUS_REG          0x09f2000
+#define PHY_TEST_PHY_2_RX_GOOD_PKT_CNT_REG    0x09f2004
+#define PHY_TEST_PHY_2_RX_ERR_PKT_CNT_REG     0x09f2008
+#define PHY_TEST_PHY_2_RX_SEQ_NO_REG          0x09f200c
+#define PHY_TEST_PHY_2_RX_CTRL_REG            0x09f2010
+#define PHY_TEST_PHY_2_RX_LOG_STATUS_REG      0x09f4000
+#define PHY_TEST_PHY_2_RX_LOG_EXP_DATA_REG    0x09f4004
+#define PHY_TEST_PHY_2_RX_LOG_RX_DATA_REG     0x09f4008
+#define PHY_TEST_PHY_2_RX_LOG_CTRL_REG        0x09f400c
+
+#define PHY_TEST_PHY_3_TX_STATUS_REG          0x09f8000
+#define PHY_TEST_PHY_3_TX_ITER_CNT_REG        0x09f8004
+#define PHY_TEST_PHY_3_TX_PKT_CNT_REG         0x09f8008
+#define PHY_TEST_PHY_3_TX_SEQ_NO_REG          0x09f800c
+#define PHY_TEST_PHY_3_TX_RAND_SEED_REG       0x09f8010
+#define PHY_TEST_PHY_3_RX_STATUS_REG          0x09fa000
+#define PHY_TEST_PHY_3_RX_GOOD_PKT_CNT_REG    0x09fa004
+#define PHY_TEST_PHY_3_RX_ERR_PKT_CNT_REG     0x09fa008
+#define PHY_TEST_PHY_3_RX_SEQ_NO_REG          0x09fa00c
+#define PHY_TEST_PHY_3_RX_CTRL_REG            0x09fa010
+#define PHY_TEST_PHY_3_RX_LOG_STATUS_REG      0x09fc000
+#define PHY_TEST_PHY_3_RX_LOG_EXP_DATA_REG    0x09fc004
+#define PHY_TEST_PHY_3_RX_LOG_RX_DATA_REG     0x09fc008
+#define PHY_TEST_PHY_3_RX_LOG_CTRL_REG        0x09fc00c
+
+#define REG_FILE_BASE_ADDR_REG              0x0800000
+
+#define SRAM_BASE_ADDR                      0x1000000
+#define DRAM_BASE_ADDR                      0x4000000
+
+#define IN_ARB_NUM_PKTS_SENT_REG                  0x2000200
+#define IN_ARB_LAST_PKT_WORD_0_LO_REG             0x2000204
+#define IN_ARB_LAST_PKT_WORD_0_HI_REG             0x2000208
+#define IN_ARB_LAST_PKT_CTRL_0_REG                0x200020c
+#define IN_ARB_LAST_PKT_WORD_1_LO_REG             0x2000210
+#define IN_ARB_LAST_PKT_WORD_1_HI_REG             0x2000214
+#define IN_ARB_LAST_PKT_CTRL_1_REG                0x2000218
+#define IN_ARB_STATE_REG                          0x200021c
+
+#define SWITCH_OP_LUT_PORTS_MAC_HI_REG            0x2000100
+#define SWITCH_OP_LUT_MAC_LO_REG                  0x2000104
+#define SWITCH_OP_LUT_NUM_HITS_REG                0x2000108
+#define SWITCH_OP_LUT_NUM_MISSES_REG              0x200010c
+#define SWITCH_OP_LUT_MAC_LUT_RD_ADDR_REG         0x2000110
+#define SWITCH_OP_LUT_MAC_LUT_WR_ADDR_REG         0x2000114
+
+#define ROUTER_RT_SIZE                                     32
+#define ROUTER_ARP_SIZE                                    32
+#define ROUTER_DST_IP_FILTER_TABLE_DEPTH                   32
+
+#define ROUTER_OP_LUT_ARP_MAC_HI_REG              0x2000100
+#define ROUTER_OP_LUT_ARP_MAC_LO_REG              0x2000104
+#define ROUTER_OP_LUT_ARP_NEXT_HOP_IP_REG         0x2000108
+#define ROUTER_OP_LUT_ARP_LUT_RD_ADDR_REG         0x200010c
+#define ROUTER_OP_LUT_ARP_LUT_WR_ADDR_REG         0x2000110
+#define ROUTER_OP_LUT_RT_IP_REG                   0x2000114
+#define ROUTER_OP_LUT_RT_MASK_REG                 0x2000118
+#define ROUTER_OP_LUT_RT_NEXT_HOP_IP_REG          0x200011c
+#define ROUTER_OP_LUT_RT_OUTPUT_PORT_REG          0x2000120
+#define ROUTER_OP_LUT_RT_LUT_RD_ADDR_REG          0x2000124
+#define ROUTER_OP_LUT_RT_LUT_WR_ADDR_REG          0x2000128
+#define ROUTER_OP_LUT_MAC_0_HI_REG                0x200012c
+#define ROUTER_OP_LUT_MAC_0_LO_REG                0x2000130
+#define ROUTER_OP_LUT_MAC_1_HI_REG                0x2000134
+#define ROUTER_OP_LUT_MAC_1_LO_REG                0x2000138
+#define ROUTER_OP_LUT_MAC_2_HI_REG                0x200013c
+#define ROUTER_OP_LUT_MAC_2_LO_REG                0x2000140
+#define ROUTER_OP_LUT_MAC_3_HI_REG                0x2000144
+#define ROUTER_OP_LUT_MAC_3_LO_REG                0x2000148
+#define ROUTER_OP_LUT_DST_IP_FILTER_IP_REG        0x200014c
+#define ROUTER_OP_LUT_DST_IP_FILTER_RD_ADDR_REG   0x2000150
+#define ROUTER_OP_LUT_DST_IP_FILTER_WR_ADDR_REG   0x2000154
+
+#define ROUTER_OP_LUT_ARP_NUM_MISSES_REG          0x2000180
+#define ROUTER_OP_LUT_LPM_NUM_MISSES_REG          0x2000184
+#define ROUTER_OP_LUT_NUM_CPU_PKTS_SENT_REG       0x2000188
+#define ROUTER_OP_LUT_NUM_BAD_OPTS_VER_REG        0x200018c
+#define ROUTER_OP_LUT_NUM_BAD_CHKSUMS_REG         0x2000190
+#define ROUTER_OP_LUT_NUM_BAD_TTLS_REG            0x2000194
+#define ROUTER_OP_LUT_NUM_NON_IP_RCVD_REG         0x2000198
+#define ROUTER_OP_LUT_NUM_PKTS_FORWARDED_REG      0x200019c
+#define ROUTER_OP_LUT_NUM_WRONG_DEST_REG          0x20001a0
+#define ROUTER_OP_LUT_NUM_FILTERED_PKTS_REG       0x20001a4
+
+#define OQ_ENABLE_SEND_BIT_NUM                              0
+#define OQ_INITIALIZE_OQ_BIT_NUM                            1
+
+#define OQ_NUM_WORDS_LEFT_REG_0                 0x2101000
+#define OQ_NUM_PKT_BYTES_STORED_REG_0           0x2101004
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_0      0x2101008
+#define OQ_NUM_PKTS_STORED_REG_0                0x210100c
+#define OQ_NUM_PKTS_DROPPED_REG_0               0x2101010
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_0          0x2101014
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_0     0x2101018
+#define OQ_NUM_PKTS_REMOVED_REG_0               0x210101c
+#define OQ_ADDRESS_HI_REG_0                     0x2101020
+#define OQ_ADDRESS_LO_REG_0                     0x2101024
+#define OQ_WR_ADDRESS_REG_0                     0x2101028
+#define OQ_RD_ADDRESS_REG_0                     0x210102c
+#define OQ_NUM_PKTS_IN_Q_REG_0                  0x2101030
+#define OQ_MAX_PKTS_IN_Q_REG_0                  0x2101034
+#define OQ_FULL_THRESH_REG_0                    0x2101040
+#define OQ_NUM_WORDS_IN_Q_REG_0                 0x210103c
+#define OQ_CONTROL_REG_0                        0x2101038
+
+#define OQ_NUM_WORDS_LEFT_REG_1                 0x2101100
+#define OQ_NUM_PKT_BYTES_STORED_REG_1           0x2101104
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_1      0x2101108
+#define OQ_NUM_PKTS_STORED_REG_1                0x210110c
+#define OQ_NUM_PKTS_DROPPED_REG_1               0x2101110
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_1          0x2101114
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_1     0x2101118
+#define OQ_NUM_PKTS_REMOVED_REG_1               0x210111c
+#define OQ_ADDRESS_HI_REG_1                     0x2101120
+#define OQ_ADDRESS_LO_REG_1                     0x2101124
+#define OQ_WR_ADDRESS_REG_1                     0x2101128
+#define OQ_RD_ADDRESS_REG_1                     0x210112c
+#define OQ_NUM_PKTS_IN_Q_REG_1                  0x2101130
+#define OQ_MAX_PKTS_IN_Q_REG_1                  0x2101134
+#define OQ_FULL_THRESH_REG_1                    0x2101140
+#define OQ_NUM_WORDS_IN_Q_REG_1                 0x210113c
+#define OQ_CONTROL_REG_1                        0x2101138
+
+#define OQ_NUM_WORDS_LEFT_REG_2                 0x2101200
+#define OQ_NUM_PKT_BYTES_STORED_REG_2           0x2101204
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_2      0x2101208
+#define OQ_NUM_PKTS_STORED_REG_2                0x210120c
+#define OQ_NUM_PKTS_DROPPED_REG_2               0x2101210
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_2          0x2101214
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_2     0x2101218
+#define OQ_NUM_PKTS_REMOVED_REG_2               0x210121c
+#define OQ_ADDRESS_HI_REG_2                     0x2101220
+#define OQ_ADDRESS_LO_REG_2                     0x2101224
+#define OQ_WR_ADDRESS_REG_2                     0x2101228
+#define OQ_RD_ADDRESS_REG_2                     0x210122c
+#define OQ_NUM_PKTS_IN_Q_REG_2                  0x2101230
+#define OQ_MAX_PKTS_IN_Q_REG_2                  0x2101234
+#define OQ_FULL_THRESH_REG_2                    0x2101240
+#define OQ_NUM_WORDS_IN_Q_REG_2                 0x210123c
+#define OQ_CONTROL_REG_2                        0x2101238
+
+#define OQ_NUM_WORDS_LEFT_REG_3                 0x2101300
+#define OQ_NUM_PKT_BYTES_STORED_REG_3           0x2101304
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_3      0x2101308
+#define OQ_NUM_PKTS_STORED_REG_3                0x210130c
+#define OQ_NUM_PKTS_DROPPED_REG_3               0x2101310
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_3          0x2101314
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_3     0x2101318
+#define OQ_NUM_PKTS_REMOVED_REG_3               0x210131c
+#define OQ_ADDRESS_HI_REG_3                     0x2101320
+#define OQ_ADDRESS_LO_REG_3                     0x2101324
+#define OQ_WR_ADDRESS_REG_3                     0x2101328
+#define OQ_RD_ADDRESS_REG_3                     0x210132c
+#define OQ_NUM_PKTS_IN_Q_REG_3                  0x2101330
+#define OQ_MAX_PKTS_IN_Q_REG_3                  0x2101334
+#define OQ_FULL_THRESH_REG_3                    0x2101340
+#define OQ_NUM_WORDS_IN_Q_REG_3                 0x210133c
+#define OQ_CONTROL_REG_3                        0x2101338
+
+#define OQ_NUM_WORDS_LEFT_REG_4                 0x2101400
+#define OQ_NUM_PKT_BYTES_STORED_REG_4           0x2101404
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_4      0x2101408
+#define OQ_NUM_PKTS_STORED_REG_4                0x210140c
+#define OQ_NUM_PKTS_DROPPED_REG_4               0x2101410
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_4          0x2101414
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_4     0x2101418
+#define OQ_NUM_PKTS_REMOVED_REG_4               0x210141c
+#define OQ_ADDRESS_HI_REG_4                     0x2101420
+#define OQ_ADDRESS_LO_REG_4                     0x2101424
+#define OQ_WR_ADDRESS_REG_4                     0x2101428
+#define OQ_RD_ADDRESS_REG_4                     0x210142c
+#define OQ_NUM_PKTS_IN_Q_REG_4                  0x2101430
+#define OQ_MAX_PKTS_IN_Q_REG_4                  0x2101434
+#define OQ_FULL_THRESH_REG_4                    0x2101440
+#define OQ_NUM_WORDS_IN_Q_REG_4                 0x210143c
+#define OQ_CONTROL_REG_4                        0x2101438
+
+#define OQ_NUM_WORDS_LEFT_REG_5                 0x2101500
+#define OQ_NUM_PKT_BYTES_STORED_REG_5           0x2101504
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_5      0x2101508
+#define OQ_NUM_PKTS_STORED_REG_5                0x210150c
+#define OQ_NUM_PKTS_DROPPED_REG_5               0x2101510
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_5          0x2101514
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_5     0x2101518
+#define OQ_NUM_PKTS_REMOVED_REG_5               0x210151c
+#define OQ_ADDRESS_HI_REG_5                     0x2101520
+#define OQ_ADDRESS_LO_REG_5                     0x2101524
+#define OQ_WR_ADDRESS_REG_5                     0x2101528
+#define OQ_RD_ADDRESS_REG_5                     0x210152c
+#define OQ_NUM_PKTS_IN_Q_REG_5                  0x2101530
+#define OQ_MAX_PKTS_IN_Q_REG_5                  0x2101534
+#define OQ_FULL_THRESH_REG_5                    0x2101540
+#define OQ_NUM_WORDS_IN_Q_REG_5                 0x210153c
+#define OQ_CONTROL_REG_5                        0x2101538
+
+#define OQ_NUM_WORDS_LEFT_REG_6                 0x2101600
+#define OQ_NUM_PKT_BYTES_STORED_REG_6           0x2101604
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_6      0x2101608
+#define OQ_NUM_PKTS_STORED_REG_6                0x210160c
+#define OQ_NUM_PKTS_DROPPED_REG_6               0x2101610
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_6          0x2101614
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_6     0x2101618
+#define OQ_NUM_PKTS_REMOVED_REG_6               0x210161c
+#define OQ_ADDRESS_HI_REG_6                     0x2101620
+#define OQ_ADDRESS_LO_REG_6                     0x2101624
+#define OQ_WR_ADDRESS_REG_6                     0x2101628
+#define OQ_RD_ADDRESS_REG_6                     0x210162c
+#define OQ_NUM_PKTS_IN_Q_REG_6                  0x2101630
+#define OQ_MAX_PKTS_IN_Q_REG_6                  0x2101634
+#define OQ_FULL_THRESH_REG_6                    0x2101640
+#define OQ_NUM_WORDS_IN_Q_REG_6                 0x210163c
+#define OQ_CONTROL_REG_6                        0x2101638
+
+#define OQ_NUM_WORDS_LEFT_REG_7                 0x2101700
+#define OQ_NUM_PKT_BYTES_STORED_REG_7           0x2101704
+#define OQ_NUM_OVERHEAD_BYTES_STORED_REG_7      0x2101708
+#define OQ_NUM_PKTS_STORED_REG_7                0x210170c
+#define OQ_NUM_PKTS_DROPPED_REG_7               0x2101710
+#define OQ_NUM_PKT_BYTES_REMOVED_REG_7          0x2101714
+#define OQ_NUM_OVERHEAD_BYTES_REMOVED_REG_7     0x2101718
+#define OQ_NUM_PKTS_REMOVED_REG_7               0x210171c
+#define OQ_ADDRESS_HI_REG_7                     0x2101720
+#define OQ_ADDRESS_LO_REG_7                     0x2101724
+#define OQ_WR_ADDRESS_REG_7                     0x2101728
+#define OQ_RD_ADDRESS_REG_7                     0x210172c
+#define OQ_NUM_PKTS_IN_Q_REG_7                  0x2101730
+#define OQ_MAX_PKTS_IN_Q_REG_7                  0x2101734
+#define OQ_FULL_THRESH_REG_7                    0x2101740
+#define OQ_NUM_WORDS_IN_Q_REG_7                 0x210173c
+#define OQ_CONTROL_REG_7                        0x2101738
+
+#define DELAY_ENABLE_REG                        0x2000500
+#define DELAY_1ST_WORD_HI_REG                   0x2000508
+#define DELAY_1ST_WORD_LO_REG                   0x200050c
+#define DELAY_LENGTH_REG                        0x2000504
+
+#define RATE_LIMIT_ENABLE_REG                   0x2000400
+#define RATE_LIMIT_SHIFT_REG                    0x2000404
+
+#define EVT_CAP_ENABLE_CAPTURE_REG              0x2000300
+#define EVT_CAP_SEND_PKT_REG                    0x2000304
+#define EVT_CAP_DST_MAC_HI_REG                  0x2000308
+#define EVT_CAP_DST_MAC_LO_REG                  0x200030c
+#define EVT_CAP_SRC_MAC_HI_REG                  0x2000310
+#define EVT_CAP_SRC_MAC_LO_REG                  0x2000314
+#define EVT_CAP_ETHERTYPE_REG                   0x2000318
+#define EVT_CAP_IP_DST_REG                      0x200031c
+#define EVT_CAP_IP_SRC_REG                      0x2000320
+#define EVT_CAP_UDP_SRC_PORT_REG                0x2000330
+#define EVT_CAP_UDP_DST_PORT_REG                0x2000334
+#define EVT_CAP_OUTPUT_PORTS_REG                0x2000338
+#define EVT_CAP_RESET_TIMERS_REG                0x200033c
+#define EVT_CAP_MONITOR_MASK_REG                0x2000324
+#define EVT_CAP_TIMER_RESOLUTION_REG            0x2000340
+#define EVT_CAP_NUM_EVT_PKTS_SENT_REG           0x2000344
+#define EVT_CAP_NUM_EVTS_SENT_REG               0x2000348
+#define EVT_CAP_NUM_EVTS_DROPPED_REG            0x200032c
+#define EVT_CAP_SIGNAL_ID_MASK_REG              0x2000328
+
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_0_REG     0x2000700
+#define BRAM_OQ_NUM_PKTS_RECEIVED_0_REG         0x2000704
+#define BRAM_OQ_NUM_PKTS_DROPPED_0_REG          0x2000708
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_1_REG    0x200070c
+#define BRAM_OQ_NUM_PKTS_RECEIVED_1_REG         0x2000710
+#define BRAM_OQ_NUM_PKTS_DROPPED_1_REG          0x2000714
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_2_REG    0x2000718
+#define BRAM_OQ_NUM_PKTS_RECEIVED_2_REG         0x200071c
+#define BRAM_OQ_NUM_PKTS_DROPPED_2_REG          0x2000720
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_3_REG    0x2000724
+#define BRAM_OQ_NUM_PKTS_RECEIVED_3_REG         0x2000728
+#define BRAM_OQ_NUM_PKTS_DROPPED_3_REG          0x200072c
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_4_REG    0x2000730
+#define BRAM_OQ_NUM_PKTS_RECEIVED_4_REG         0x2000734
+#define BRAM_OQ_NUM_PKTS_DROPPED_4_REG          0x2000738
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_5_REG    0x200073c
+#define BRAM_OQ_NUM_PKTS_RECEIVED_5_REG         0x2000740
+#define BRAM_OQ_NUM_PKTS_DROPPED_5_REG          0x2000744
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_6_REG    0x2000748
+#define BRAM_OQ_NUM_PKTS_RECEIVED_6_REG         0x200074c
+#define BRAM_OQ_NUM_PKTS_DROPPED_6_REG          0x2000750
+#define BRAM_OQ_NUM_PKT_BYTES_RECEIVED_7_REG    0x2000754
+#define BRAM_OQ_NUM_PKTS_RECEIVED_7_REG         0x2000758
+#define BRAM_OQ_NUM_PKTS_DROPPED_7_REG          0x200075c
+#define BRAM_OQ_DISABLE_QUEUES_REG              0x2000760
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_0_REG        0x2000764
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_1_REG        0x2000768
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_2_REG        0x200076c
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_3_REG        0x2000770
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_4_REG        0x2000774
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_5_REG        0x2000778
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_6_REG        0x200077c
+#define BRAM_OQ_NUM_WORDS_IN_QUEUE_7_REG        0x2000780
+
+
+int nf2k_reg_read(struct net_device *dev, unsigned int addr, void* data);
+int nf2k_reg_write(struct net_device *dev, unsigned int addr, void* data);
+/*
+ * Flush previous PCI writes through intermediate bridges
+ * by doing a benign read 
+ */
+static inline void nf2_write_flush(struct nf2_card_priv *card)
+{
+   (void)ioread32(card->ioaddr);
+}
+
+/*
+ * Enable interrupts
+ */
+static inline void nf2_enable_irq(struct nf2_card_priv *card)
+{
+   iowrite32(0x00000000, card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+   nf2_write_flush(card);
+}
+
+/*
+ * Disable interrupts
+ */
+static inline void nf2_disable_irq(struct nf2_card_priv *card)
+{
+   iowrite32(0xFFFFFFFF, card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+   nf2_write_flush(card);
+}
+
+/* 
+ * Get the revision from the config space
+ */
+static unsigned char nf2_get_revision(struct pci_dev *pdev)
+{
+   u8 revision;
+
+   pci_read_config_byte(pdev, PCI_REVISION_ID, &revision);
+   return revision;
+}
+
+/*
+ * Reset the HW
+ */
+void nf2_hw_reset(struct nf2_card_priv *card)
+{
+   /* Reset the CPCI */
+   iowrite32(RESET_CPCI, card->ioaddr + CPCI_REG_RESET);
+
+   /* Reset the CNET */
+   if (card->is_ctrl)
+   {
+       iowrite32(CTRL_CNET_RESET, card->ioaddr + CNET_REG_CTRL);
+       iowrite32(CNET_RESET_MAC_3 |
+           CNET_RESET_MAC_2 |
+           CNET_RESET_MAC_1 |
+           CNET_RESET_MAC_0, card->ioaddr + CNET_REG_RESET);
+
+       /* Disable all MACs */
+       iowrite32(0, card->ioaddr + CNET_REG_ENABLE);
+   }
+
+   /* Flush the writes */
+   nf2_write_flush(card);
+}
+
+/*
+ * Reset the CPCI chip.
+ *
+ * Make sure to restore interrupts to their previous state
+ */
+void nf2_reset_cpci(struct nf2_card_priv *card)
+{
+   u32 intmask;
+
+   intmask = ioread32(card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+   iowrite32(RESET_CPCI, card->ioaddr + CPCI_REG_RESET);
+   iowrite32(intmask, card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+
+   /* Flush the writes */
+   nf2_write_flush(card);
+}
+
+static int nf2_get_settings(struct net_device *dev,
+       struct ethtool_cmd *ecmd)
+{
+   ecmd->supported = SUPPORTED_1000baseT_Full |
+       SUPPORTED_MII;
+   ecmd->advertising = ADVERTISED_TP;
+   ecmd->port = PORT_MII;
+   ecmd->speed = SPEED_1000;
+   ecmd->duplex = DUPLEX_FULL;
+   ecmd->autoneg = AUTONEG_DISABLE;
+
+   return 0;
+}
+
+/**
+ * nf2_set_settings - set values passed from ethtool
+ * @dev:   net_device pointer
+ * @ecmd:  ethtool command
+ *
+ * Can be used to configure the interface from the
+ * parameters passed via ethtool command
+ */
+static int nf2_set_settings(struct net_device *dev,
+       struct ethtool_cmd *ecmd)
+{
+   return 0;
+}
+
+static void nf2_get_drvinfo(struct net_device *dev,
+       struct ethtool_drvinfo *drvinfo)
+{
+
+}
+
+static int nf2_phys_id(struct net_device *dev, __u32 data)
+{
+   return 0;
+}
+
+static const struct ethtool_ops nf2_ethtool_ops = {
+   .get_settings       = nf2_get_settings,
+   .set_settings       = nf2_set_settings,
+   .get_drvinfo        = nf2_get_drvinfo,
+   .get_link       = ethtool_op_get_link,
+   .phys_id        = nf2_phys_id,
+};
+
+void nf2_set_ethtool_ops(struct net_device *dev)
+{
+   SET_ETHTOOL_OPS(dev, &nf2_ethtool_ops);
+}
+
+#define KERN_DFLT_DEBUG KERN_INFO
+
+/* JN: If we are working with an older kernel, it would probably
+ * still use the SA_SHIRQ */
+#ifndef IRQF_SHARED
+#define IRQF_SHARED SA_SHIRQ
+#endif
+
+/* Control card device number */
+static int devnum;
+
+/* Function declarations */
+static int nf2c_send(struct net_device *dev);
+static void nf2c_rx(struct net_device *dev, struct nf2_packet *pkt);
+static int nf2c_create_pool(struct nf2_card_priv *card);
+static void nf2c_destroy_pool(struct nf2_card_priv *card);
+static irqreturn_t nf2c_intr(int irq, void *dev_id
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+           , struct pt_regs *regs
+#endif
+           );
+
+static void nf2c_clear_dma_flags(struct nf2_card_priv *card);
+static void nf2c_check_link_status(struct nf2_card_priv *card,
+       struct net_device *dev, unsigned int ifnum);
+
+/**
+ * nf2c_open - open method called when the interface is brought up
+ * @dev:   Net device
+ *
+ * Locking: state_lock - prevent the state variable and the corresponding
+ *                       register from getting out of sync
+ */
+static int nf2c_open(struct net_device *dev)
+{
+   int err = 0;
+   u32 mac_reset;
+   u32 enable;
+   struct nf2_iface_priv *iface =
+       (struct nf2_iface_priv *)netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+
+   PDEBUG(KERN_DFLT_DEBUG "nf2: bringing up card\n");
+
+   /* Aquire the mutex for the state variables */
+   if (down_interruptible(&card->state_lock))
+       return -ERESTARTSYS;
+
+   /* Tell the driver the carrier is down... */
+   netif_carrier_off(dev);
+
+   /* Check if any other interfaces are active.
+    * If no other interfaces are up install the IRQ handler
+    * Always attach the interrupt to the first device in the pool
+    */
+   if (!card->ifup) {
+       nf2_hw_reset(card);
+       err = request_irq(card->pdev->irq, nf2c_intr, IRQF_SHARED,
+               card->ndev[0]->name, card->ndev[0]);
+       if (err)
+           goto out;
+       nf2_enable_irq(card);
+   }
+
+   /* Modify the ifup flag */
+   card->ifup |= 1 << iface->iface;
+   PDEBUG(KERN_DFLT_DEBUG "nf2: ifup: %x\n", card->ifup);
+
+   /* Perform the necessary actions to enable the MAC */
+   mac_reset = CNET_RESET_MAC_0 << iface->iface;
+   iowrite32(mac_reset, card->ioaddr + CNET_REG_RESET);
+
+   enable = ioread32(card->ioaddr + CNET_REG_ENABLE);
+   enable |= (CNET_ENABLE_RX_FIFO_0 | CNET_ENABLE_TX_MAC_0) <<
+       iface->iface |
+       CNET_ENABLE_INGRESS_ARBITER |
+       CNET_ENABLE_RX_DMA;
+   iowrite32(enable, card->ioaddr + CNET_REG_ENABLE);
+
+   /* We don't have means to access phy registers to check their link
+    * status until CNET bitfile has been downloaded
+    * Assumption is carrier on (as same as previous version of this
+    * code).
+    *
+    *  netif_carrier_on(dev);
+    *
+    *  Since, nf2_download enables PHY interrupts, no need to do
+    *  netif_carrier_on here
+    */
+
+
+   netif_wake_queue(dev);
+
+out:
+   up(&card->state_lock);
+   return err;
+}
+
+/**
+ * nf2c_release - release method called when the interface is brought down
+ * @dev:   Net device
+ *
+ * Locking: state_lock - prevent the state variable and the corresponding
+ *                       register from getting out of sync
+ *
+ *          no locking for txbuff variables as other functions that modify
+ *          these variables will not execute concurrently if nf2c_release
+ *          has been called
+ */
+static int nf2c_release(struct net_device *dev)
+{
+   u32 mac_reset;
+   u32 enable;
+   struct nf2_iface_priv *iface =
+       (struct nf2_iface_priv *)netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+
+   /* Aquire the mutex for the state variables */
+   if (down_interruptible(&card->state_lock))
+       return -ERESTARTSYS;
+
+   /* Prevent transmission at the software level */
+   netif_carrier_off(dev);
+   netif_stop_queue(dev);
+
+   /* Perform the necessary actions to disable the MAC */
+   enable = ioread32(card->ioaddr + CNET_REG_ENABLE);
+   enable &= ~((CNET_ENABLE_RX_FIFO_0 | CNET_ENABLE_TX_MAC_0) <<
+           iface->iface);
+   iowrite32(enable, card->ioaddr + CNET_REG_ENABLE);
+
+   mac_reset = CNET_RESET_MAC_0 << iface->iface;
+   iowrite32(mac_reset, card->ioaddr + CNET_REG_RESET);
+
+   /* Update the ifup flag */
+   card->ifup &= ~(1 << iface->iface);
+   PDEBUG(KERN_ALERT "nf2: ifup: %x\n", card->ifup);
+
+   /* Check if any other interfaces are active.
+    * If no other interfaces are up uninstall the IRQ handler
+    */
+   if (!card->ifup) {
+       free_irq(card->pdev->irq, card->ndev[0]);
+       nf2_hw_reset(card);
+       /* No need to call nf2_disable_irq(card) as the reset will
+        * disable the interrupts */
+
+       /* Free any skb's in the transmit queue */
+       if (card->free_txbuffs != tx_pool_size) {
+           if (atomic_read(&card->dma_tx_in_progress))
+               pci_unmap_single(card->pdev,
+                   card->dma_tx_addr,
+                   card->txbuff[card->rd_txbuff].skb->len,
+                   PCI_DMA_TODEVICE);
+
+           while (card->free_txbuffs < tx_pool_size) {
+               dev_kfree_skb(
+                   card->txbuff[card->rd_txbuff].skb);
+               card->rd_txbuff = (card->rd_txbuff + 1) %
+                         tx_pool_size;
+               card->free_txbuffs++;
+           }
+       }
+       atomic_set(&card->dma_tx_in_progress, 0);
+       atomic_set(&card->dma_rx_in_progress, 0);
+   }
+
+   PDEBUG(KERN_DFLT_DEBUG "nf2: Queue stopped\n");
+
+   up(&card->state_lock);
+   return 0;
+}
+
+/**
+ * nf2c_config - Configuration changes (passed on by ifconfig)
+ * @dev:   Net device
+ * @map:   ifmap
+ *
+ */
+static int nf2c_config(struct net_device *dev, struct ifmap *map)
+{
+   if (dev->flags & IFF_UP) /* can't act on a running interface */
+       return -EBUSY;
+
+   /* Don't allow changing the I/O address */
+   if (map->base_addr != dev->base_addr) {
+       printk(KERN_WARNING "nf2: Can't change I/O address\n");
+       return -EOPNOTSUPP;
+   }
+
+   /* Allow changing the IRQ */
+   if (map->irq != dev->irq) {
+       printk(KERN_WARNING "nf2: Can't change IRQ\n");
+       return -EOPNOTSUPP;
+   }
+
+   /* ignore other fields */
+   return 0;
+}
+
+/**
+ * nf2c_tx - Transmit a packet (called by the kernel)
+ * @skb:   socket buffer
+ * @dev:   net device
+ *
+ */
+static int nf2c_tx(struct sk_buff *skb, struct net_device *dev)
+{
+   int err = 0;
+   unsigned long flags;
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+
+   /* Aquire a spinlock for the buffs vbles */
+   spin_lock_irqsave(&card->txbuff_lock, flags);
+
+   if (card->free_txbuffs == 0) {
+       if (printk_ratelimit())
+           printk(KERN_ALERT "nf2: no available transmit/receive"
+                   " buffers\n");
+       err = 1;
+   } else {
+       card->txbuff[card->wr_txbuff].skb = skb;
+       card->txbuff[card->wr_txbuff].iface = iface->iface;
+       card->wr_txbuff = (card->wr_txbuff + 1) % tx_pool_size;
+       card->free_txbuffs--;
+       card->free_txbuffs_port[iface->iface]--;
+
+       /* Stop the queue if the number of txbuffs drops to 0 */
+       if (card->free_txbuffs_port[iface->iface] == 0) {
+           PDEBUG(KERN_DFLT_DEBUG "nf2: stopping queue %d\n",
+                   iface->iface);
+           netif_stop_queue(dev);
+       }
+
+       /* Attempt to send the actual packet */
+       nf2c_send(dev);
+
+       /* save the timestamp */
+       dev->trans_start = jiffies;
+   }
+
+   /*err_unlock:*/
+   spin_unlock_irqrestore(&card->txbuff_lock, flags);
+
+   return err;
+}
+
+/**
+ * nf2c_send - Send an actual packet
+ * @dev:   net device
+ *
+ * Atomic variable dma_tx_lock is used to prevent multiple packets from
+ * being sent simultaneously (the hardware can only transfer one at once)
+ *
+ * Note: The txbuff lock is not used as an incorrect read of free_txbuffs is
+ *       not fatal (this function will be called again).
+ */
+static int nf2c_send(struct net_device *dev)
+{
+   int err = 0;
+   int dma_len = 0;
+   /*unsigned long flags;*/
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+   struct sk_buff *skb;
+   unsigned int rd_iface;  /* iface of skb at front of Q*/
+
+   /* Aquire a spinlock for the dma variables */
+   /*spin_lock_irqsave(&card->dma_tx_lock, flags);*/
+
+   /* Check if a DMA transfer is in progress and record the fact that
+    * we have started a transfer
+    */
+   if (atomic_add_return(1, &card->dma_tx_in_progress) != 1) {
+       atomic_dec(&card->dma_tx_in_progress);
+       err = 1;
+       goto err_unlock;
+   }
+
+   /* Check if there's something to send */
+   if (card->free_txbuffs == tx_pool_size) {
+       atomic_dec(&card->dma_tx_in_progress);
+       err = 1;
+       goto err_unlock;
+   }
+
+   /* Get the interface number of the skb we are sending. */
+   rd_iface = card->txbuff[card->rd_txbuff].iface;
+
+   /* Verify that the TX queue can accept a packet */
+   if ((card->dma_can_wr_pkt & (1 << rd_iface)) == 0) {
+       atomic_dec(&card->dma_tx_in_progress);
+       err = 1;
+       goto err_unlock;
+   }
+
+   /* Grab the skb */
+   skb = card->txbuff[card->rd_txbuff].skb;
+
+   /* Map the buffer into DMA space */
+   card->dma_tx_addr = pci_map_single(card->pdev,
+           skb->data, skb->len, PCI_DMA_TODEVICE);
+
+   /* Start the transfer */
+   iowrite32(card->dma_tx_addr,
+           card->ioaddr + CPCI_REG_DMA_E_ADDR);
+
+   /* Pad the skb to be at least 60 bytes. Call the padding function
+    * to ensure that there is no information leakage */
+   if (skb->len < 60) {
+       skb_pad(skb, 60 - skb->len);
+       dma_len = 60;
+   } else {
+       dma_len = skb->len;
+   }
+   iowrite32(dma_len,
+           card->ioaddr + CPCI_REG_DMA_E_SIZE);
+
+   iowrite32(NF2_SET_DMA_CTRL_MAC(rd_iface) | DMA_CTRL_OWNER,
+           card->ioaddr + CPCI_REG_DMA_E_CTRL);
+
+   PDEBUG(KERN_DFLT_DEBUG "nf2: sending DMA pkt to iface: %d\n",
+           rd_iface);
+
+err_unlock:
+   /*spin_unlock_irqrestore(&priv->card->dma_tx_lock, flags);*/
+
+   return err;
+}
+
+/**
+ * nf2c_rx - Receive a packet: retrieve, encapsulate,pass over to upper levels
+ * @dev:   net device
+ * @pkt:   nf2 packet
+ *
+ * Note: This is called from the interrupt handler. netif_rx schedules
+ * the skb to be delivered to the kernel later (ie. bottom-half delivery).
+ */
+static void nf2c_rx(struct net_device *dev, struct nf2_packet *pkt)
+{
+   struct sk_buff *skb;
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+
+   /*
+    * The packet has been retrieved from the transmission
+    * medium. Build an skb around it, so upper layers can handle it
+    */
+   skb = dev_alloc_skb(pkt->len + 2);
+   if (!skb) {
+       if (printk_ratelimit())
+           printk(KERN_NOTICE "nf2 rx: low on mem - packet"
+                   " dropped\n");
+       iface->stats.rx_dropped++;
+       goto out;
+   }
+
+   skb_reserve(skb, 2); /* align IP on 16B boundary */
+   memcpy(skb_put(skb, pkt->len), pkt->data, pkt->len);
+
+   /* Write metadata, and then pass to the receive level */
+   skb->dev = dev;
+   skb->protocol = eth_type_trans(skb, dev);
+   skb->ip_summed = CHECKSUM_NONE; /* Check the checksum */
+   iface->stats.rx_packets++;
+   iface->stats.rx_bytes += pkt->len;
+   netif_rx(skb);
+
+out:
+   return;
+}
+
+/**
+ * nf2c_clear_dma_flags - Clear the DMA flags
+ * @card: nf2 card private data
+ *
+ * clear the dma flags that record that a DMA transfer is in progress
+ */
+static void nf2c_clear_dma_flags(struct nf2_card_priv *card)
+{
+   unsigned long flags;
+   unsigned int ifnum;
+
+   PDEBUG(KERN_DFLT_DEBUG "nf2: clearing dma flags\n");
+
+   /* Clear the dma_rx_in_progress flag */
+   if (atomic_read(&card->dma_rx_in_progress)) {
+       pci_unmap_single(card->pdev, card->dma_rx_addr,
+               MAX_DMA_LEN,
+               PCI_DMA_FROMDEVICE);
+
+       atomic_dec(&card->dma_rx_in_progress);
+   }
+
+   /* Clear the dma_tx_in_progress flag
+    * Note: also frees the skb */
+   if (atomic_read(&card->dma_tx_in_progress)) {
+       pci_unmap_single(card->pdev, card->dma_tx_addr,
+               card->txbuff[card->rd_txbuff].skb->len,
+               PCI_DMA_TODEVICE);
+
+       /* Aquire a spinlock for the buffs vbles */
+       spin_lock_irqsave(&card->txbuff_lock, flags);
+
+       /* Free the skb */
+       dev_kfree_skb_irq(card->txbuff[card->rd_txbuff].skb);
+
+       /* Note: make sure that txbuffs is incremented before
+        * dma_tx_in_progress is decremented due to the lack of
+        * locking in nf2c_send()
+        */
+       ifnum = card->txbuff[card->rd_txbuff].iface;
+       card->rd_txbuff = (card->rd_txbuff + 1) % tx_pool_size;
+       card->free_txbuffs++;
+       card->free_txbuffs_port[ifnum]++;
+       atomic_dec(&card->dma_tx_in_progress);
+
+       /* Re-enable the queues if necessary */
+       if (card->free_txbuffs_port[ifnum] == 1)
+           netif_wake_queue(card->ndev[ifnum]);
+
+       spin_unlock_irqrestore(&card->txbuff_lock, flags);
+   }
+}
+
+/**
+ * nf2c_ioctl - Handle ioctl calls
+ * @dev:   net device
+ * @rq:        ifreq structure
+ * @cmd:   ioctl cmd
+ *
+ */
+static int nf2c_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+   struct nf2reg reg;
+   struct mii_ioctl_data *data = if_mii(rq);
+   u32 phy_id_lo, phy_id_hi, phy_id;
+
+   struct nf2_iface_priv *iface =
+       (struct nf2_iface_priv *)netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+
+
+   switch (cmd) {
+       /* Read a register */
+   case SIOCREGREAD:
+           if (copy_from_user(&reg, rq->ifr_data,
+                       sizeof(struct nf2reg))) {
+               printk(KERN_ERR "nf2: Unable to copy data from"
+                       " user space\n");
+               return -EFAULT;
+           }
+
+           nf2k_reg_read(dev, reg.reg, &reg.val);
+
+           if (copy_to_user(rq->ifr_data, &reg,
+                       sizeof(struct nf2reg))) {
+               printk(KERN_ERR "nf2: Unable to copy data to "
+                       "user space\n");
+               return -EFAULT;
+           }
+           return 0;
+
+           /* Write a register */
+   case SIOCREGWRITE:
+           if (copy_from_user(&reg, rq->ifr_data,
+                       sizeof(struct nf2reg))) {
+               printk(KERN_ERR "nf2: Unable to copy data from "
+                       "user space\n");
+               return -EFAULT;
+           }
+
+           nf2k_reg_write(dev, reg.reg, &(reg.val));
+           return 0;
+
+           /* Read address of MII PHY in use */
+   case SIOCGMIIPHY:
+           phy_id_lo = ioread32(card->ioaddr +
+                   MDIO_0_PHY_ID_LO_REG +
+                   (ADDRESS_DELTA * (iface->iface)));
+           phy_id_hi = ioread32(card->ioaddr +
+                   MDIO_0_PHY_ID_HI_REG +
+                   (ADDRESS_DELTA * (iface->iface)));
+           phy_id = (phy_id_hi << 16) | phy_id_lo;
+           data->phy_id = phy_id;
+           return 0;
+
+           /* Read an MII register */
+   case SIOCGMIIREG:
+           data->val_out = ioread32(card->ioaddr +
+                   MDIO_0_BASE + (ADDRESS_DELTA *
+                       (iface->iface)) +
+                   data->reg_num);
+           return 0;
+
+   default:
+           return -EOPNOTSUPP;
+   }
+
+   /* Should never reach here, but anyway :) */
+   return -EOPNOTSUPP;
+}
+
+/**
+ * nf2k_reg_read - handle register reads
+ * @dev:   net device
+ * @addr:  address
+ * @data:  the data
+ *
+ */
+int nf2k_reg_read(struct net_device *dev, unsigned int addr, void* data)
+{
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+   void *from_addr = card->ioaddr + addr;
+
+   if (!data) {
+       printk(KERN_WARNING "nf2:  WARNING: register read with data "
+               "address 0 requested\n");
+       return 1;
+   }
+
+   if (!card->ioaddr) {
+       printk(KERN_WARNING "nf2:  WARNING: card IO address is NULL "
+               "during register read\n");
+       return 1;
+   }
+
+   if (addr >= pci_resource_len(card->pdev, 0)) {
+       printk(KERN_ERR "nf2:  ERROR: address exceeds bounds (0x%lx) "
+           "during register read\n",
+           (long unsigned int)pci_resource_len(card->pdev, 0) - 1);
+       return 1;
+   }
+
+   memcpy_fromio(data, from_addr, sizeof(uint32_t));
+
+   return 0;
+}
+
+/**
+ * nf2k_reg_write - handle register writes
+ * @dev:   net device
+ * @addr:  address
+ * @data:  the data
+ *
+ */
+int nf2k_reg_write(struct net_device *dev, unsigned int addr, void* data)
+{
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+   void *to_addr = card->ioaddr + addr;
+
+   if (!data) {
+       printk(KERN_WARNING "nf2:  WARNING: register write with data"
+               " address 0 requested\n");
+       return 1;
+   }
+
+   if (!card->ioaddr) {
+       printk(KERN_WARNING "nf2:  WARNING: card IO address is NULL "
+               "during register write\n");
+       return 1;
+   }
+
+   if (addr >= pci_resource_len(card->pdev, 0)) {
+       printk(KERN_ERR "nf2:  ERROR: address exceeds bounds (0x%lx) "
+           "during register write\n",
+           (long unsigned int)pci_resource_len(card->pdev, 0) - 1);
+       return 1;
+   }
+
+   memcpy_toio(to_addr, data, sizeof(uint32_t));
+
+   return 0;
+}
+
+/**
+ * nf2c_stats - Return statistics to the caller
+ * @dev:   net device
+ *
+ */
+static struct net_device_stats *nf2c_stats(struct net_device *dev)
+{
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+   return &iface->stats;
+}
+
+/*
+ * Set the MAC address of the interface
+ */
+static int nf2c_set_mac_address(struct net_device *dev, void *a)
+{
+   struct sockaddr *addr = (struct sockaddr *) a;
+
+   /* Verify that the address is valid */
+   if (!is_valid_ether_addr(addr->sa_data))
+       return -EADDRNOTAVAIL;
+
+   /* Copy the MAC address into the dev */
+   memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+
+   return 0;
+}
+
+/*
+ * Deal with a transmit timeout.
+ *
+ * FIXME: Consider adding locking to protect the enable register
+ * (what if ifup is modified while this function is executing?)
+ * Also What happens if this is executed while the ISR is running?
+ * We need a lock on the intmask reg.
+ */
+static void nf2c_tx_timeout(struct net_device *dev)
+{
+   struct nf2_iface_priv *iface = netdev_priv(dev);
+   struct nf2_card_priv *card = iface->card;
+   u32 enable, intmask;
+
+   printk(KERN_ALERT "nf2: Transmit timeout on %s at %lu, latency %lu\n",
+           dev->name, jiffies, jiffies - dev->trans_start);
+
+   iface->stats.tx_errors++;
+
+   /* Read the current status of enable and interrupt mask registers */
+   enable = ioread32(card->ioaddr + CNET_REG_ENABLE);
+   intmask = ioread32(card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+
+   /* Reset the card! */
+   nf2_hw_reset(card);
+
+   /* Write the status of the enable registers */
+   iowrite32(enable, card->ioaddr + CNET_REG_ENABLE);
+   iowrite32(intmask, card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+
+   /* Clear the DMA flags */
+   nf2c_clear_dma_flags(card);
+
+   /* Call the send function if there's packets to send */
+   if (card->free_txbuffs != tx_pool_size)
+       nf2c_send(dev);
+
+   /* Wake the stalled queue */
+   netif_wake_queue(dev);
+   return;
+}
+
+/**
+ * nf2c_intr - Handle an interrupt
+ * @irq:   Irq number
+ * @dev_id:    devicd id
+ * @regs:  regs
+ *
+ * Note: Keep this as short as possible!
+ */
+static irqreturn_t nf2c_intr(int irq, void *dev_id
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19)
+           , struct pt_regs *regs
+#endif
+           )
+{
+
+   struct net_device *netdev = dev_id;
+   struct nf2_iface_priv *iface = netdev_priv(netdev);
+   struct nf2_card_priv *card = iface->card;
+   struct nf2_iface_priv *tx_iface;
+   unsigned long flags;
+   unsigned int ifnum;
+   u32 err;
+   u32 ctrl;
+   u32 status;
+   u32 status_orig;
+   u32 prog_status;
+   u32 int_mask;
+   u32 cnet_err;
+
+   unsigned int phy_intr_status;
+   int i;
+
+   /* get the interrupt mask */
+   int_mask = ioread32(card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+
+   /* disable interrupts so we don't get race conditions */
+   nf2_disable_irq(card);
+   smp_mb();
+
+   /* Grab the interrupt status */
+   status_orig = status = ioread32(card->ioaddr + CPCI_REG_INTERRUPT_STATUS);
+
+   if (status) {
+       PDEBUG(KERN_DFLT_DEBUG "nf2: intr mask vector: 0x%08x\n", int_mask);
+       PDEBUG(KERN_DFLT_DEBUG "nf2: intr status vector: 0x%08x\n", status);
+   }
+
+   /* only consider bits that are not masked plus INT_PKT_AVAIL*/
+   status &= ~(int_mask & ~INT_PKT_AVAIL);
+
+   /* Check if the interrrupt was generated by us */
+   if (status) {
+       PDEBUG(KERN_DFLT_DEBUG "nf2: intr to be handled: 0x%08x\n",
+               status);
+
+       /* Handle queue status change */
+       if (status & INT_DMA_QUEUE_STATUS_CHANGE) {
+           PDEBUG(KERN_DFLT_DEBUG "nf2: intr: "
+                   "INT_DMA_QUEUE_STATUS_CHANGE\n");
+
+           card->dma_can_wr_pkt =
+               ioread32(card->ioaddr +
+                   CPCI_REG_DMA_QUEUE_STATUS) & 0xffff;
+           PDEBUG(KERN_DFLT_DEBUG "nf2: can_wr_pkt status: 0x%04x\n",
+                   card->dma_can_wr_pkt);
+
+           /* Call the send function if there are other
+            * packets to send */
+           if (atomic_add_return(1, &card->dma_rx_in_progress) == 1) {
+               if (card->free_txbuffs != tx_pool_size)
+                   nf2c_send(netdev);
+           }
+           atomic_dec(&card->dma_rx_in_progress);
+       }
+
+       /* Handle packet RX complete
+        * Note: don't care about the rx pool here as the packet is
+        * copied to an skb immediately so there is no need to have
+        * multiple packets in the rx pool
+        */
+       if (status & INT_DMA_RX_COMPLETE) {
+           PDEBUG(KERN_DFLT_DEBUG "nf2: intr: "
+                   "INT_DMA_RX_COMPLETE\n");
+
+           pci_unmap_single(card->pdev, card->dma_rx_addr,
+                   MAX_DMA_LEN,
+                   PCI_DMA_FROMDEVICE);
+
+           card->wr_pool->len = ioread32(card->ioaddr +
+                   CPCI_REG_DMA_I_SIZE);
+
+           ctrl = ioread32(card->ioaddr + CPCI_REG_DMA_I_CTRL);
+           card->wr_pool->dev = card->ndev[(ctrl & 0x300) >> 8];
+
+           atomic_dec(&card->dma_rx_in_progress);
+
+           nf2c_rx(card->wr_pool->dev, card->wr_pool);
+
+           /* reenable PKT_AVAIL interrupts */
+           int_mask &= ~INT_PKT_AVAIL;
+       }
+
+       /* Handle packet TX complete */
+       if (status & INT_DMA_TX_COMPLETE) {
+           PDEBUG(KERN_DFLT_DEBUG "nf2: intr: "
+                   "INT_DMA_TX_COMPLETE\n");
+
+           /* make sure there is a tx dma in progress */
+           if (atomic_read(&card->dma_tx_in_progress)) {
+               pci_unmap_single(card->pdev, card->dma_tx_addr,
+                   card->txbuff[card->rd_txbuff].skb->len,
+                   PCI_DMA_TODEVICE);
+
+               /* Establish which iface we were sending the
+                * packet on */
+               ifnum = card->txbuff[card->rd_txbuff].iface;
+               tx_iface = netdev_priv(card->ndev[ifnum]);
+
+               /* Update the statistics */
+               tx_iface->stats.tx_packets++;
+               tx_iface->stats.tx_bytes +=
+                   card->txbuff[card->rd_txbuff].skb->len;
+
+               /* Free the skb */
+               dev_kfree_skb_irq(
+                   card->txbuff[card->rd_txbuff].skb);
+
+               /* Aquire a spinlock for the buffs vbles */
+               spin_lock_irqsave(&card->txbuff_lock, flags);
+
+               /* Note: make sure that txbuffs is incremented
+                * before dma_tx_in_progress is decremented due
+                * to the lack of locking in nf2c_send()
+                */
+               card->rd_txbuff = (card->rd_txbuff + 1) %
+                         tx_pool_size;
+               card->free_txbuffs++;
+               card->free_txbuffs_port[ifnum]++;
+               atomic_dec(&card->dma_tx_in_progress);
+
+               /* Re-enable the queues if necessary */
+               if (card->free_txbuffs_port[ifnum] == 1)
+                   netif_wake_queue(card->ndev[ifnum]);
+
+               spin_unlock_irqrestore(&card->txbuff_lock,
+                       flags);
+
+               /* Call the send function if there are other
+                * packets to send */
+               if (card->free_txbuffs != tx_pool_size)
+                   nf2c_send(netdev);
+           }
+       }
+
+       /* Handle PHY interrupts */
+       if (status & INT_PHY_INTERRUPT) {
+           PDEBUG(KERN_DFLT_DEBUG "nf2: intr: "
+                   "INT_PHY_INTERRUPT\n");
+
+           for (i = 0; i < MAX_IFACE; i++) {
+               phy_intr_status = ioread32(card->ioaddr +
+                       MDIO_0_INTR_STATUS +
+                       ADDRESS_DELTA * i);
+               PDEBUG(KERN_DFLT_DEBUG "PHY_INTR_STATUS for"
+                       " nf2c%d is %x\n", i,
+                       phy_intr_status);
+
+               if (phy_intr_status & INTR_LINK_STATUS_POS)
+                   nf2c_check_link_status(card,
+                           card->ndev[i], i);
+               else {
+                   PDEBUG(KERN_DFLT_DEBUG "---INT: not"
+                           " from nf2c%d\n", i);
+               }
+           }
+       }
+
+       /* Handle a packet RX notification
+        *
+        * Should not need to worry about this interrupt being asserted
+        * while a DMA transfer is in progress as the hardware should
+        * prevent this.
+        *
+        * ie. no need to do: !card->dma_rx_in_progress
+        */
+       if (status & INT_PKT_AVAIL) {
+           PDEBUG(KERN_DFLT_DEBUG "nf2: intr: INT_PKT_AVAIL\n");
+
+           if (atomic_add_return(1, &card->dma_rx_in_progress)
+                   == 1) {
+               PDEBUG(KERN_DFLT_DEBUG "nf2: dma_rx_in_progress"
+                   " is %d\n",
+                   atomic_read(&card->dma_rx_in_progress));
+               card->dma_rx_addr = pci_map_single(card->pdev,
+                       card->wr_pool->data,
+                       MAX_DMA_LEN,
+                       PCI_DMA_FROMDEVICE);
+               /* Start the transfer */
+               iowrite32(card->dma_rx_addr,
+                       card->ioaddr +
+                       CPCI_REG_DMA_I_ADDR);
+               iowrite32(DMA_CTRL_OWNER,
+                       card->ioaddr +
+                       CPCI_REG_DMA_I_CTRL);
+
+           } else {
+               PDEBUG(KERN_DFLT_DEBUG "nf2: received "
+                       "interrupt for new rx packet "
+                       "avail while still\n");
+               PDEBUG(KERN_DFLT_DEBUG "processing last packet"
+                       " - TODO for performance, "
+                       "that's ok for now.\n");
+               atomic_dec(&card->dma_rx_in_progress);
+           }
+           /* mask off subsequent PKT_AVAIL interrupts */
+           int_mask |= INT_PKT_AVAIL;
+       }
+
+       /* The cnet is asserting an error */
+       if (status & INT_CNET_ERROR) {
+           cnet_err = ioread32(card->ioaddr + CNET_REG_ERROR);
+           int_mask |= INT_CNET_ERROR;
+
+           printk(KERN_ERR "nf2: CNET error "
+                   "(CNET reg 0x%x : %08x).\n",
+                   CNET_REG_ERROR, cnet_err);
+       }
+
+       /* CNET read timeout */
+       if (status & INT_CNET_READ_TIMEOUT)
+           printk(KERN_ERR "nf2: CNET read timeout occurred\n");
+
+       /* Programming error occured */
+       if (status & INT_PROG_ERROR)
+           printk(KERN_ERR "nf2: CNET programming error\n");
+
+       /* DMA transfer error */
+       if (status & INT_DMA_TRANSFER_ERROR) {
+           err = ioread32(card->ioaddr + CPCI_REG_ERROR);
+           printk(KERN_ERR "nf2: DMA transfer error: 0x%08x\n",
+                   err);
+           if (err & ERR_DMA_RETRY_CNT_EXPIRED) {
+               printk(KERN_ERR "\t ERR_DMA_RETRY_CNT_EXPIRED"
+                       " - Too many unsuccessful "
+                       "retries.\n");
+           }
+           if (err & ERR_DMA_TIMEOUT) {
+               printk(KERN_ERR "\t ERR_DMA_TIMEOUT - DMA "
+                       "transfer took"
+                       " too long.\n");
+           }
+
+           /* Check the programming status */
+           prog_status = ioread32(card->ioaddr +
+                   CPCI_REG_PROG_STATUS);
+           if (!(prog_status & PROG_DONE)) {
+               printk(KERN_ERR "\t Note: Virtex is not "
+                       "currently"
+                       " programmed.\n");
+           }
+           nf2_reset_cpci(card);
+
+           nf2c_clear_dma_flags(card);
+
+           /* Call the send function if there's packets to send */
+           if (card->free_txbuffs != tx_pool_size)
+               nf2c_send(netdev);
+       }
+
+       /* DMA setup error */
+       if (status & INT_DMA_SETUP_ERROR) {
+           err = ioread32(card->ioaddr + CPCI_REG_ERROR);
+           printk(KERN_ERR "nf2: DMA setup error: 0x%08x\n", err);
+           if (err & ERR_DMA_RD_MAC_ERROR) {
+               printk(KERN_ERR "\t ERR_DMA_RD_MAC_ERROR - No "
+                       "data to read from MAC.\n");
+           }
+           if (err & ERR_DMA_WR_MAC_ERROR) {
+               printk(KERN_ERR "\t ERR_DMA_WR_MAC_ERROR - MAC "
+                       "Tx is full.\n");
+           }
+           if (err & ERR_DMA_WR_ADDR_ERROR) {
+               printk(KERN_ERR "\t ERR_DMA_WR_ADDR_ERROR - not"
+                       " on word boundary.\n");
+           }
+           if (err & ERR_DMA_RD_ADDR_ERROR) {
+               printk(KERN_ERR "\t ERR_DMA_RD_ADDR_ERROR - not"
+                       " on word boundary.\n");
+           }
+           if (err & ERR_DMA_WR_SIZE_ERROR) {
+               printk(KERN_ERR "\t ERR_DMA_WR_SIZE_ERROR - "
+                       "egress pkt too big (>2kB)\n");
+           }
+           if (err & ERR_DMA_RD_SIZE_ERROR) {
+               printk(KERN_ERR "\t ERR_DMA_RD_SIZE_ERROR - "
+                       "ingress pkt too big "
+                       "(>2kB)\n");
+           }
+           if (err & ERR_DMA_BUF_OVERFLOW) {
+               printk(KERN_ERR "\t ERR_DMA_BUF_OVERFLOW - CPCI"
+                       " internal buffer overflow\n");
+           }
+
+           nf2_reset_cpci(card);
+
+           nf2c_clear_dma_flags(card);
+
+           /* Call the send function if there's packets to send */
+           if (card->free_txbuffs != tx_pool_size)
+               nf2c_send(netdev);
+       }
+
+       /* DMA fatal error */
+       if (status & INT_DMA_FATAL_ERROR) {
+           err = ioread32(card->ioaddr + CPCI_REG_ERROR);
+           printk(KERN_ERR "nf2: DMA fatal error: 0x%08x\n", err);
+
+           nf2_reset_cpci(card);
+
+           nf2c_clear_dma_flags(card);
+
+           /* Call the send function if there's packets to send */
+           if (card->free_txbuffs != tx_pool_size)
+               nf2c_send(netdev);
+       }
+
+       /* Check for unknown errors */
+       if (status & INT_UNKNOWN)
+           printk(KERN_ERR "nf2: Unknown interrupt(s): 0x%08x\n",
+                   status);
+
+   }
+
+   if (status_orig)
+       PDEBUG(KERN_DFLT_DEBUG "nf2: Reenabling interrupts: mask is 0x%08x\n",
+               int_mask);
+
+   /* Rewrite the interrupt mask including any changes */
+   iowrite32(int_mask, card->ioaddr + CPCI_REG_INTERRUPT_MASK);
+
+   if (status)
+       return IRQ_HANDLED;
+   else
+       return IRQ_NONE;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 31)
+static const struct net_device_ops nf2c_netdev_ops = {
+   .ndo_open       = nf2c_open,
+   .ndo_stop       = nf2c_release,
+   .ndo_set_config     = nf2c_config,
+   .ndo_start_xmit     = nf2c_tx,
+#ifdef CONFIG_PCI
+   .ndo_do_ioctl       = nf2c_ioctl,
+#endif
+   .ndo_get_stats      = nf2c_stats,
+   .ndo_tx_timeout     = nf2c_tx_timeout,
+   /*  .ndo_set_multicast_list = */
+   /*  .ndo_change_mtu     = */
+   .ndo_set_mac_address    = nf2c_set_mac_address,
+   /*  .ndo_validate_addr  = */
+#ifdef CONFIG_NET_POLL_CONTROLLER
+   /*  .ndo_poll_controller    = */
+#endif
+};
+#endif
+
+/*
+ * Link Status Check
+ */
+static void nf2c_check_link_status(struct nf2_card_priv *card,
+       struct net_device *dev, unsigned int ifnum)
+{
+   unsigned int phy_aux_status;
+
+   phy_aux_status = ioread32(card->ioaddr + MDIO_0_AUX_STATUS + \
+           ADDRESS_DELTA * ifnum);
+   PDEBUG(KERN_DFLT_DEBUG "---PHY_AUX_STATUS is %x\n", phy_aux_status);
+
+   if (phy_aux_status & AUX_LINK_STATUS_POS) {
+       PDEBUG(KERN_DFLT_DEBUG "-----Link %d is up\n", ifnum);
+       netif_carrier_on(dev);
+   } else {
+       PDEBUG(KERN_DFLT_DEBUG "-----Link %d is down\n", ifnum);
+       netif_carrier_off(dev);
+   }
+}
+
+/**
+ * nf2c_init - The init function (sometimes called probe).
+ * @dev:   net device
+ *
+ * It is invoked by register_netdev()
+ */
+static void nf2c_init(struct net_device *dev)
+{
+   struct nf2_iface_priv *iface;
+
+   ether_setup(dev); /* assign some of the fields */
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 31)
+   dev->netdev_ops = &nf2c_netdev_ops;
+#else
+   dev->open            = nf2c_open;
+   dev->stop            = nf2c_release;
+   dev->set_config      = nf2c_config;
+   dev->hard_start_xmit = nf2c_tx;
+   dev->do_ioctl        = nf2c_ioctl;
+   dev->get_stats       = nf2c_stats;
+   dev->tx_timeout      = nf2c_tx_timeout;
+   dev->watchdog_timeo  = timeout;
+   dev->set_mac_address = nf2c_set_mac_address;
+   dev->mtu             = MTU;
+#endif
+   iface = netdev_priv(dev);
+   memset(iface, 0, sizeof(struct nf2_iface_priv));
+}
+
+/**
+ * nf2c_create_pool - Create the pool of buffers for DMA transfers
+ * @card:  nf2 card private data
+ *
+ * Only one is used by the control card
+ */
+static int nf2c_create_pool(struct nf2_card_priv *card)
+{
+   card->ppool = kmalloc(sizeof(struct nf2_packet), GFP_KERNEL);
+   if (card->ppool == NULL) {
+       printk(KERN_NOTICE "nf2: Out of memory while allocating "
+               "packet pool\n");
+       return -ENOMEM;
+   }
+   card->ppool->dev = NULL;
+   card->ppool->next = card->ppool;
+
+   card->rd_pool = card->wr_pool = card->ppool;
+
+   return 0;
+}
+
+/**
+ * nf2c_destroy_pool - Destroy the pool of buffers available for DMA transfers
+ * @card:  nf2 card private data
+ *
+ */
+static void nf2c_destroy_pool(struct nf2_card_priv *card)
+{
+   kfree(card->ppool);
+}
+
+/**
+ * nf2_probe - probe function
+ * @pdev:  PCI device
+ * @id:        PCI device id
+ * @card:  nf2 card private data
+ *
+ * Identifies the card, performs initialization and sets up the necessary
+ * data structures.
+ */
+int nf2c_probe(struct pci_dev *pdev, const struct pci_device_id *id,
+       struct nf2_card_priv *card)
+{
+   int ret = -ENODEV;
+
+   struct net_device *netdev;
+   struct nf2_iface_priv *iface;
+
+   int i;
+   int result;
+
+   int err;
+
+   char *devname = "nf2c%d";
+
+   /* Create the rx pool */
+   err = nf2c_create_pool(card);
+   if (err != 0) {
+       ret = err;
+       goto err_out_free_none;
+   }
+
+   /* Create the tx pool */
+   PDEBUG(KERN_DFLT_DEBUG "nf2: kmallocing memory for tx buffers\n");
+   card->txbuff = kmalloc(sizeof(struct txbuff) * tx_pool_size,
+           GFP_KERNEL);
+   if (card->txbuff == NULL) {
+       printk(KERN_ERR "nf2: Could not allocate nf2 user card "
+               "tx buffers.\n");
+       ret = -ENOMEM;
+       goto err_out_free_rx_pool;
+   }
+   card->free_txbuffs = tx_pool_size;
+   for (i = 0; i < MAX_IFACE; i++)
+       card->free_txbuffs_port[i] = tx_pool_size / MAX_IFACE;
+
+   /* Set up the network device... */
+   for (i = 0; i < MAX_IFACE; i++) {
+       netdev = card->ndev[i] = alloc_netdev(
+               sizeof(struct nf2_iface_priv),
+               devname, nf2c_init);
+       if (netdev == NULL) {
+           printk(KERN_ERR "nf2: Could not allocate ethernet "
+                   "device.\n");
+
+           ret = -ENOMEM;
+           goto err_out_free_etherdev;
+       }
+       netdev->irq = pdev->irq;
+       iface = (struct nf2_iface_priv *)netdev_priv(netdev);
+
+       iface->card = card;
+       iface->iface = i;
+
+       /*
+        * Assign the hardware address of the board: use "\0NF2Cx",
+        * where x is the device number.
+        */
+       memcpy(netdev->dev_addr, "\0NF2C0", ETH_ALEN);
+       netdev->dev_addr[ETH_ALEN - 1] = devnum++;
+
+       /* call the ethtool ops */
+       nf2_set_ethtool_ops(netdev);
+   }
+
+   /* Register the network devices */
+   PDEBUG(KERN_DFLT_DEBUG "nf2: registering network devices\n");
+   for (i = 0; i < MAX_IFACE; i++) {
+       if (card->ndev[i]) {
+           result = register_netdev(card->ndev[i]);
+           if (result) {
+               printk(KERN_ERR "nf2: error %i registering "
+                       "device \"%s\"\n",
+                       result,
+                       card->ndev[i]->name);
+           } else {
+               PDEBUG(KERN_ALERT "nf2: registered "
+                       "netdev %d\n", i);
+           }
+       }
+   }
+
+   nf2_dev = card->ndev[0];
+
+   /* If we make it here then everything has succeeded */
+   return 0;
+
+   /* Error handling points. Undo any resource allocation etc */
+err_out_free_etherdev:
+   for (i = 0; i < MAX_IFACE; i++)
+       if (card->ndev[i])
+           free_netdev(card->ndev[i]);
+   if (card->txbuff != NULL)
+       kfree(card->txbuff);
+
+err_out_free_rx_pool:
+   nf2c_destroy_pool(card);
+
+err_out_free_none:
+   return ret;
+}
+
+/**
+ * nf2c_remove - Called when the device driver is unloaded
+ * @pdev:  PCI device
+ * @card:  nf2 card private data
+ *
+ */
+void nf2c_remove(struct pci_dev *pdev, struct nf2_card_priv *card)
+{
+   int i;
+
+   /* Release the ethernet data structures */
+   for (i = 0; i < MAX_IFACE; i++) {
+       if (card->ndev[i]) {
+           unregister_netdev(card->ndev[i]);
+           free_netdev(card->ndev[i]);
+       }
+   }
+
+   /* Free any skb's in the transmit queue */
+   if (card->free_txbuffs != tx_pool_size) {
+       while (card->free_txbuffs < tx_pool_size) {
+           dev_kfree_skb(card->txbuff[card->rd_txbuff].skb);
+           card->rd_txbuff = (card->rd_txbuff + 1) % tx_pool_size;
+           card->free_txbuffs++;
+       }
+   }
+
+   /* Destroy the txbuffs */
+   if (card->txbuff != NULL)
+       kfree(card->txbuff);
+
+   nf2_dev = 0;
+
+   /* Destroy the rx pool */
+   nf2c_destroy_pool(card);
+}
+
+/**
+ * nf2_probe - Probe function for the card
+ * @pdev:  PCI device
+ * @id:        PCI device id
+ *
+ * Identifies the card, performs initialization and sets up the necessary
+ * data structures.
+ */
+static int nf2_probe(struct pci_dev *pdev, const struct pci_device_id *id)
+{
+   int ret = -ENODEV;
+   struct nf2_card_priv *card;
+   int rev;
+   int err;
+
+   /* Enable the device */
+   err = pci_enable_device(pdev);
+   if (err) {
+       printk(KERN_ERR "nf2: Unable to enable the PCI device, "
+               "aborting.\n");
+       goto err_out_none;
+   }
+
+
+   /* Grab the revision and make sure we know about it */
+   rev = nf2_get_revision(pdev);
+   printk(KERN_INFO "nf2: Found an NetFPGA-1G device (cfg revision "
+           "%d)...\n", rev);
+   if (rev != 0x00)
+       return -ENODEV;
+
+   /* Enable bus mastering */
+   PDEBUG(KERN_INFO "nf2: Enabling bus mastering\n");
+   pci_set_master(pdev);
+
+   /* Test to make sure we can correctly set the DMA mask */
+   PDEBUG(KERN_INFO "nf2: Setting DMA mask\n");
+   err = pci_set_dma_mask(pdev, 0xFFFFFFFFULL);
+   if (err) {
+       printk(KERN_ERR "nf2: No usable DMA configuration, "
+               "aborting.\n");
+       goto err_out_none;
+   }
+
+   /* Request the memory region corresponding to the card */
+   PDEBUG(KERN_INFO "nf2: Requesting memory region for NetFPGA-1G\n");
+   if (!request_mem_region(pci_resource_start(pdev, 0),
+               pci_resource_len(pdev, 0), "nf2")) {
+       printk(KERN_ERR "nf2: cannot reserve MMIO region\n");
+       goto err_out_none;
+   }
+
+   /* Create the card private data structure */
+   PDEBUG(KERN_INFO "nf2: kmallocing memory for nf2_card_priv\n");
+   card = (struct nf2_card_priv *)kmalloc(sizeof(struct nf2_card_priv),
+           GFP_KERNEL);
+   if (card == NULL) {
+       printk(KERN_ERR "nf2: Could not allocate memory for card "
+               "private data.\n");
+
+       ret = -ENOMEM;
+       goto err_out_free_mem_region;
+   }
+   /* Clear the contents of the data structure */
+   memset(card, 0, sizeof(struct nf2_card_priv));
+
+   /* Record the pdev corresponding to the card */
+   card->pdev = pdev;
+
+   /* Initialize the locking mechanisms */
+   PDEBUG(KERN_INFO "nf2: initializing data structures in card\n");
+   init_MUTEX(&card->state_lock);
+   spin_lock_init(&card->txbuff_lock);
+   atomic_set(&card->dma_tx_in_progress, 0);
+   atomic_set(&card->dma_rx_in_progress, 0);
+   atomic_set(&card->dma_tx_lock, 0);
+   atomic_set(&card->dma_rx_lock, 0);
+   /*spin_lock_init(&card->dma_tx_lock);*/
+   /*spin_lock_init(&card->dma_rx_lock);*/
+
+   /* Store the netdevice associated with the pdev */
+   pci_set_drvdata(pdev, card);
+
+   /* Map the memory region */
+   PDEBUG(KERN_INFO "nf2: mapping I/O space\n");
+   card->ioaddr = ioremap(pci_resource_start(pdev, 0),
+           pci_resource_len(pdev, 0));
+   if (!card->ioaddr) {
+       printk(KERN_ERR "nf2: cannot remap mem region %lx @ %lx\n",
+               (long unsigned int)pci_resource_len(pdev, 0),
+               (long unsigned int)pci_resource_start(pdev, 0));
+       goto err_out_free_card;
+   }
+
+   /* Disable all MACs */
+   iowrite32(0, card->ioaddr + CNET_REG_ENABLE);
+
+   /* Work out whether the card is a control or user card */
+   PDEBUG(KERN_INFO "nf2: calling control/user probe function\n");
+   card->is_ctrl = 1;
+   ret = nf2c_probe(pdev, id, card);
+   /*card->is_ctrl = nf2_is_control_board(card->ioaddr);
+     if (card->is_ctrl)
+     {
+     ret = nf2c_probe(pdev, id, card);
+     }
+     else
+     {
+     ret = nf2u_probe(pdev, id, card);
+     }*/
+
+   /* Check for errors from the control/user probes */
+   if (ret < 0)
+       goto err_out_iounmap;
+   else {
+       /* If we make it here then everything has succeeded */
+       PDEBUG(KERN_INFO "nf2: device probe succeeded\n");
+       return ret;
+   }
+
+   /* Error handling */
+err_out_iounmap:
+   iounmap(card->ioaddr);
+
+err_out_free_card:
+   pci_set_drvdata(pdev, NULL);
+   kfree(card);
+
+err_out_free_mem_region:
+   release_mem_region(pci_resource_start(pdev, 0),
+           pci_resource_len(pdev, 0));
+
+err_out_none:
+   pci_disable_device(pdev);
+   return ret;
+}
+
+/**
+ * nf2_remove - Remove the card
+ * @pdev:  PCI device
+ *
+ */
+static void nf2_remove(struct pci_dev *pdev)
+{
+   struct nf2_card_priv *card;
+
+   /* clean up any allocated resources and stuff here.
+    * like call release_region();
+    */
+   printk(KERN_ALERT "nf2: Unloading driver\n");
+
+   /* Get the private data */
+   card = (struct nf2_card_priv *)pci_get_drvdata(pdev);
+   if (card) {
+       /* Call the control/user release function */
+       nf2c_remove(pdev, card);
+       /*if (card->is_ctrl)
+         nf2c_remove(pdev, card);
+         else
+         nf2u_remove(pdev, card);*/
+
+       /* Unmap the IO memory region */
+       if (card->ioaddr) {
+           printk(KERN_ALERT "nf2: unmapping ioaddr\n");
+           iounmap(card->ioaddr);
+       }
+
+       /* Free the private data */
+       printk(KERN_ALERT "nf2: freeing card\n");
+       kfree(card);
+   }
+
+   /* Unset the driver data */
+   printk(KERN_ALERT "nf2: setting drvdata to NULL\n");
+   pci_set_drvdata(pdev, NULL);
+
+   /* Release the memory */
+   printk(KERN_ALERT "nf2: releasing mem region\n");
+   release_mem_region(pci_resource_start(pdev, 0),
+           pci_resource_len(pdev, 0));
+
+   /* Disable the device */
+   printk(KERN_ALERT "nf2: disabling device\n");
+   pci_disable_device(pdev);
+
+   printk(KERN_ALERT "nf2: finished removing\n");
+}
+
+/*****************************************************************
+ * NetFPGA Communication
+ *****************************************************************/
+void netfpga_write_register(unsigned reg, unsigned val)
+{
+   int retval = 0;
+
+   nf2k_reg_write(nf2_dev, reg, &(val)); 
+
+       if (retval) {
+           PDEBUG(9, "Error writing register %x\n", reg);
+   }   
+}
+
+unsigned netfpga_read_register(unsigned reg)
+{
+   int retval = 0;
+   unsigned val;
+
+   retval = nf2k_reg_read(nf2_dev, reg, &val);
+
+   if (retval) {
+       PDEBUG(9, "Error reading register %x\n", reg);
+   }
+   
+   return val; 
+}
+
+/*
+ * Strip the header off a bin file
+ *
+ * Does so by reading past the header
+ */
+void StripHeader(struct file* file, uint32_t *offset, uint32_t *len) 
+{
+   int code_header_size;
+   unsigned char * code_header;
+   int header_len;
+   uint32_t header_offset = *offset;
+
+   /* Malloc memory for the header */
+   code_header = (unsigned char *) kmalloc(sizeof(unsigned char) * READ_BUFFER_SIZE, GFP_KERNEL);
+
+   /* Read the first few bytes */
+   code_header_size = kernel_read(file, header_offset, code_header, 2);
+
+   /* Check to see if we're dealing with a header or not */
+   if (code_header_size && (code_header[0] != 0xff || code_header[1] != 0xff)) {
+       header_len = code_header[0] << 8 | code_header[1];
+       header_offset += code_header_size;
+ 
+       /* Read the header and skip a field */
+       code_header_size = kernel_read(file, header_offset, code_header, header_len + 2 + 1 + 2);
+       header_offset += code_header_size;
+
+       /* Read the ncd file name */
+       header_len = code_header[header_len + 2 + 1] << 8 | code_header[header_len + 2 + 1 + 1];
+       code_header_size = kernel_read(file, header_offset, code_header, header_len + 1 + 2);
+       header_offset += code_header_size;
+       printk("Bit file built from: %s\n", code_header);
+
+       /* Read the part name */
+           header_len = code_header[header_len + 1] << 8 | code_header[header_len + 1 + 1];
+       code_header_size = kernel_read(file, header_offset, code_header, header_len + 1 + 2);
+       header_offset += code_header_size;
+       printk("Part: %s\n", code_header);
+
+       /* Read the date */
+       header_len = code_header[header_len + 1] << 8 | code_header[header_len + 1 + 1];
+       code_header_size = kernel_read(file, header_offset, code_header, header_len + 1 + 2);
+       header_offset += code_header_size;
+       printk("Date: %s\n", code_header);
+
+       /* Read the time */
+       header_len = code_header[header_len + 1] << 8 | code_header[header_len + 1 + 1];
+       code_header_size = kernel_read(file, header_offset, code_header, header_len + 1 + 4);
+       header_offset += code_header_size;
+       printk("Time: %s\n", code_header);
+
+       (*len) -= (header_offset - (*offset));
+       /* Update the file offset */
+       *offset = header_offset;
+       }
+
+   /* Free the code_header variable */
+       kfree(code_header);
+}
+
+int DownloadVirtexCodeBlock(u_char *code_data, int code_data_size) 
+{
+   u_int result;
+   u_int data_word;
+   int bytes_left;
+   u_int count = 0;
+
+   bytes_left = code_data_size;
+   
+   while (bytes_left)
+   {
+       data_word = (u_int) (*code_data++); bytes_left--;
+       if (bytes_left) { data_word |= ((u_int) (*code_data++))<<8 ; bytes_left--;}
+       if (bytes_left) { data_word |= ((u_int) (*code_data++))<<16 ; bytes_left--;}
+       if (bytes_left) { data_word |= ((u_int) (*code_data++))<<24 ; bytes_left--;}
+
+       netfpga_write_register(CPCI_PROGRAMMING_DATA, data_word);
+
+       /* Every 8 words we need to check the FIFO - should always be empty!
+        * (or the done flag should be asserted)
+        */
+       if (++count == 8) {
+           count = 0;
+           while (((result = netfpga_read_register(CPCI_PROGRAMMING_STATUS)) & 0x10002) != 2 && (result & 0x100) != 0x100) {
+               if (result & 0x10000) {
+                   printk("INIT went active during programming - there was an error!\n");
+                   return 1;
+               }
+               //printk("Strange. FIFO wasnt empty... trying again.\n");
+               udelay(100);
+               result = netfpga_read_register(CPCI_PROGRAMMING_STATUS);
+               if ((result & 0x10002) != 2) {
+                   printk("Retrying ... FIFO still not empty. Giving up.\n");
+                   printk("Last status word read was 0x%0x\n", result);
+               }
+           }
+       }
+   }
+   return 0;
+}
+
+/*****************************************************************
+ * BORPH definitions
+ *****************************************************************/
+static ssize_t netfpga_send_iobuf (struct hwr_iobuf* iobuf)
+{
+   uint32_t *src;
+   int i;
+
+   PDEBUG(9, "Writing IOREG (size = %d bytes) to location 0x%x\n", iobuf->size, (unsigned int) (iobuf->location));
+   
+
+   src = (uint32_t*) iobuf->data;  
+   for (i = 0; i < iobuf->size; i +=sizeof(uint32_t))
+   {
+       netfpga_write_register(iobuf->location + i, *src);
+       src++; 
+   }
+
+   return iobuf->size;
+}
+
+static ssize_t netfpga_recv_iobuf (struct hwr_iobuf* iobuf)
+{
+   uint32_t *dst;
+   int i;
+
+   PDEBUG(9, "Reading IOREG (size = %d bytes) from location 0x%x\n", iobuf->size,  (unsigned int) (iobuf->location));
+
+   dst = (uint32_t*) iobuf->data;  
+   for (i = 0; i < iobuf->size; i +=sizeof(uint32_t))
+   {
+       *dst = netfpga_read_register(iobuf->location + i);
+       dst++; 
+   }
+
+   return iobuf->size;
+}
+
+static struct hwr_iobuf* netfpga_get_iobuf(void)
+{
+        PDEBUG(9, "Locking IOBUF\n");
+
+   /* If there is different buffer for differ hwr, should
+    * deferentiate them here using *reg* */
+
+   if (down_interruptible(&netfpga_mutex)) {
+           /* signal received, semaphore not acquired ... */
+       return NULL;
+   }
+
+   iobuf->cmd = 0;
+   iobuf->size = PAGE_SIZE - 12;
+   return iobuf;
+}
+
+static ssize_t netfpga_put_iobuf (struct hwr_iobuf* iobuf)
+{
+        PDEBUG(9, "Unlocking IOBUF\n");
+   up(&netfpga_mutex);
+   return 0; 
+}
+
+static int netfpga_configure(struct hwr_addr* addr, struct file* file, uint32_t offset, uint32_t len)
+{
+   int retval = -EIO;
+   u_int result;
+   u_int version;
+   int code_data_size;
+   unsigned char * code_data;
+   u_int retries;
+   int count, bytes_expected, bytes_sent;
+
+   printk("Configuring NetFPGA fpga #%u from (offset %u, len %u) of %s\n",
+          addr->addr, offset, len, file->f_dentry->d_name.name);
+
+   if (addr->addr != 0) {
+       printk("Invalid FPGA #%d for NetFPGA\n", addr->addr); /* NetFPGA only has 1 HWR */
+       goto out; 
+   }
+
+   if (down_interruptible(&netfpga_mutex)) {
+           /* signal received, semaphore not acquired ... */
+       goto out;
+   }
+
+       /*
+        * Identify what version of the board we are running
+        */
+   printk("Checking CPCI Version...");
+       version = netfpga_read_register(CPCI_ID);
+       version &= 0xffffff;
+
+   /* 
+         *  First, make sure the download interface is reset.
+         *  This flushes buffers, resets state machines etc.
+        */
+   netfpga_write_register(CPCI_PROGRAMMING_CONTROL, 1);
+
+       /* Clear the error registers */
+       netfpga_write_register(CPCI_ERROR, 0);
+
+       /* Wait a while for the PROG_B cycle to finish. */
+       udelay(100);
+
+       /* 
+         * Read programming status:
+         * Check that DONE bit (bit 8) is zero and FIFO (bit 1) is empty (1).
+        */
+       result = netfpga_read_register(CPCI_PROGRAMMING_STATUS);
+
+   if ((result & 0x102) != 0x2) 
+   {
+       printk("After resetting Programming interface, expected status to be 1 (FIFO empty).\n");
+       printk("However status & 0x102 is 0x%0x\n", (result & 0x102));
+       goto out_free_mutex;
+   }
+
+       /* Check the error register */
+       printk("Error Registers: %x\n", netfpga_read_register(CPCI_ERROR));
+       printk("Good, after resetting programming interface the FIFO is empty\n");
+
+   /* Sleep for a while to allow the INIT pin to be reset */
+       udelay(10000);
+       retries = 3;
+
+       while (netfpga_read_register(CPCI_PROGRAMMING_STATUS) & 0x10002)
+       {
+           if ((netfpga_read_register(CPCI_PROGRAMMING_STATUS) & 0x10000))
+                   udelay(10000);
+           else
+                   break;
+           retries--;
+
+           if (retries <= 0)
+           {
+                   printk("CPCI's INIT signal did not clear in time, exiting\n");
+                   printk("CPCI_PROGRAMMING_STATUS: 0x%08x\n", netfpga_read_register(CPCI_PROGRAMMING_STATUS));
+           goto out_free_mutex;
+           }
+       }
+   
+   /* Strip bitfile header if present */
+   StripHeader(file, &offset, &len);
+
+   count = 0;
+   bytes_expected = len;
+   bytes_sent = 0;
+
+   /* Read bitstream from file */
+   while (len > 0) {
+       count = min(PAGE_SIZE, len);
+       //printk("Reading (%d) bytes from file at offset 0x%x into 0x%x...\n", count, offset, netfpga_page);
+       retval = kernel_read(file, offset, netfpga_page, count);
+       if (retval < 0) {
+           goto out_free_mutex;
+       }
+       if (retval != count) {
+           printk("kernel_read returns (%d) less than requested (%d)...\n", retval, count);
+           count = retval;
+       }
+
+       len -= count;
+       offset += count;
+
+       retval = -EIO;
+
+       /* Download the configuration data */   
+       if (DownloadVirtexCodeBlock(netfpga_page, count)) {
+           printk("Configuration error -  %d bytes. (expected %d).\n", bytes_sent, bytes_expected);
+           goto out_free_mutex;
+       }   
+       bytes_sent += count;        
+   }
+
+   printk("Configuration downloaded -  %d bytes. (expected %d).\n", bytes_sent, bytes_expected);
+    
+   /*
+        * Now wait to see that DONE goes high (bit 8) and INIT (16) is low
+        */
+       for (retries=0; retries<3; retries++) 
+   {
+           udelay(1000);
+           result = netfpga_read_register(CPCI_PROGRAMMING_STATUS);
+           if  ((result & 0x100) == 0x100 ) { 
+                   printk("DONE went high - chip has been successfully programmed.\n");
+                   goto prog_completed;
+           }
+           if  ((result & 0x10000) == 0x10000 ) { 
+                   printk("INIT went high - appears to be a programming error.\n");
+                   goto out_free_mutex;
+           }
+           if (retries == 2) {
+                   printk("DONE has not gone high - looks like an error\n");
+                   goto out_free_mutex;
+           }
+       }
+
+prog_completed:
+       /* Read the current value of the control register so that we can modify it to do a reset */
+       result = netfpga_read_register(CPCI_CTRL);
+
+       /* Write to the control register to reset it */
+       netfpga_write_register(CPCI_CTRL, result | 0x100);
+
+       /* Sleep for a while to let the reset complete */
+       udelay(2000);
+
+   /* reset the PHYs */
+       netfpga_write_register(MDIO_0_CONTROL_REG, 0x8000);
+       netfpga_write_register(MDIO_1_CONTROL_REG, 0x8000);
+       netfpga_write_register(MDIO_2_CONTROL_REG, 0x8000);
+       netfpga_write_register(MDIO_3_CONTROL_REG, 0x8000);
+
+       /* wait until the resets have been completed */
+       udelay(100);
+
+   /* Verify device info */
+
+   /* reset the PHYs */
+       netfpga_write_register(MDIO_0_CONTROL_REG, 0x8000);
+       netfpga_write_register(MDIO_1_CONTROL_REG, 0x8000);
+       netfpga_write_register(MDIO_2_CONTROL_REG, 0x8000);
+       netfpga_write_register(MDIO_3_CONTROL_REG, 0x8000);
+
+   /* Verify device info */
+
+   retval = 0;
+out_free_mutex:
+   up(&netfpga_mutex);
+out:
+   return retval;  
+}
+
+static int netfpga_unconfigure(struct hwr_addr* addr)
+{
+   return 0;
+}
+
+struct phyhwr* netfpga_reserve_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* ret;
+   if (a && a->class != HAC_NETFPGA) {
+                return NULL;
+        }
+   
+   /* safety check */
+   if (a->addr >= 1)
+       return NULL;
+
+   ret = phyhwrs[a->class][a->addr];
+   if (!atomic_inc_and_test(&ret->count)) {
+       atomic_dec(&ret->count);
+       /* was being used */
+       return NULL;
+   }
+   /* count is now a usage count */
+   atomic_inc(&ret->count);
+   return ret;
+}
+
+void netfpga_release_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* hwr;
+   if (a && a->class != HAC_NETFPGA)
+       return;
+
+   /* safety check */
+   if (a->addr >= 1)
+       return;
+   
+   hwr = phyhwrs[a->class][a->addr];
+   if (atomic_dec_and_test(&hwr->count)) {
+       hwr->task = NULL;
+       atomic_set(&hwr->count, -1);
+   }
+}
+
+static struct hwr_operations netfpga_hwr_operations = {
+   .configure = netfpga_configure,
+   .unconfigure = netfpga_unconfigure,
+   .reserve_hwr = netfpga_reserve_hwr,
+   .release_hwr = netfpga_release_hwr,
+   .get_iobuf = netfpga_get_iobuf,
+   .put_iobuf = netfpga_put_iobuf,
+   .send_iobuf = netfpga_send_iobuf,
+   .recv_iobuf = netfpga_recv_iobuf
+};
+
+static struct hwrtype hwrtype_netfpga = {
+   name: "netfpga",
+   type: HAC_NETFPGA,
+   count: ATOMIC_INIT(0),
+        num_devs: 1,
+   hwr_ops: &netfpga_hwr_operations,
+};
+
+/*
+ * pci_driver structure to set up callbacks for various PCI events
+ */ 
+static struct pci_driver pci_driver = {
+   .name = "nf2",
+   .id_table = ids,
+   .probe = nf2_probe,
+   .remove = nf2_remove,
+};
+
+static int __init hwrtype_netfpga_init(void)
+{
+   int retval = 0;
+   int i;
+
+   if ((retval = register_hwrtype(&hwrtype_netfpga)) < 0) {
+       printk("Error registering hwrtype\n");
+       goto out;
+   } else {
+       printk("NetFPGA Hardware Region (HWR) version 2.0 registered\n");
+   }
+
+   /* initialize hwr */
+        atomic_set(&(phyhwrs[HAC_NETFPGA][0])->count, -1);
+           
+   /* initialize iobuf memory */
+   netfpga_page = (buf_t*)__get_free_page(GFP_KERNEL);
+   iobuf = (struct hwr_iobuf*) kmalloc(sizeof(struct hwr_iobuf), GFP_KERNEL);
+   if (iobuf) {
+       iobuf->data = netfpga_page + 12;
+       iobuf->size = PAGE_SIZE - 12;
+   } else {
+       printk("failed getting memory for netfpga iobuf\n");
+       retval = -ENOMEM;
+       goto out;
+   }
+
+   /* Register PCI Driver */
+   pci_register_driver(&pci_driver);
+
+   /* Should reprogram the CPCI here !! */
+   
+   return 0;
+
+out:
+   return retval;
+}
+
+static void __exit hwrtype_netfpga_exit(void)
+{
+   /* Unregister PCI driver */
+   pci_unregister_driver(&pci_driver);
+
+   /* Free iobuf */
+   if (iobuf) {
+       kfree(iobuf);
+   }
+
+   if (netfpga_page) {
+       free_page((unsigned long) netfpga_page);
+   }
+
+   if (unregister_hwrtype(&hwrtype_netfpga)) {
+       printk("Error unregistering hwrtype_netfpga\n");
+   } else {
+       printk("NetFPGA Hardware Region (HWR) version 2.0 unregistered");
+   }
+}
+
+module_init(hwrtype_netfpga_init);
+module_exit(hwrtype_netfpga_exit);
+
+MODULE_AUTHOR("Brandon Hamilton");
+MODULE_DESCRIPTION("Add hwrtype netfpga to program FPGA on NetFPGA as hw process");
+MODULE_LICENSE("GPL");
\ No newline at end of file
diff --git a/kernel/hwr/hwrtype_rhino.c b/kernel/hwr/hwrtype_rhino.c
new file mode 100644
index 0000000..ae14173
--- /dev/null
+++ b/kernel/hwr/hwrtype_rhino.c
@@ -0,0 +1,677 @@
+/*********************************************************************
+ * File  : kernel/hwr/hwrtype_rhino.c
+ * Author: Brandon Hamilton
+ * Date  : 18/02/2011
+ * Description:
+ *   Define hwrtype for RHINO board
+ *		This file deals with the platform specific functions for
+ *      communication with the FPGA.
+ *********************************************************************/
+#include <linux/fs.h>
+#include <linux/module.h>
+#include <linux/slab.h>    /* kmalloc/kfree */
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/ioport.h>  /* request_mem_region */
+#include <linux/spi/spi.h>
+
+#include <mach/gpio.h>
+
+#include <asm/io.h>
+
+#include <linux/bof.h>
+#include <linux/borph.h>
+#define HDEBUG
+#define HDBG_NAME "hwrtype_rhino"
+#define HDBG_LVL 9
+#include <linux/hdebug.h>
+
+/*
+ * A static buffer for data transfer.  It should be expanded to a 
+ * kmem_cache when higher performance is needed.  (Right now, there
+ * can only be one ioreg performing I/O at a time.
+ */
+static buf_t* rhino_page;
+static struct hwr_iobuf* iobuf;
+
+struct rhino_fpga_device {
+	struct spi_device *spi;
+};
+
+/* Buffers used for asynchronous configuration data transfers */
+struct config_transfer_part {
+	buf_t* page;
+	struct spi_transfer	transfer;
+	struct spi_message	message;
+	int number;
+	char last;
+	
+};
+static atomic_t config_transfer_parts;
+struct kmem_cache *config_transport_part_cache;
+
+/* Bus mapping for GPMC */
+typedef struct fpga_map {
+	resource_size_t cs0_base;
+	void __iomem *cs0_virtual;
+	resource_size_t cs1_base;
+	void __iomem *cs1_virtual;
+	resource_size_t cs2_base;
+	void __iomem *cs2_virtual;
+	resource_size_t cs3_base;
+	void __iomem *cs3_virtual;
+	resource_size_t cs4_base;
+	void __iomem *cs4_virtual;
+	resource_size_t cs5_base;
+	void __iomem *cs5_virtual;
+} rhino_fpga_map_t;
+
+static rhino_fpga_map_t *rhino_fpga_bus;
+
+struct rhino_fpga_device *rhino_fpga;
+
+DECLARE_COMPLETION(configuration_data_sent);
+
+/* Mutex Semaphore to ensure proper access to page buffer */
+static DEFINE_SEMAPHORE(rhino_mutex);
+
+/* FPGA configuration pins definitions */
+#define PROG_B     126
+#define INIT_B     127
+#define INIT_B_DIR 129
+#define DONE       128
+
+#define CFG_INITB_WAIT 4000000 //100000
+#define CFG_DONE_WAIT  100000
+                        
+#define FPGA_VCCINT		99
+#define FPGA_VCCO_AUX	100
+#define FPGA_VCCMGT		101
+
+#define FPGA_CS0_BASE		0x08000000
+#define FPGA_CS1_BASE		0x10000000
+#define FPGA_CS2_BASE		0x18000000
+#define FPGA_CS3_BASE		0x20000000
+#define FPGA_CS4_BASE		0x28000000
+#define FPGA_CS5_BASE		0x38000000
+
+static void rhino_set_fpga_psu(int enable)
+{
+	/* Enable power to FPGA */
+    gpio_direction_output(FPGA_VCCINT, enable);
+    gpio_direction_output(FPGA_VCCO_AUX, enable);
+    gpio_direction_output(FPGA_VCCMGT, enable);
+}
+/*****************************************************************
+ * functions definitions
+ *****************************************************************/
+
+static unsigned int get_mapped_location(unsigned int reg_loc) {
+	unsigned int location = reg_loc;
+	if (reg_loc >= FPGA_CS0_BASE && reg_loc < FPGA_CS0_BASE + SZ_128M) {
+		location = rhino_fpga_bus->cs0_virtual + (reg_loc - FPGA_CS0_BASE);
+	} else if (reg_loc >= FPGA_CS1_BASE && reg_loc < FPGA_CS1_BASE + SZ_128M) {
+		location = rhino_fpga_bus->cs1_virtual + (reg_loc - FPGA_CS1_BASE);
+	} else if (reg_loc >= FPGA_CS2_BASE && reg_loc < FPGA_CS2_BASE + SZ_128M) {
+		location = rhino_fpga_bus->cs2_virtual + (reg_loc - FPGA_CS2_BASE);
+	} else if (reg_loc >= FPGA_CS3_BASE && reg_loc < FPGA_CS3_BASE + SZ_128M) {
+		location = rhino_fpga_bus->cs3_virtual + (reg_loc - FPGA_CS3_BASE);
+	} else if (reg_loc >= FPGA_CS4_BASE && reg_loc < FPGA_CS4_BASE + SZ_128M) {
+		location = rhino_fpga_bus->cs4_virtual + (reg_loc - FPGA_CS4_BASE);
+	} else if (reg_loc >= FPGA_CS5_BASE && reg_loc < FPGA_CS5_BASE + SZ_128M) {
+		location = rhino_fpga_bus->cs5_virtual + (reg_loc - FPGA_CS5_BASE);
+	}
+	return location;
+}
+
+static ssize_t rhino_send_iobuf (struct hwr_iobuf* iobuf)
+{	
+	int count;
+	unsigned short *src;
+	unsigned int dst;
+	int i;
+
+	count = iobuf->size / sizeof(unsigned short);
+	src = (unsigned short *)iobuf->data;	
+	dst = get_mapped_location(iobuf->location) + iobuf->offset;	
+
+	/* Uncomment for Debugging
+	 * PDEBUG(9, "Writing data to RHINO FPGA Register (%d bytes) at location 0x%x\n", iobuf->size, dst);
+	 */
+
+	/* Write 16-bit words to the GPMC bus */
+	for (i = 0; i < count; i++) {
+		__raw_writew(*src, dst);
+		dst += sizeof(unsigned short);
+		src++; 
+	}
+
+	return (count * sizeof(unsigned short));
+}
+
+static ssize_t rhino_recv_iobuf (struct hwr_iobuf* iobuf)
+{
+	int count;
+	unsigned short *dst;
+	unsigned int src;
+	int i;
+
+	count = iobuf->size / sizeof(unsigned short);
+	dst = (unsigned short *)iobuf->data;	
+	src = get_mapped_location(iobuf->location) + iobuf->offset;
+
+	/* Uncomment for Debugging
+	 * PDEBUG(9, "Reading data from RHINO FPGA register (%d bytes) at location 0x%x\n", iobuf->size,  src);
+	 */
+	 
+	/* Read 16-bit words from the GPMC bus */
+	for (i = 0; i < count; i++){
+		*dst = __raw_readw(src);
+		src += sizeof(unsigned short);
+		dst++; 
+	}
+
+	return (count * sizeof(unsigned short));
+}
+
+static struct hwr_iobuf* rhino_get_iobuf(void)
+{
+	if (down_interruptible(&rhino_mutex)) {
+	    /* signal received, semaphore not acquired ... */
+		return NULL;
+	}
+	iobuf->size = PAGE_SIZE - 12;
+	return iobuf;
+}
+
+static ssize_t rhino_put_iobuf (struct hwr_iobuf* iobuf)
+{
+	up(&rhino_mutex);
+	return 0;
+}
+
+static void spi_transfer_completed(void *buf) 
+{
+	struct config_transfer_part *ctp = buf;
+	int status = ctp->message.status;
+	free_page(ctp->page);
+	kmem_cache_free(config_transport_part_cache, ctp);
+	if (status == 0) {
+		/* Transfer succeeded */
+		atomic_dec(&config_transfer_parts);	
+	}
+	else {
+		/* Transfer failed */
+		PDEBUG(9, "SPI transfer failed with status: %d...\n", status);
+		atomic_set(&config_transfer_parts, -1);
+	}
+
+	/* Indicate to configuration function that SPI transfers are done */
+	if (ctp->last || status) {
+		complete(&configuration_data_sent);
+	}
+}
+
+static void setup_config_transport_part(struct config_transfer_part *ctp, int len)
+{
+	/* Setup SPI transfer request */
+	memset(&ctp->transfer, 0, sizeof (struct spi_transfer));
+	ctp->transfer.tx_buf = ctp->page;
+	ctp->transfer.len = len;
+	/* Setup SPI message */
+	spi_message_init(&ctp->message);
+	spi_message_add_tail(&ctp->transfer, &ctp->message);
+	/* Use asynchronous callback method */
+	ctp->message.complete = spi_transfer_completed;
+	ctp->message.context  = ctp;
+}
+
+static int rhino_configure(struct hwr_addr* addr, struct file* file, uint32_t offset, uint32_t len)
+{
+	/*
+	 * Xilinx XAPP 502: Using a Microprocessor to Configure Xilinx FPGAs
+	 *   via Slave Serial Mode.
+	 *   _____________                _____________ 
+	 *  |   Assert    |              |  Send bit   |
+	 *  | NOT_PROGRAM |        ----->|  of Data    |<----
+	 *  |_____________|        |     |_____________|    |
+	 *         | > 300ns       |            |           | More
+	 *   ______v______         |      ______v______     | Data
+	 *  |   Deassert  |        |     |  Increment  |    |
+	 *  | NOT_PROGRAM |        |     |   Address   |-----
+	 *  |_____________|        |     |   Counter   | 
+	 *         |<------------  |     |_____________|
+	 *   ______v________ No |  |            |
+	 *  |   Check for   |   |  |      ______v______
+	 *  | NOT_INIT high |----  |     |  Check for  |  
+	 *  |_______________|      |     |  DONE high  |
+	 *         |__________Yes__|     |_____________|
+	 */
+	int i;
+	int count;
+	int retval = -EIO;
+	u16* src;
+	int number;
+	PDEBUG(9, "Configuring RHINO HWR %u from (offset %u, len %u) of %s\n", addr->addr, offset, len, file->f_dentry->d_name.name);
+
+	if (addr->addr != 0) {
+		PDEBUG(9, "Invalid FPGA #%d for RHINO\n", addr->addr); /* Rhino only has 1 HWR */
+		goto out; 
+	}
+
+	if (!rhino_fpga) {
+		PDEBUG(9, "FPGA configuration error: Invalid SPI device\n");
+		goto out;
+	}
+
+	if (down_interruptible(&rhino_mutex)) {
+	    /* signal received, semaphore not acquired ... */
+		goto out;
+	}
+
+	/*************************************************
+	 * Initialize the FPGA		                     *
+	 *************************************************/
+	/* Turn on FPGA */
+	rhino_set_fpga_psu(1);
+
+	/* Reset the FPGA */
+	gpio_direction_output(PROG_B, 1);	
+
+	/*************************************************
+	 * Clear Configuration Memory                    *
+	 *************************************************/
+	PDEBUG(9, "[1] Clear Configuration Memory\n");
+
+	/* Start to clear configuration memory */
+	gpio_set_value(PROG_B, 0);
+
+	/* Wait for FPGA initialization */
+	gpio_direction_input(INIT_B);
+	for (i=0; i < CFG_INITB_WAIT + 1; i++) {
+		if (!gpio_get_value(INIT_B)) {
+			break;
+		}
+		if (i == CFG_INITB_WAIT) {
+			PDEBUG(9, "Warning: INIT_B did not go low during PROG_B pulse\n");
+		}
+	}
+					
+	/* Clear configuration memory */
+	gpio_set_value(PROG_B, 1);
+
+	/*************************************************
+	 * Bitstream Loading                             *
+	 *************************************************/
+
+	PDEBUG(9, "[2] Loading Bitstream\n");
+	/* Wait for FPGA to be ready for configuration data */
+	gpio_direction_input(INIT_B);
+	for (i=0; i < CFG_INITB_WAIT + 1; i++) {
+		if (gpio_get_value(INIT_B)) {
+			break;
+		}
+		if (i == CFG_INITB_WAIT) {
+			PDEBUG(9, "FPGA configuration error: Could not initialize FPGA for transfer\n");
+			goto out_free_mutex;
+		}
+	}
+
+	/* Transfer configuration data to FPGA using SPI (DMA) */
+	atomic_set(&config_transfer_parts, 0);
+	count = 0;
+	number = 0;
+	while (len > 0) {
+		/* Setup buffer to hold segment of configuration data */
+		struct config_transfer_part* ctp = kmem_cache_alloc(config_transport_part_cache, GFP_KERNEL);
+		ctp->page = (buf_t*)__get_free_page(GFP_KERNEL | GFP_DMA);
+		ctp->number = ++number;
+		/* Read configuration data into buffer */
+		count = min(PAGE_SIZE, len);
+		retval = kernel_read(file, offset, ctp->page, count);
+		if (retval < 0) {
+			free_page(ctp->page);
+			kmem_cache_free(config_transport_part_cache, ctp);
+			goto out_free_mutex;
+		}
+		if (retval != count) {
+			PDEBUG(9, "kernel_read returns less than requested...\n");
+			count = retval;
+		}
+
+		len -= count;
+		offset += count;
+
+		if (atomic_inc_and_test( &config_transfer_parts )) {
+			PDEBUG(9, "FPGA configuration error: Configuration data write over SPI failed (%d)\n", retval);
+			goto out_free_mutex;
+		}
+
+		setup_config_transport_part(ctp, count);
+		ctp->last = count < PAGE_SIZE;
+
+		/* Send configuration data over SPI using DMA */
+		spi_async(rhino_fpga->spi, &ctp->message);
+	}
+
+	/* Wait for signal that all configuration data has been sent */
+	wait_for_completion(&configuration_data_sent);
+
+	PDEBUG(9, "[3] CRC Check\n");
+	/* CRC Check */
+	if(!(gpio_get_value(INIT_B)))
+	{
+		PDEBUG(9, "FPGA configuration error: CRC check failed\n");
+		goto out_free_mutex;
+	}
+
+	/*************************************************
+	 * Startup sequence                              *
+	 *************************************************/
+	PDEBUG(9, "[4] Checking configuration results\n");
+	gpio_direction_input(DONE);
+	for (i=0; i <= CFG_DONE_WAIT; i++) {
+		if(gpio_get_value(DONE)) {
+			break;
+		}
+		else {
+			PDEBUG(9, "FPGA configuration error: Error in startup sequence, DONE pin not asserted\n");
+			goto out_free_mutex;
+    	}
+    }
+
+	PDEBUG(9, "RHINO HWR %u configuration completed successfully\n", addr->addr);
+	retval = 0;
+
+out_free_mutex:
+	up(&rhino_mutex);
+out:
+	return retval;	
+}
+
+static int rhino_unconfigure(struct hwr_addr* addr)
+{
+	rhino_set_fpga_psu(0);
+	PDEBUG(9, "Unconfiguring RHINO HWR %u\n", addr->addr);
+	return 0;
+}
+
+
+
+struct phyhwr* rhino_reserve_hwr(struct hwr_addr* a)
+{
+	struct phyhwr* ret;
+	if (a && a->class != HAC_RHINO) {
+                return NULL;
+        }
+	
+	/* safety check */
+	if (a->addr >= 1)
+		return NULL;
+
+	ret = phyhwrs[a->class][a->addr];
+	if (!atomic_inc_and_test(&ret->count)) {
+		atomic_dec(&ret->count);
+		/* was being used */
+		return NULL;
+	}
+	/* count is now a usage count */
+	atomic_inc(&ret->count);
+
+	return ret;
+}
+
+void rhino_release_hwr(struct hwr_addr* a)
+{
+	struct phyhwr* hwr;
+	if (a && a->class != HAC_RHINO)
+		return;
+
+	/* safety check */
+	if (a->addr >= 1)
+		return;
+	
+	hwr = phyhwrs[a->class][a->addr];
+	if (atomic_dec_and_test(&hwr->count)) {
+		hwr->task = NULL;
+		atomic_set(&hwr->count, -1);
+	}
+}
+
+static struct hwr_operations rhino_hwr_operations = {
+	.configure = rhino_configure,
+	.unconfigure = rhino_unconfigure,
+	.reserve_hwr = rhino_reserve_hwr,
+	.release_hwr = rhino_release_hwr,
+	.get_iobuf   = rhino_get_iobuf,
+	.put_iobuf   = rhino_put_iobuf,
+	.send_iobuf  = rhino_send_iobuf,
+	.recv_iobuf  = rhino_recv_iobuf
+};
+
+static struct hwrtype hwrtype_rhino = {
+	name: "rhino",
+	type: HAC_RHINO,
+	count: ATOMIC_INIT(0),
+    num_devs: 1,
+	hwr_ops: &rhino_hwr_operations,
+};
+
+static int __devinit fpga_probe(struct spi_device *spi)
+{
+	int retval = 0;
+	printk("RHINO Spartan-6 FPGA interface driver");
+
+	spi->mode = SPI_MODE_0;
+	spi->max_speed_hz = 48000000;
+	retval = spi_setup(spi);
+	if (retval < 0)
+		return retval;
+
+	rhino_fpga = kzalloc(sizeof(struct rhino_fpga_device), GFP_KERNEL);
+	if (rhino_fpga == NULL) {
+		dev_err(&spi->dev, "failed to allocate memory\n");
+		return -ENOMEM;
+	}
+
+	rhino_fpga->spi = spi;
+	spi_set_drvdata(spi, rhino_fpga);
+
+	return retval;
+}
+
+static int __devexit fpga_remove(struct spi_device *spi)
+{
+	return 0;
+}
+
+
+static struct spi_driver rhino_spartan6_driver = {
+	.driver = {
+		.name	= "rhino-spartan6",
+		.bus	= &spi_bus_type,
+		.owner	= THIS_MODULE,
+	},
+	.probe	= fpga_probe,
+	.remove = __devexit_p(fpga_remove),
+};
+
+static void hwrtype_rhino_cleanup(void) {
+
+	/* Release GPMC bus mappings */
+	if (rhino_fpga_bus) {
+#define release_rhino_gmpc(p, q) \
+	if(rhino_fpga_bus->p##_virtual){ \
+		iounmap(rhino_fpga_bus->p##_virtual); \
+		rhino_fpga_bus->p##_virtual = NULL; \
+	} \
+	if(rhino_fpga_bus->p##_base){ \
+		release_mem_region(rhino_fpga_bus->p##_base, SZ_128M); \
+		rhino_fpga_bus->p##_base = 0; \
+	}
+
+	release_rhino_gmpc(cs0, CS0)
+	release_rhino_gmpc(cs1, CS1)
+	release_rhino_gmpc(cs2, CS2)
+	//release_rhino_gmpc(cs3, CS3)
+	//release_rhino_gmpc(cs4, CS4)
+	//release_rhino_gmpc(cs5, CS5)
+#undef release_rhino_gmpc
+
+		kfree(rhino_fpga_bus);
+		rhino_fpga_bus = NULL;
+	}
+
+	/* Free iobuf */
+	if (iobuf) {
+		kfree(iobuf);
+		iobuf = NULL;
+	}
+
+	if (rhino_page) {
+		free_page((unsigned long) rhino_page);
+		rhino_page = NULL;
+	}
+
+	if (config_transport_part_cache) {
+		kmem_cache_destroy(config_transport_part_cache);
+		config_transport_part_cache = NULL;
+	}
+
+	spi_unregister_driver(&rhino_spartan6_driver);
+
+	if (unregister_hwrtype(&hwrtype_rhino)) {
+		printk("Error unregistering RHINO HWR\n");
+	} else {
+		printk("Unregistered RHINO HWR\n");
+	}
+}
+
+static int __init hwrtype_rhino_init(void) {
+	int retval = 0;
+	rhino_fpga = 0;
+
+	if ((retval = register_hwrtype(&hwrtype_rhino)) < 0) {
+		printk("Error registering RHINO HWR\n");
+		goto out;
+	} else {
+		printk("Registered RHINO HWR\n");
+	}
+
+	/* initialize hwr */
+    atomic_set(&(phyhwrs[HAC_RHINO][0])->count, -1);
+	      	
+	/* initialize iobuf memory */
+	rhino_page = (buf_t*)__get_free_page(GFP_KERNEL);
+	iobuf = (struct hwr_iobuf*) kmalloc(sizeof(struct hwr_iobuf), GFP_KERNEL);
+	if (iobuf) {
+		iobuf->data = rhino_page + 12;
+		iobuf->size = PAGE_SIZE - 12;
+	} else {
+		printk("Failed getting memory for RHINO iobuf\n");
+		retval = -ENOMEM;
+		goto out;
+	}
+
+	/* Map GPMC memory regions */
+	rhino_fpga_bus = kmalloc(sizeof(rhino_fpga_map_t), GFP_KERNEL);
+	if (rhino_fpga_bus == NULL) {
+		printk("Failed getting memory for RHINO FPGA bus mapping\n");
+		free_page((unsigned long) rhino_page);
+		rhino_page = 0;
+		kfree(iobuf);
+		iobuf = 0;
+		retval = -ENOMEM;
+		goto out;	
+	}
+
+	rhino_fpga_bus->cs0_base = 0;
+	rhino_fpga_bus->cs0_virtual = NULL;
+	rhino_fpga_bus->cs1_base = 0;
+	rhino_fpga_bus->cs1_virtual = NULL;
+	rhino_fpga_bus->cs2_base = 0;
+	rhino_fpga_bus->cs2_virtual = NULL;
+	rhino_fpga_bus->cs3_base = 0;
+	rhino_fpga_bus->cs3_virtual = NULL;
+	rhino_fpga_bus->cs4_base = 0;
+	rhino_fpga_bus->cs4_virtual = NULL;
+	rhino_fpga_bus->cs5_base = 0;
+	rhino_fpga_bus->cs5_virtual = NULL;
+
+#define map_rhino_gmpc(p, q)  \
+	if(!request_mem_region(FPGA_##q##_BASE, SZ_128M, "rhino-fpga-" #p)){ \
+		printk("Unable to request memory region 0x%08x for GPMC\n", FPGA_##q##_BASE); \
+		hwrtype_rhino_cleanup(); \
+		return -ENOMEM; \
+	} \
+	rhino_fpga_bus->p##_base = FPGA_##q##_BASE; \
+	rhino_fpga_bus->p##_virtual = ioremap(FPGA_##q##_BASE, SZ_128M); \
+	if(!rhino_fpga_bus->p##_virtual){ \
+		printk("Unable to map memory region 0x%08x for GPMC\n", FPGA_##q##_BASE); \
+		hwrtype_rhino_cleanup(); \
+		return -ENOMEM; \
+	} \
+	PDEBUG(9, "RHINO FPGA: " #p " GPMC at 0x%08x:0x%08x mapped to 0x%08x\n", FPGA_##q##_BASE, FPGA_##q##_BASE + SZ_128M, rhino_fpga_bus->p##_virtual); 
+
+	map_rhino_gmpc(cs0, CS0)
+	map_rhino_gmpc(cs1, CS1)
+	map_rhino_gmpc(cs2, CS2)
+	//map_rhino_gmpc(cs3, CS3)
+	//map_rhino_gmpc(cs4, CS4)
+	//map_rhino_gmpc(cs5, CS5)
+
+#undef map_rhino_gmpc
+
+	config_transport_part_cache = KMEM_CACHE(config_transfer_part, SLAB_HWCACHE_ALIGN);
+
+	spi_register_driver(&rhino_spartan6_driver);
+
+	/* request FPGA gpio */
+	if (gpio_request(FPGA_VCCINT, "FPGA_VCCINT") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", FPGA_VCCINT);
+	}
+	if (gpio_request(FPGA_VCCO_AUX, "FPGA_VCCO_AUX") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", FPGA_VCCO_AUX);
+	}
+    if (gpio_request(FPGA_VCCMGT, "FPGA_VCCMGT") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", FPGA_VCCMGT);
+	}
+
+    if (gpio_request(INIT_B_DIR, "init_b_dir_gpio") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", INIT_B_DIR);
+	}
+
+	if (gpio_request(PROG_B, "prog_b_gpio") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", PROG_B);
+	}
+
+	if (gpio_request(INIT_B, "init_b_gpio") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", INIT_B);
+	}
+
+	if (gpio_request(DONE, "done_gpio") != 0) {
+		PDEBUG(9, "Could not request GPIO %d\n", DONE);
+	}
+
+	gpio_direction_output(INIT_B_DIR, 0);
+
+	/* export FPGA GPIOs to userspace */
+	gpio_export(FPGA_VCCINT, 1);
+	gpio_export(FPGA_VCCO_AUX, 1);
+	gpio_export(FPGA_VCCMGT, 1);
+
+out:
+	return retval;
+}
+
+static void __exit hwrtype_rhino_exit(void)
+{
+	hwrtype_rhino_cleanup();
+}
+
+module_init(hwrtype_rhino_init);
+module_exit(hwrtype_rhino_exit);
+
+MODULE_AUTHOR("Brandon Hamilton");
+MODULE_DESCRIPTION("RHINO hardware region support");
+MODULE_LICENSE("GPL");
diff --git a/kernel/hwr/hwrtype_roach.c b/kernel/hwr/hwrtype_roach.c
new file mode 100644
index 0000000..5a84e6e
--- /dev/null
+++ b/kernel/hwr/hwrtype_roach.c
@@ -0,0 +1,560 @@
+/*********************************************************************
+ * $Id: 
+ * File  : hwrtype_roach.c
+ * Author: Hayden Kwok-Hay So, Brandon Hamilton
+ * Date  : 
+ * Description:
+ *   Define hwrtype for ROACH board 
+ *********************************************************************/
+#include <linux/fs.h>
+#include <linux/module.h>
+#include <linux/slab.h>    /* kmalloc/kfree            */
+#include <linux/init.h>
+#include <asm/uaccess.h>   /* copy_from_user */
+#include <linux/ioport.h>  /* request_mem_region */
+
+#include <linux/bof.h>
+#include <linux/borph.h>
+#define HDEBUG
+#define HDBG_NAME "hwrtype_roach"
+#ifdef CONFIG_MKD
+# define HDBG_LVL mkd_info->dbg_lvl
+#else
+# define HDBG_LVL 9
+#endif
+#include <linux/hdebug.h>
+
+#ifdef CONFIG_RESOURCES_64BIT
+#define RESOURCE_SUFFIX(a) U64_C(a)
+#else
+#define RESOURCE_SUFFIX(a) U32_C(a)
+#endif
+
+/* Some device specific definitions */
+#define ROACH_CPLD_BASE   RESOURCE_SUFFIX(0x1C0000000)
+#define ROACH_SMAP_BASE   RESOURCE_SUFFIX(0x1C0100000)
+#define ROACH_EBC_BASE    RESOURCE_SUFFIX(0x1D0000000)
+
+#define ROACH_CPLD_LENGTH 0x000000400
+#define ROACH_SMAP_LENGTH 0x000100000
+#define ROACH_EBC_LENGTH  0x008000000
+
+#define CPLD_SM_STATUS  0x8
+#define CPLD_SM_OREGS   0x9
+#define CPLD_SM_DATA    0xa
+#define CPLD_SM_CTRL    0xb
+
+#define CPLD_SM_DONE    0x2
+#define CPLD_SM_INIT_N  0x1
+
+#define SM_INITB_WAIT 100000
+#define SM_DONE_WAIT  100000
+
+
+#define SMAP_READW \
+        (readw((void *)(roach_ebc->smap_virt)))
+
+#define SMAP_WRITEW(value) \
+   (writew(value, (void *)(roach_ebc->smap_virt)))
+
+#define SMAP_WRITEL(value) \
+   (writel(value, (void *)(roach_ebc->smap_virt)))
+
+#define FPGA_READW(offset) \
+        (readw((void *)(roach_ebc->ebc_virt + offset)))
+
+#define FPGA_WRITEW(offset, value) \
+   (writew(value, (void *)(roach_ebc->ebc_virt + offset)))
+
+#define FPGA_WRITEL(offset, value) \
+   (writel(value, (void *)(roach_ebc->ebc_virt + offset)))
+
+/*
+#define CPLD_CFG_OUT(offset, value) \
+   (out_le32(roach_ebc->cpld_virt + offset, value))
+
+#define CPLD_CFG_IN(offset) \
+   (in_le32(roach_ebc->cpld_virt + offset))
+*/
+
+#define CPLD_CFG_OUT(offset, value) \
+   (iowrite8(value, roach_ebc->cpld_virt + offset))
+
+#define CPLD_CFG_IN(offset) \
+   (ioread8(roach_ebc->cpld_virt + offset))
+
+/*
+ * A static buffer for data transfer.  It should be expanded to a 
+ * kmem_cache when higher performance is needed.  (Right now, there
+ * can only be one ioreg performing I/O at a time.
+ */
+static buf_t* roach_page;
+static struct hwr_iobuf* iobuf;
+
+/* Mutex Semaphore to ensure proper access to page buffer */
+static DECLARE_MUTEX(roach_mutex);
+
+typedef struct ebc_map {
+    resource_size_t cpld_base;    /* Base address of memory region   */
+    void *cpld_virt;              /* Virtual base address of region  */
+    resource_size_t smap_base;   
+    void *smap_virt;
+    resource_size_t ebc_base;   
+    void *ebc_virt;
+} roach_ebc_map_t;
+
+static roach_ebc_map_t* roach_ebc;
+
+
+/*****************************************************************
+ * functions definitions
+ *****************************************************************/
+static ssize_t roach_send_iobuf (struct hwr_iobuf* iobuf)
+{
+   /* int packet_length;
+
+        PDEBUG(9, "SEND: Sending iobuf to ROACH [CMD = %d]\n", iobuf->cmd);
+
+   roach_page[0] = iobuf->cmd;
+   packet_length = 1;
+
+   switch (iobuf->cmd)
+   {
+       case PP_CMD_WRITE:
+           roach_page[1] = (iobuf->location >> 16) & 0xFF;
+           roach_page[2] = (iobuf->location >> 8) & 0xFF;
+           roach_page[3] = iobuf->location & 0xFF;
+           roach_page[4] = (iobuf->offset >> 24) & 0xFF;
+           roach_page[5] = (iobuf->offset >> 16) & 0xFF;
+           roach_page[6] = (iobuf->offset >> 8) & 0xFF;
+           roach_page[7] = iobuf->offset & 0xFF;
+           roach_page[8]  = (iobuf->size >> 24) & 0xFF;
+           roach_page[9]  = (iobuf->size >> 16) & 0xFF;
+           roach_page[10] = (iobuf->size >> 8) & 0xFF;
+           roach_page[11] = iobuf->size & 0xFF;
+           packet_length = 12 + iobuf->size;
+           break;
+       case PP_CMD_READACK:
+       case PP_CMD_WRITEACK:
+           // Used by mkd thread - still need to implement 
+           break;
+       case PP_CMD_GREET:      
+                           roach_page[1] = 0xFF;
+           roach_page[2] = 0xAA;
+           roach_page[3] = 0x55;
+           if (iobuf->size > 0) {
+               roach_page[4] = (iobuf->size >> 8) & 0xFF;
+               roach_page[5] = iobuf->size & 0xFF;
+               memmove(roach_page + 6, roach_page + 12, iobuf->size);
+               packet_length = 6 + iobuf->size; 
+           }
+           else {
+               packet_length = 4;
+           }
+           break;
+       case PP_CMD_BYE:
+           roach_page[1] = 0x55;
+           roach_page[2] = 0xAA;
+           roach_page[3] = 0xFF;
+           packet_length = 4;
+           break;
+       case PP_CMD_EXIT:
+           break;
+       default:
+           packet_length = 0;
+   }
+
+   */
+
+   unsigned short *src;
+   int i;
+
+   PDEBUG(9, "Writing IOREG (size = %d bytes) to location 0x%x\n", iobuf->size, (unsigned int) (roach_ebc->ebc_virt + iobuf->location));
+
+   src = (unsigned short*) iobuf->data;    
+   for (i = 0; i < iobuf->size; i +=2)
+   {
+       FPGA_WRITEW(iobuf->location + i, *src);
+       src++; 
+   }
+
+   //PDEBUG(9, "Writing to location 0x%x: 0x%x\n", roach_ebc->fpga_virt + iobuf->location, rrd);
+   
+   return iobuf->size; // HHH
+}
+
+static ssize_t roach_recv_iobuf (struct hwr_iobuf* iobuf)
+{
+   /* PDEBUG(9, "RECV: Sending request iobuf to ROACH [CMD = %d]\n", iobuf->cmd);
+
+   roach_page[0] = iobuf->cmd;
+
+   switch (iobuf->cmd)
+   {
+       case PP_CMD_READ:
+           roach_page[1] = (iobuf->location >> 16) & 0xFF;
+           roach_page[2] = (iobuf->location >> 8) & 0xFF;
+           roach_page[3] = iobuf->location & 0xFF;
+           roach_page[4] = (iobuf->offset >> 24) & 0xFF;
+           roach_page[5] = (iobuf->offset >> 16) & 0xFF;
+           roach_page[6] = (iobuf->offset >> 8) & 0xFF;
+           roach_page[7] = iobuf->offset & 0xFF;
+           roach_page[8]  = (iobuf->size >> 24) & 0xFF;
+           roach_page[9]  = (iobuf->size >> 16) & 0xFF;
+           roach_page[10] = (iobuf->size >> 8) & 0xFF;
+           roach_page[11] = iobuf->size & 0xFF;
+           break;
+       case PP_CMD_READACK:
+       case PP_CMD_WRITEACK:
+           break;
+       default:
+           break;
+   }
+   */
+
+   unsigned short *dst;
+   int i;
+
+   PDEBUG(9, "Reading IOREG (size = %d bytes) from location 0x%x\n", iobuf->size,  (unsigned int) (roach_ebc->ebc_virt + iobuf->location));
+
+   dst = (unsigned short*) iobuf->data;    
+   for (i = 0; i < iobuf->size; i +=2)
+   {
+       *dst = FPGA_READW(iobuf->location + i);
+       dst++; 
+   }
+
+   //PDEBUG(9, "Reading from location 0x%x: 0x%x\n", roach_ebc->fpga_virt + iobuf->location, wrd);
+   
+   return iobuf->size;
+}
+
+static struct hwr_iobuf* roach_get_iobuf(void)
+{
+        PDEBUG(9, "Locking IOBUF\n");
+
+   /* If there is different buffer for differ hwr, should
+    * deferentiate them here using *reg* */
+
+   if (down_interruptible(&roach_mutex)) {
+           /* signal received, semaphore not acquired ... */
+       return NULL;
+   }
+
+   iobuf->cmd = 0;
+   iobuf->size = PAGE_SIZE - 12;
+   return iobuf; //HHH
+}
+
+static ssize_t roach_put_iobuf (struct hwr_iobuf* iobuf)
+{
+        PDEBUG(9, "Unlocking IOBUF\n");
+   up(&roach_mutex);
+   return 0; //HHH
+}
+
+static int roach_configure(struct hwr_addr* addr, struct file* file, uint32_t offset, uint32_t len)
+{
+   int i;
+   int count;
+   int retval = -EIO;
+   volatile unsigned short *src;
+
+   PDEBUG(9, "Configuring ROACH fpga %u from (offset %u, len %u) of %s\n",
+          addr->addr, offset, len, file->f_dentry->d_name.name);
+
+   if (addr->addr != 0) {
+       PDEBUG(9, "Invalid FPGA #%d for ROACH\n", addr->addr); /* Roach only has 1 HWR */
+       goto out; 
+   }
+
+   if (down_interruptible(&roach_mutex)) {
+           /* signal received, semaphore not acquired ... */
+       goto out;
+   }
+
+   /* Disable the init_n output */
+   CPLD_CFG_OUT(CPLD_SM_CTRL, 0x00);
+   wmb();
+
+   /* Set Write mode, and enable init_n and prog_b pins  */ 
+   CPLD_CFG_OUT(CPLD_SM_OREGS, 0x03);
+   wmb();
+
+   for (i=0; i < 32; i++) { /* Delay for at least 350ns  */
+       /* Set Write mode, and disable init_n and prog_b pins */
+       CPLD_CFG_OUT(CPLD_SM_OREGS, 0x00);
+   }
+   wmb();  
+   
+   /* Set Write mode, and enable init_n and prog_b pins    */
+   CPLD_CFG_OUT(CPLD_SM_OREGS, 0x03);
+   wmb();
+
+   /* Poll until init_n is enabled */
+   for (i=0; i < SM_INITB_WAIT + 1; i++) {
+       if (CPLD_CFG_IN(CPLD_SM_STATUS) & CPLD_SM_INIT_N) {
+           break;
+       }
+       if (i == SM_INITB_WAIT) {
+           PDEBUG(9, "SelectMap - Init_n pin has not been asserted\n");
+           goto out_free_mutex;
+       }
+   }
+   
+   count = 0;
+
+   /* Read bitstream from file and write it out over SelectMap */
+   while (len > 0) {
+       count = min(PAGE_SIZE, len);
+       retval = kernel_read(file, offset, roach_page, count);
+       if (retval < 0) {
+           goto out_free_mutex;
+       }
+       if (retval != count) {
+           printk("kernel_read returns less than requested...\n");
+           count = retval;
+       }
+
+       len -= count;
+       offset += count;
+
+       i = 0; retval = -EIO;
+
+       src = (unsigned short *)(roach_page);       
+       while(count > 0) {
+           SMAP_WRITEW(*src);
+           src++;
+           count -= 2;
+       }
+   }
+
+   
+   /* Poll until done pin is enabled */
+   for (i=0; i < SM_INITB_WAIT + 1; i++) {
+           if (CPLD_CFG_IN(CPLD_SM_STATUS) & CPLD_SM_DONE) {
+               break;
+           }
+           if (i == SM_DONE_WAIT) {
+           PDEBUG(9, "SelectMap - Done pin has not been asserted\n");
+           goto out_free_mutex;
+       }
+   }
+
+   PDEBUG(9, "ROACH Virtex-5 configuration completed successfully\n");
+   retval = 0;
+
+out_free_mutex:
+   up(&roach_mutex);
+out:
+   return retval;  
+}
+
+static int roach_unconfigure(struct hwr_addr* addr)
+{
+   PDEBUG(9, "Unconfigure ROACH fpga %u\n", addr->addr);
+   return 0;
+}
+
+struct phyhwr* roach_reserve_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* ret;
+   if (a && a->class != HAC_ROACH) {
+                return NULL;
+        }
+   
+   /* safety check */
+   if (a->addr >= 1)
+       return NULL;
+
+   ret = phyhwrs[a->class][a->addr];
+   if (!atomic_inc_and_test(&ret->count)) {
+       atomic_dec(&ret->count);
+       /* was being used */
+       return NULL;
+   }
+   /* count is now a usage count */
+   atomic_inc(&ret->count);
+   return ret;
+}
+
+void roach_release_hwr(struct hwr_addr* a)
+{
+   struct phyhwr* hwr;
+   if (a && a->class != HAC_ROACH)
+       return;
+
+   /* safety check */
+   if (a->addr >= 1)
+       return;
+   
+   hwr = phyhwrs[a->class][a->addr];
+   if (atomic_dec_and_test(&hwr->count)) {
+       hwr->task = NULL;
+       atomic_set(&hwr->count, -1);
+   }
+}
+
+static struct hwr_operations roach_hwr_operations = {
+   .configure = roach_configure,
+   .unconfigure = roach_unconfigure,
+   .reserve_hwr = roach_reserve_hwr,
+   .release_hwr = roach_release_hwr,
+   .get_iobuf = roach_get_iobuf,
+   .put_iobuf = roach_put_iobuf,
+   .send_iobuf = roach_send_iobuf,
+   .recv_iobuf = roach_recv_iobuf
+};
+
+static struct hwrtype hwrtype_roach = {
+   name: "roach",
+   type: HAC_ROACH,
+   count: ATOMIC_INIT(0),
+        num_devs: 1,
+   hwr_ops: &roach_hwr_operations,
+};
+
+static int __init hwrtype_roach_init(void)
+{
+   int retval = 0;
+   int i;
+
+   if ((retval = register_hwrtype(&hwrtype_roach)) < 0) {
+       printk("Error registering hwrtype\n");
+       goto out;
+   } else {
+       printk("hwrtype_roach version CVS-$Revision: 1.1 $ registered\n");
+   }
+
+   /* initialize hwr */
+        atomic_set(&(phyhwrs[HAC_ROACH][0])->count, -1);
+           
+   /* initialize iobuf memory */
+   roach_page = (buf_t*)__get_free_page(GFP_KERNEL);
+   iobuf = (struct hwr_iobuf*) kmalloc(sizeof(struct hwr_iobuf), GFP_KERNEL);
+   if (iobuf) {
+       iobuf->data = roach_page + 12;
+       iobuf->size = PAGE_SIZE - 12;
+   } else {
+       printk("failed getting memory for roach iobuf\n");
+       retval = -ENOMEM;
+       goto out;
+   }
+
+   /* initialise EBC IO Memory */
+   if (!(roach_ebc = kmalloc(sizeof(roach_ebc_map_t), GFP_KERNEL))) {
+       printk("failed getting memory for roach ebc\n");
+       retval = -ENOMEM;
+       goto out;
+   }
+
+   roach_ebc->cpld_base = 0;
+
+   if (!request_mem_region(ROACH_CPLD_BASE, ROACH_CPLD_LENGTH, "roach-cpld")) {
+       printk(KERN_ERR "%s: memory range 0x%08llx to 0x%08llx is in use\n",
+                   "roach-cpld",
+                   (unsigned long long) ROACH_CPLD_BASE,
+                   (unsigned long long)(ROACH_CPLD_BASE + ROACH_CPLD_LENGTH));
+       goto out_freemem;
+   }
+
+   roach_ebc->cpld_base = ROACH_CPLD_BASE;
+  printk(KERN_ERR "borph: about to map cpld at 0x%llx\n", ROACH_CPLD_BASE);
+   roach_ebc->cpld_virt = ioremap(roach_ebc->cpld_base, ROACH_CPLD_LENGTH);
+  if(!roach_ebc->cpld_virt){
+    printk(KERN_ERR "borph: unable to map cpld\n");
+  }
+
+   PDEBUG(9, "new I/O memory range 0x%08llx to 0x%08llx allocated (virt:0x%p)\n",
+              (unsigned long long) roach_ebc->cpld_base,
+              (unsigned long long) (roach_ebc->cpld_base + ROACH_CPLD_LENGTH),
+              roach_ebc->cpld_virt);
+
+   roach_ebc->smap_base = 0;
+
+   if (!request_mem_region(ROACH_SMAP_BASE, ROACH_SMAP_LENGTH, "roach-selectmap")) {
+       printk(KERN_ERR "%s: memory range 0x%08llx to 0x%08llx is in use\n",
+                   "roach-selectmap",
+                   (unsigned long long) ROACH_SMAP_BASE,
+                   (unsigned long long)(ROACH_SMAP_BASE + ROACH_SMAP_LENGTH));
+       goto out_freemem;
+   }
+
+   roach_ebc->smap_base = ROACH_SMAP_BASE;
+   roach_ebc->smap_virt = ioremap(ROACH_SMAP_BASE,ROACH_SMAP_LENGTH);
+
+   PDEBUG(9, "new I/O memory range 0x%08llx to 0x%08llx allocated (virt:0x%p)\n",
+              (unsigned long long) roach_ebc->smap_base,
+              (unsigned long long) (roach_ebc->smap_base + ROACH_SMAP_LENGTH),
+              roach_ebc->smap_virt);
+
+   roach_ebc->ebc_base = 0;
+
+   if (!request_mem_region(ROACH_EBC_BASE, ROACH_EBC_LENGTH, "roach-ebc")) {
+       printk(KERN_ERR "%s: memory range 0x%08llx to 0x%08llx is in use\n",
+                   "roach-fpga",
+                   (unsigned long long) ROACH_EBC_BASE,
+                   (unsigned long long)(ROACH_EBC_BASE + ROACH_EBC_LENGTH));
+       goto out_freemem;
+   }
+
+   roach_ebc->ebc_base = ROACH_EBC_BASE;
+   roach_ebc->ebc_virt = ioremap(ROACH_EBC_BASE,ROACH_EBC_LENGTH);
+
+   PDEBUG(9, "new I/O memory range 0x%08llx to 0x%08llx allocated (virt:0x%p)\n",
+              (unsigned long long) roach_ebc->ebc_base,
+              (unsigned long long) (roach_ebc->ebc_base + ROACH_EBC_LENGTH),
+              roach_ebc->ebc_virt);
+
+
+        // Check for roach CPLD
+        PDEBUG(9, "Reading ROACH CPLD: ");
+   
+   for (i = 0; i < 32; i++)
+     PDEBUG(9, " 0x%02x ", CPLD_CFG_IN(i));
+      
+        PDEBUG(9, "\n");
+
+   return 0;
+
+out_freemem:
+   kfree(roach_ebc);
+   roach_ebc = NULL;
+out:
+   return retval;
+}
+
+static void __exit hwrtype_roach_exit(void)
+{
+   /* free ebc memory used */
+   if (roach_ebc) {
+       if (roach_ebc->cpld_base) {
+           iounmap(roach_ebc->cpld_virt);
+           release_mem_region(roach_ebc->cpld_base, ROACH_CPLD_LENGTH);
+       }
+       kfree(roach_ebc);
+       roach_ebc = NULL;
+   }
+
+   /* Free iobuf */
+   if (iobuf) {
+       kfree(iobuf);
+   }
+
+   if (roach_page) {
+       free_page((unsigned long) roach_page);
+   }
+
+   if (unregister_hwrtype(&hwrtype_roach)) {
+       printk("Error unregistering hwrtyp\n");
+   } else {
+       printk("hwrtype_roach CVS-$Revision: 1.1 $ unregistered\n");
+   }
+}
+
+module_init(hwrtype_roach_init);
+module_exit(hwrtype_roach_exit);
+
+MODULE_AUTHOR("Brandon Hamilton");
+MODULE_DESCRIPTION("Add hwrtype roach to program FPGA on ROACH as hw process");
+MODULE_LICENSE("GPL");
diff --git a/kernel/hwr/nf2.h b/kernel/hwr/nf2.h
new file mode 100644
index 0000000..c68311c
--- /dev/null
+++ b/kernel/hwr/nf2.h
@@ -0,0 +1,458 @@
+/* ****************************************************************************
+ * $Id: nf2.h 6067 2010-04-01 22:36:26Z grg $
+ *
+ * Module: nf2.h
+ * Project: NetFPGA 2 Linux Kernel Driver
+ * Description: Header file for kernel driver
+ *
+ * Change history:
+ *
+ */
+
+#ifndef _NF2_H
+#define _NF2_H 1
+
+#define NF2_DEV_NAME   "nf2"
+
+/* Include for socket IOCTLs */
+#include <linux/sockios.h>
+
+/* Maximum number of interfaces */
+#ifndef MAX_IFACE
+#define MAX_IFACE  4
+#endif
+
+/*
+ * Register names and locations.
+ *
+ * Note that these names are not necessarily identical to
+ * those in netfpga/hw/common/src/defines
+ */
+
+/* CPCI registers */
+#define CPCI_REG_ID            0x000
+#define CPCI_REG_BOARD_ID      0x004
+#define CPCI_REG_CTRL          0x008
+#define CPCI_REG_RESET         0x00c
+#define CPCI_REG_ERROR         0x010
+#define CPCI_REG_DUMMY         0x020
+#define CPCI_REG_INTERRUPT_MASK        0x040
+#define CPCI_REG_INTERRUPT_STATUS  0x044
+#define CPCI_REG_PROG_DATA     0x100
+#define CPCI_REG_PROG_STATUS       0x104
+#define CPCI_REG_PROG_CTRL     0x108
+#define CPCI_REG_DMA_I_ADDR        0x140
+#define CPCI_REG_DMA_E_ADDR        0x144
+#define CPCI_REG_DMA_I_SIZE        0x148
+#define CPCI_REG_DMA_E_SIZE        0x14c
+#define CPCI_REG_DMA_I_CTRL        0x150
+#define CPCI_REG_DMA_E_CTRL        0x154
+#define CPCI_REG_DMA_QUEUE_STATUS  0x158
+#define CPCI_REG_DMA_MAX_XFER_TIME 0x180
+#define CPCI_REG_DMA_MAX_RETRIES   0x184
+#define CPCI_REG_CNET_MAX_XFER_TIME    0x188
+#define CPCI_REG_DMA_I_PKT_CNT     0x400
+#define CPCI_REG_DMA_E_PKT_CNT     0x404
+#define CPCI_REG_CPCI_REG_RD_CNT   0x408
+#define CPCI_REG_CPCI_REG_WR_CNT   0x40c
+#define CPCI_REG_CNET_REG_RD_CNT   0x410
+#define CPCI_REG_CNET_REG_WR_CNT   0x414
+
+#define CPCI_REG_N_CLK_COUNT            0x500
+#define CPCI_REG_P_MAX                  0x504
+#define CPCI_REG_N_EXP                  0x508
+#define CPCI_REG_P_CLK_CTR              0x510
+#define CPCI_REG_RESET_CTR              0x520
+
+
+
+/* Base address for CNET registers */
+#define CNET_REG_BASE          0x400000
+
+
+/* Added by nweaver for building memory manipulation
+   utilities */
+/* 2 MB SRAM size on current board, MAX and SIZE will
+   need to be changed if upgraded to 4 MB SRAMs */
+#define SRAM_SIZE                       0x200000
+
+#define SRAM_1_BASE                     0x800000
+#define SRAM_1_MAX                      0x9FFFFF
+
+#define SRAM_2_BASE                     0xC00000
+#define SRAM_2_MAX                      0xDFFFFF
+/* end nweaver addition */
+
+
+/* Device ID registers */
+#define NF2_DEVICE_ID   0x0400000
+#define NF2_REVISION    0x0400004
+#define NF2_DEVICE_STR  0x0400008
+
+
+/* CNET registers */
+#define CNET_REG_ID            (CNET_REG_BASE + 0x000)
+#define CNET_REG_CTRL          (CNET_REG_BASE + 0x004)
+#define CNET_REG_RESET         (CNET_REG_BASE + 0x008)
+#define CNET_REG_ERROR         (CNET_REG_BASE + 0x00C)
+#define CNET_REG_ENABLE            (CNET_REG_BASE + 0x010)
+#define CNET_REG_WR_SRAM1_EOP      (CNET_REG_BASE + 0x0F0)
+#define CNET_REG_RD_SRAM1_EOP      (CNET_REG_BASE + 0x0F4)
+#define CNET_REG_WR_SRAM2_EOP      (CNET_REG_BASE + 0x0F8)
+#define CNET_REG_RD_SRAM2_EOP      (CNET_REG_BASE + 0x0FC)
+#define CNET_REG_MF_STATUS_0       (CNET_REG_BASE + 0x100)
+#define CNET_REG_MF_TX_PKTS_SENT_0 (CNET_REG_BASE + 0x104)
+#define CNET_REG_MF_RX_PKTS_RCVD_0 (CNET_REG_BASE + 0x108)
+#define CNET_REG_MF_RX_PKTS_LOST_0 (CNET_REG_BASE + 0x10C)
+#define CNET_REG_MAC_CONFIG_0      (CNET_REG_BASE + 0x110)
+#define CNET_REG_MF_STATUS_1       (CNET_REG_BASE + 0x140)
+#define CNET_REG_MF_TX_PKTS_SENT_1 (CNET_REG_BASE + 0x144)
+#define CNET_REG_MF_RX_PKTS_RCVD_1 (CNET_REG_BASE + 0x148)
+#define CNET_REG_MF_RX_PKTS_LOST_1 (CNET_REG_BASE + 0x14C)
+#define CNET_REG_MAC_CONFIG_1      (CNET_REG_BASE + 0x150)
+#define CNET_REG_MF_STATUS_2       (CNET_REG_BASE + 0x180)
+#define CNET_REG_MF_TX_PKTS_SENT_2 (CNET_REG_BASE + 0x184)
+#define CNET_REG_MF_RX_PKTS_RCVD_2 (CNET_REG_BASE + 0x188)
+#define CNET_REG_MF_RX_PKTS_LOST_2 (CNET_REG_BASE + 0x18C)
+#define CNET_REG_MAC_CONFIG_2      (CNET_REG_BASE + 0x190)
+#define CNET_REG_MF_STATUS_3       (CNET_REG_BASE + 0x1C0)
+#define CNET_REG_MF_TX_PKTS_SENT_3 (CNET_REG_BASE + 0x1C4)
+#define CNET_REG_MF_RX_PKTS_RCVD_3 (CNET_REG_BASE + 0x1C8)
+#define CNET_REG_MF_RX_PKTS_LOST_3 (CNET_REG_BASE + 0x1CC)
+#define CNET_REG_MAC_CONFIG_3      (CNET_REG_BASE + 0x1D0)
+#define CNET_REG_RXQ_NUM_PKTS_0        (CNET_REG_BASE + 0x200)
+#define CNET_REG_RXQ_POINTERS_0        (CNET_REG_BASE + 0x204)
+#define CNET_REG_RXQ_NUM_PKTS_1        (CNET_REG_BASE + 0x240)
+#define CNET_REG_RXQ_POINTERS_1        (CNET_REG_BASE + 0x244)
+#define CNET_REG_RXQ_NUM_PKTS_2        (CNET_REG_BASE + 0x280)
+#define CNET_REG_RXQ_POINTERS_2        (CNET_REG_BASE + 0x284)
+#define CNET_REG_RXQ_NUM_PKTS_3        (CNET_REG_BASE + 0x2C0)
+#define CNET_REG_RXQ_POINTERS_3        (CNET_REG_BASE + 0x2C4)
+
+#define CNET_REG_MF_RX_PKTS_LOST_BAD_FCS_0 (CNET_REG_BASE + 0x114)
+#define CNET_REG_MF_RX_PKTS_LOST_FULL_FIFO_0 (CNET_REG_BASE+0x118)
+#define CNET_REG_MF_RX_GOOD_PKTS_RCVD_0     (CNET_REG_BASE+0x11C)
+#define CNET_REG_MF_RX_GOOD_BYTES_RCVD_0   (CNET_REG_BASE+0x120)
+#define CNET_REG_MF_TX_BYTES_SENT_0 (CNET_REG_BASE+0x124)
+#define CNET_REG_MF_RX_PKTS_LOST_BAD_FCS_1 (CNET_REG_BASE+0x154)
+#define CNET_REG_MF_RX_PKTS_LOST_FULL_FIFO_1 (CNET_REG_BASE+0x158)
+#define CNET_REG_MF_RX_GOOD_PKTS_RCVD_1     (CNET_REG_BASE+0x15C)
+#define CNET_REG_MF_RX_GOOD_BYTES_RCVD_1   (CNET_REG_BASE+0x160)
+#define CNET_REG_MF_TX_BYTES_SENT_1 (CNET_REG_BASE+0x164)
+#define CNET_REG_MF_RX_PKTS_LOST_BAD_FCS_2 (CNET_REG_BASE+0x194)
+#define CNET_REG_MF_RX_PKTS_LOST_FULL_FIFO_2 (CNET_REG_BASE+0x198)
+#define CNET_REG_MF_RX_GOOD_PKTS_RCVD_2     (CNET_REG_BASE+0x19C)
+#define CNET_REG_MF_RX_GOOD_BYTES_RCVD_2   (CNET_REG_BASE+0x1A0)
+#define CNET_REG_MF_TX_BYTES_SENT_2 (CNET_REG_BASE+0x1A4)
+#define CNET_REG_MF_RX_PKTS_LOST_BAD_FCS_3 (CNET_REG_BASE+0x1D4)
+#define CNET_REG_MF_RX_PKTS_LOST_FULL_FIFO_3 (CNET_REG_BASE+0x1D8)
+#define CNET_REG_MF_RX_GOOD_PKTS_RCVD_3     (CNET_REG_BASE+0x1DC)
+#define CNET_REG_MF_RX_GOOD_BYTES_RCVD_3   (CNET_REG_BASE+0x1E0)
+#define CNET_REG_MF_TX_BYTES_SENT_3 (CNET_REG_BASE+0x1E4)
+
+#define CNET_MAC_CLK_CHK_CTRL           (CNET_REG_BASE + 0xF00)
+#define CNET_MAC_CLK_CHK_CNT_VALUE      (CNET_REG_BASE + 0xF04)
+
+
+/* Base address for CNET PHY registers */
+#define PHY_REG_BASE           0x600000
+
+#define PHY_REG_CMD            (PHY_REG_BASE)
+#define PHY_REG_STATUS         (PHY_REG_BASE)
+
+/*
+ * CPCI register masks
+ */
+
+/* ID Masks */
+#define ID_VERSION         0x00FFFFFF
+#define ID_REVISION            0xFF000000
+
+/* Board ID Masks */
+#define BOARD_ID           0x00000F00
+#define BOARD_ID_CONTROL       0x00000001
+
+/* Control masks */
+#define CTRL_CNET_RESET            0x00000100
+#define CTRL_LED           0x00000001
+
+/* RESET masks */
+#define RESET_CPCI         0x00000001
+
+/* Error masks */
+#define ERR_CNET_READ_TIMEOUT      0x02000000
+#define ERR_CNET_ERROR         0x01000000
+#define ERR_PROG_BUF_OVERFLOW      0x00020000
+#define ERR_PROG_ERROR         0x00010000
+#define ERR_DMA_TIMEOUT            0x00000400
+#define ERR_DMA_RETRY_CNT_EXPIRED  0x00000200
+#define ERR_DMA_BUF_OVERFLOW       0x00000100
+#define ERR_DMA_RD_SIZE_ERROR      0x00000040
+#define ERR_DMA_WR_SIZE_ERROR      0x00000020
+#define ERR_DMA_RD_ADDR_ERROR      0x00000010
+#define ERR_DMA_WR_ADDR_ERROR      0x00000008
+#define ERR_DMA_RD_MAC_ERROR       0x00000004
+#define ERR_DMA_WR_MAC_ERROR       0x00000002
+#define ERR_DMA_FATAL_ERROR        0x00000001
+
+#define ERR_DMA_SETUP_ERROR ( ERR_DMA_WR_MAC_ERROR | \
+                               ERR_DMA_RD_MAC_ERROR | \
+                               ERR_DMA_WR_ADDR_ERROR | \
+                               ERR_DMA_RD_ADDR_ERROR | \
+                               ERR_DMA_WR_SIZE_ERROR | \
+                               ERR_DMA_RD_SIZE_ERROR )
+
+
+/* Interrupt masks */
+#define INT_DMA_RX_COMPLETE        0x80000000
+#define INT_DMA_TX_COMPLETE        0x40000000
+#define INT_PHY_INTERRUPT      0x20000000
+#define INT_DMA_QUEUE_STATUS_CHANGE    0x00000200
+#define INT_PKT_AVAIL          0x00000100
+#define INT_CNET_ERROR         0x00000020
+#define INT_CNET_READ_TIMEOUT      0x00000010
+#define INT_PROG_ERROR         0x00000008
+#define INT_DMA_TRANSFER_ERROR     0x00000004
+#define INT_DMA_SETUP_ERROR        0x00000002
+#define INT_DMA_FATAL_ERROR        0x00000001
+
+#define INT_UNKNOWN            ~(INT_DMA_RX_COMPLETE | \
+                     INT_DMA_TX_COMPLETE | \
+                     INT_PHY_INTERRUPT | \
+                     INT_DMA_QUEUE_STATUS_CHANGE | \
+                     INT_PKT_AVAIL | \
+                     INT_CNET_ERROR | \
+                     INT_CNET_READ_TIMEOUT | \
+                     INT_PROG_ERROR | \
+                     INT_DMA_TRANSFER_ERROR | \
+                     INT_DMA_SETUP_ERROR | \
+                     INT_DMA_FATAL_ERROR)
+
+/* Programming status */
+#define PROG_INIT          0x00010000
+#define PROG_DONE          0x00000100
+#define PROG_FIFO_EMPTY            0x00000002
+#define PROG_IN_PROGRESS       0x00000001
+
+/* Programming control */
+#define PROG_CTRL_RESET            0x00000001
+
+/* DMA control */
+#define DMA_CTRL_MAC           0x00000300
+#define DMA_CTRL_OWNER         0x00000001
+
+/*
+ * CNET register masks
+ */
+
+/* Reset masks */
+#define CNET_RESET_MAC         0x0000000F
+#define CNET_RESET_MAC_3       0x00000008
+#define CNET_RESET_MAC_2       0x00000004
+#define CNET_RESET_MAC_1       0x00000002
+#define CNET_RESET_MAC_0       0x00000001
+
+/* Error masks */
+#define CNET_ERROR_TX_UNDERRUN_MAC 0x000000F0
+#define CNET_ERROR_TX_UNDERRUN_MAC_3   0x00000080
+#define CNET_ERROR_TX_UNDERRUN_MAC_2   0x00000040
+#define CNET_ERROR_TX_UNDERRUN_MAC_1   0x00000020
+#define CNET_ERROR_TX_UNDERRUN_MAC_0   0x00000010
+#define CNET_ERROR_TX_OVERRUN_MAC  0x0000000F
+#define CNET_ERROR_TX_OVERRUN_MAC_3    0x00000008
+#define CNET_ERROR_TX_OVERRUN_MAC_2    0x00000004
+#define CNET_ERROR_TX_OVERRUN_MAC_1    0x00000002
+#define CNET_ERROR_TX_OVERRUN_MAC_0    0x00000001
+
+/* Enable masks */
+#define CNET_ENABLE_RX_FIFO        0x0000F000
+#define CNET_ENABLE_RX_FIFO_3      0x00008000
+#define CNET_ENABLE_RX_FIFO_2      0x00004000
+#define CNET_ENABLE_RX_FIFO_1      0x00002000
+#define CNET_ENABLE_RX_FIFO_0      0x00001000
+#define CNET_ENABLE_TX_MAC     0x00000F00
+#define CNET_ENABLE_TX_MAC_3       0x00000800
+#define CNET_ENABLE_TX_MAC_2       0x00000400
+#define CNET_ENABLE_TX_MAC_1       0x00000200
+#define CNET_ENABLE_TX_MAC_0       0x00000100
+#define CNET_ENABLE_DEBUG_TRISTATE 0x00000004
+#define CNET_ENABLE_INGRESS_ARBITER    0x00000002
+#define CNET_ENABLE_RX_DMA     0x00000001
+
+/* MF Status masks */
+#define CNET_MF_STATUS_RX_FIFO_EMPTY   0x02000000
+#define CNET_MF_STATUS_RX_PKT_AVAIL    0x01000000
+#define CNET_MF_STATUS_RX_NUM_PKTS 0x00FF0000
+#define CNET_MF_STATUS_TX_FIFO_FULL    0x00000200
+#define CNET_MF_STATUS_TX_FIFO_NO_MAX_PKT  0x00000100
+#define CNET_MF_STATUS_TX_NUM_PKTS 0x000000FF
+
+/* MAC Config masks */
+#define CNET_MAC_CFG_FULL_DUPLEX   0x00000020
+#define CNET_MAC_CFG_TX_FCS_SUPPLIED   0x00000010
+#define CNET_MAC_CFG_RX_WANT_FCS   0x00000008
+#define CNET_MAC_CFG_JUMBO_ENABLE  0x00000004
+
+#define CNET_MAC_CFG_SPEED     0x00000002
+#define CNET_MAC_CFG_1000_MBPS     0x00000002
+#define CNET_MAC_CFG_100_MBPS      0x00000001
+#define CNET_MAC_CFG_10_MBPS       0x00000000
+
+#define CNET_RXQ_WR_PTR            0x00FF0000
+#define CNET_RXQ_RD_PTR            0x000000FF
+
+
+/* Phy register masks */
+#define PHY_RD_WR          0x80000000
+#define PHY_PHY                0x03000000
+#define PHY_ADDR           0x001F0000
+#define PHY_DATA           0x0000FFFF
+
+#define PHY_DONE           0x80000000
+#define PHY_DONE_CNT           0x001F0000
+
+/* Defines to calculate register values */
+/* CPCI Funcs */
+#define NF2_GET_VERSION(x)     (x & 0xFFFFFF)
+#define NF2_GET_REVISION(x)        ((x & 0xFF000000) >> 24)
+
+#define NF2_GET_BOARD_ID(x)        ((x & BOARD_ID) >> 8)
+#define NF2_GET_CONTROL(x)     (x & BOARD_ID_CONTROL)
+
+#define NF2_GET_CNET_RESET(x)      ((x & CTRL_CNET_RESET) >> 8)
+#define NF2_GET_LED(x)         (x & CTRL_LED)
+
+#define NF2_GET_RESET(x)       (x & RESET_CPCI)
+
+#define NF2_GET_CNET_READ_TIMEOUT(x)   ((x & ERR_CNET_READ_TIMEOUT) >> 25)
+#define NF2_GET_CNET_ERROR(x)      ((x & ERR_CNET_ERROR) >> 24)
+#define NF2_GET_PROG_BUF_OVERFLOW(x)   ((x & ERR_PROG_BUF_OVERFLOW) >> 12)
+#define NF2_GET_PROG_ERROR(x)      ((x & ERR_PROG_ERROR) >> 11)
+#define NF2_GET_DMA_TIMEOUT(x)     ((x & ERR_DMA_TIMEOUT) >> 10)
+#define NF2_GET_DMA_RETRY_CNT_EXPIRED(x)   \
+   ((x & ERR_DMA_RETRY_CNT_EXPIRED) >> 9)
+#define NF2_GET_DMA_BUF_OVERFLOW(x)    ((x & ERR_DMA_BUF_OVERFLOW) >> 8)
+#define NF2_GET_DMA_RD_SIZE_ERROR(x)   ((x & ERR_DMA_RD_SIZE_ERROR) >> 6)
+#define NF2_GET_DMA_WR_SIZE_ERROR(x)   ((x & ERR_DMA_WR_SIZE_ERROR) >> 5)
+#define NF2_GET_DMA_RD_ADDR_ERROR(x)   ((x & ERR_DMA_RD_ADDR_ERROR) >> 4)
+#define NF2_GET_DMA_WR_ADDR_ERROR(x)   ((x & ERR_DMA_WR_ADDR_ERROR) >> 3)
+#define NF2_GET_DMA_RD_MAC_ERROR(x)    ((x & ERR_DMA_RD_MAC_ERROR) >> 2)
+#define NF2_GET_DMA_WR_MAC_ERROR(x)    ((x & ERR_DMA_WR_MAC_ERROR) >> 1)
+#define NF2_GET_DMA_FATAL_ERROR(x) (x & ERR_DMA_FATAL_ERROR)
+
+#define NF2_GET_INT_DMA_TX_COMPLETE(x) ((x & INT_DMA_TX_COMPLETE) >> 31)
+#define NF2_GET_INT_DMA_RX_COMPLETE(x) ((x & INT_DMA_RX_COMPLETE) >> 30)
+#define NF2_GET_INT_PHY_INTERRUPT(x)   ((x & INT_PHY_INTERRUPT) >> 29)
+#define NF2_GET_INT_PKT_AVAIL(x)   ((x & INT_PKT_AVAIL) >> 8)
+#define NF2_GET_INT_CNET_ERROR(x)  ((x & INT_CNET_ERROR) >> 5)
+#define NF2_GET_INT_CNET_READ_TIMEOUT(x)   \
+   ((x & INT_CNET_READ_TIMEOUT) >> 4)
+#define NF2_GET_INT_PROG_ERROR(x)  ((x & INT_PROG_ERROR) >> 3)
+#define NF2_GET_INT_DMA_TRANSFER_ERROR(x)  \
+   ((x & INT_DMA_TRANSFER_ERROR) >> 2)
+#define NF2_GET_INT_DMA_SETUP_ERROR(x) ((x & INT_DMA_SETUP_ERROR) >> 1)
+#define NF2_GET_INT_DMA_FATAL_ERROR(x) (x & INT_DMA_FATAL_ERROR)
+
+#define NF2_GET_PROG_INIT(x)       ((x & PROG_INIT) >> 16)
+#define NF2_GET_PROG_DONE(x)       ((x & PROG_DONE) >> 8)
+#define NF2_GET_PROG_FIFO_EMPTY(x) ((x & PROG_FIFO_EMPTY) >> 1)
+#define NF2_GET_PROG_IN_PROGRESS(x)    (x & PROG_IN_PROGRESS)
+
+#define NF2_GET_DMA_CTRL_MAC(x)        ((x & DMA_CTRL_MAC) >> 8)
+#define NF2_GET_DMA_CTRL_OWNER(x)  (x & DMA_CTRL_OWNER)
+
+#define NF2_SET_DMA_CTRL_MAC(x)        (x << 8)
+
+
+/* CNET Funcs */
+#define NF2_GET_CNET_VERSION(x)        ((x & 0xFFFF0000) >> 16)
+#define NF2_GET_CNET_DEVICE_ID(x)  (x & 0xFFFF)
+
+#define NF2_GET_CNET_RESET_MAC(x)      (x & CNET_RESET_MAC)
+
+#define NF2_GET_CNET_ERROR_TX_UNDERRUN_MAC(x)  \
+   ((x & CNET_ERROR_TX_UNDERRUN_MAC) >> 4)
+#define NF2_GET_CNET_ERROR_TX_OVERRUN_MAC(x)   \
+   (x & CNET_ERROR_TX_OVERRUN_MAC)
+
+#define NF2_GET_CNET_ENABLE_RX_FIFO(x) ((x & CNET_ENABLE_RX_FIFO) >> 12)
+#define NF2_GET_CNET_ENABLE_TX_MAC(x)  ((x & CNET_ENABLE_TX_MAC) >> 8)
+#define NF2_GET_CNET_ENABLE_DEBUG_TRISTATE(x)  \
+   ((x & CNET_ENABLE_DEBUG_TRISTATE) >> 2)
+#define NF2_GET_CNET_ENABLE_INGRESS_ARBITER(x) \
+   ((x & CNET_ENABLE_INGRESS_ARBITER) >> 1)
+#define NF2_GET_CNET_ENABLE_RX_DMA(x)  (x & CNET_ENABLE_RX_DMA)
+
+#define NF2_GET_CNET_MF_STATUS_RX_FIFO_EMPTY(x)    \
+   ((x & CNET_MF_STATUS_RX_FIFO_EMPTY) >> 25)
+#define NF2_GET_CNET_MF_STATUS_RX_PKT_AVAIL(x) \
+   ((x & CNET_MF_STATUS_RX_PKT_AVAIL) >> 24)
+#define NF2_GET_CNET_MF_STATUS_RX_NUM_PKTS(x)  \
+   ((x & CNET_MF_STATUS_RX_NUM_PKTS) >> 16)
+#define NF2_GET_CNET_MF_STATUS_TX_FIFO_FULL(x) \
+   ((x & CNET_MF_STATUS_TX_FIFO_FULL) >> 9)
+#define NF2_GET_CNET_MF_STATUS_TX_FIFO_NO_MAX_PKT(x)   \
+   ((x & CNET_MF_STATUS_TX_FIFO_NO_MAX_PKT) >> 8)
+#define NF2_GET_CNET_MF_STATUS_TX_NUM_PKTS(x)  \
+   (x & CNET_MF_STATUS_TX_NUM_PKTS)
+
+#define NF2_GET_CNET_MAC_CFG_FULL_DUPLEX(x)    \
+   ((x & CNET_MAC_CFG_FULL_DUPLEX) >> 5)
+#define NF2_GET_CNET_MAC_CFG_TX_FCS_SUPPLIED(x)    \
+   ((x & CNET_MAC_CFG_TX_FCS_SUPPLIED) >> 4)
+#define NF2_GET_CNET_MAC_CFG_RX_WANT_FCS(x)    \
+   ((x & CNET_MAC_CFG_RX_WANT_FCS) >> 3)
+#define NF2_GET_CNET_MAC_CFG_JUMBO_ENABLE(x)   \
+   ((x & CNET_MAC_CFG_JUMBO_ENABLE) >> 2)
+#define NF2_GET_CNET_MAC_CFG_SPEED(x)  \
+   (x & CNET_MAC_CFG_SPEED)
+
+#define NF2_GET_CNET_RXQ_WR_PTR(x) ((x & CNET_RXQ_WR_PTR) >> 16)
+#define NF2_GET_CNET_RXQ_RD_PTR(x) (x & CNET_RXQ_RD_PTR)
+
+
+/* PHY functions */
+#define NF2_SET_PHY_IS_READ(x)     (x << 31)
+#define NF2_SET_PHY_SELECT(x)      (x << 24)
+#define NF2_SET_PHY_ADDR(x)        (x << 16)
+#define NF2_SET_PHY_DATA(x)        (x)
+
+#define NF2_GET_PHY_DATA(x)        (x & PHY_DATA)
+#define NF2_GET_PHY_DONE(x)        ((x & PHY_DONE) >> 31)
+#define NF2_GET_PHY_DONE_CNT(x)        ((x & PHY_DONE_CNT) >> 16)
+
+
+/*
+ * IOCTLs
+ */
+#define SIOCREGREAD        SIOCDEVPRIVATE
+#define SIOCREGWRITE       (SIOCDEVPRIVATE + 1)
+
+
+/* MDIO registers */
+#define MDIO_0_BASE                    0x0440000
+#define MDIO_0_PHY_ID_LO_REG           0x0440008
+#define MDIO_0_PHY_ID_HI_REG           0x044000C
+#define MDIO_0_AUX_STATUS              0x0440064
+#define MDIO_0_INTR_STATUS             0x0440068
+#define MDIO_0_INTR_MASK               0x044006c
+
+
+/* MDIO address delta between each phy base address */
+#define ADDRESS_DELTA                  0x80
+
+
+/* MDIO bit positions */
+#define INTR_LINK_STATUS_POS           0x2
+#define AUX_LINK_STATUS_POS            0x4
+
+
+/*
+ * Structure for transferring register data via an IOCTL
+ */
+struct nf2reg {
+   unsigned int    reg;
+   unsigned int    val;
+};
+
+#endif
diff --git a/kernel/hwr/nf2kernel.h b/kernel/hwr/nf2kernel.h
new file mode 100644
index 0000000..04e7e38
--- /dev/null
+++ b/kernel/hwr/nf2kernel.h
@@ -0,0 +1,279 @@
+/* ****************************************************************************
+ *
+ * Module: nf2kernel.h
+ * Project: NetFPGA 2 Linux Kernel Driver
+ * Description: Header file for kernel driver
+ *
+ * Change history:
+ *
+ */
+
+#ifndef _NF2KERNEL_H
+#define _NF2KERNEL_H   1
+
+#ifdef __KERNEL__
+
+#include <linux/cdev.h>
+#include <linux/sockios.h>
+#include <linux/netdevice.h>
+#include <linux/fs.h>
+#include <linux/mii.h>
+#include <asm/atomic.h>
+
+/* Define PCI Vendor and device IDs for the NetFPGA-1G card */
+#define PCI_VENDOR_ID_STANFORD     0xFEED
+#define PCI_DEVICE_ID_STANFORD_NF2 0x0001
+
+/* Prefix for device names
+ * - will have either c or u appended to indicate control or user
+ */
+#define NF2_DEV_NAME   "nf2"
+
+/* How many interfaces does a single card support */
+#ifndef MAX_IFACE
+#define MAX_IFACE  4
+#endif
+
+/* Transmit timeout period */
+#define NF2_TIMEOUT    (2 * HZ)
+
+/* How many transmit buffers to allocate */
+#define NUM_TX_BUFFS   16
+
+/* How many transmit buffers to allocate */
+#define NUM_RX_BUFFS   8
+
+/* How large is the largest DMA transfer */
+#define MAX_DMA_LEN    2048
+
+/* Major device number for user devices */
+#define NF2_MAJOR 0   /* dynamic major by default */
+
+/* Maximum transmission size -- this should be
+ * max packet size - 14 for the Ethernet header */
+#define MTU 1986
+
+/*
+ * Debugging diagnostic printk
+ */
+#ifdef NF2_DEBUG
+#  define PDEBUG(fmt, args...) printk(fmt, ## args)
+#else
+#  define PDEBUG(fmt, args...) /* Don't do anything */
+#endif
+
+/**
+ * nf2_iface_priv - Interface data structure
+ * @card:  pointer to card this IF belongs to
+ * @iface: number of the interface
+ * @stats: statistics for this interface
+ *
+ * an instance of this structure exists for each interface/port
+ * on a control card.
+ * Not used for user cards.
+ */
+
+struct nf2_iface_priv {
+   /* Which card does this IF belong to? */
+   struct nf2_card_priv *card;
+
+   /* What number interface is this? */
+   unsigned int iface;
+
+   /* Statistics for the interface */
+   struct net_device_stats stats;
+};
+
+
+/**
+ * nf2_user_priv - User card private data
+ * @card:  pointer to the corresponding card
+ * @open_count:    to keep track of no. of opening
+ * @dev:   dev_t for user card
+ * @cdev:  char device
+ * @sem:   semaphore
+ * @rx_wr_pos:
+ * @rx_rd_pos: No of bytes available for reading
+ * @rx_buf_rd_pos: Actual read position
+ * @inq:   read queue
+ * @outq:  write queue
+ *
+ *
+ * an instance of this structure exists for each user card.
+ * Not used for control cards.
+ */
+struct nf2_user_priv {
+   /* The card corresponding to this structure */
+   struct nf2_card_priv *card;
+
+   /* How many times has this been opened? */
+   int open_count;
+
+   /* dev_t for user cards */
+   dev_t dev;
+
+   /* Char device */
+   struct cdev cdev;
+
+   /* Mutual exclusion semaphore */
+   struct semaphore sem;
+
+   /* Track the number of bytes available for reading */
+   u32 rx_wr_pos, rx_rd_pos;
+
+   /* Actual read position */
+   unsigned char *rx_buf_rd_pos;
+
+   /* Read and write queues */
+   wait_queue_head_t inq, outq;
+};
+
+
+/**
+ * nf2_card_priv - Card data structrue
+ * @pdev:  pointer to pci_dev
+ * @ioaddr:    address in board memory
+ * @is_ctrl:   is this control card
+ * @txbuff:    trasmit buffer
+ * @wr_txbuff:
+ * @rd_txbuff:
+ * @free_txbuffs:
+ * @free_txbuffs_port:
+ * @txbuff_lock:   spinlock
+ * @dma_tx_addr:   addr for dma tx
+ * @dma_rx_addr:   addr for dma rx
+ * @dma_tx_in_progress:    is dma tx in progress
+ * @dma_rx_in_progress: is dma rx in progress
+ * @dma_tx_lock:   spinlock for dma tx
+ * @dma_rx_lock:   spinlock for dma rx
+ * @ppool: packet pool for incoming packet
+ * @ndev:  network devices
+ * @ifup:  bitmask for up interfaces
+ * @state_lock: semaphore for state vars
+ * @upriv: user card variables
+ * @rd_pool:   last buffer used from pool
+ * @wr_pool:   current buffer to process
+ *
+ * - an instance of this data structure exists for each card.
+ */
+struct nf2_card_priv {
+   /* PCI device corresponding to the card */
+   struct pci_dev *pdev;
+
+   /* Address in memory of board */
+   void *ioaddr;
+
+   /* Control card */
+   char is_ctrl;
+
+   /* Transmit Buffers */
+   struct txbuff *txbuff;
+
+   /* Current and available txbuff */
+   int wr_txbuff;
+   int rd_txbuff;
+   int free_txbuffs;
+   int free_txbuffs_port[MAX_IFACE];
+
+   /* Spinlock for the buffer variables */
+   spinlock_t txbuff_lock;
+
+   /* Address of the DMA transfer */
+   u32 dma_tx_addr;
+   u32 dma_rx_addr;
+
+   /* Is a DMA transfer in progress? */
+   atomic_t dma_tx_in_progress;
+   atomic_t dma_rx_in_progress;
+   /*int dma_tx_in_progress;*/
+   /*int dma_rx_in_progress;*/
+
+   /* Spinlock for the dma variables */
+   atomic_t dma_tx_lock;
+   atomic_t dma_rx_lock;
+   /*spinlock_t dma_tx_lock;*/
+   /*spinlock_t dma_rx_lock;*/
+
+   /* Packet pool for incomming packets */
+   struct nf2_packet *ppool;
+
+   /* Interfaces that can currently transmit packets */
+   int dma_can_wr_pkt;
+
+   /* === Control Card Variables === */
+   /* Network devices */
+   struct net_device *ndev[MAX_IFACE];
+
+   /* Which interfaces are currently up?
+    * Note: This is a bitmask*/
+   unsigned int ifup;
+
+   /* Semaphore for the state variables */
+   struct semaphore state_lock;
+
+
+   /* === User Card Variables === */
+   struct nf2_user_priv *upriv;
+
+   /* The current buffer to process and the last
+    * buffer used from the pool */
+   struct nf2_packet *rd_pool, *wr_pool;
+};
+
+
+/**
+ * txbuff - Buffer to hold packets to be transmitted
+ * @skb:   socket buffer
+ * @buff:  buffer
+ * @len:   length field
+ * @iface: interface no
+ *
+ */
+struct txbuff {
+   struct sk_buff *skb;
+   char *buff;
+   u16 len;
+   unsigned int iface;
+};
+
+
+/**
+ * nf2_packet - A structure representing an in-flight packet being received.
+ * @next:  pointer to next packet
+ * @dev:   pointer to net_device
+ * @len:   length of packet
+ * @data:  data
+ *
+ */
+struct nf2_packet {
+   struct nf2_packet *next;
+   struct net_device *dev;
+   int len;
+   u8 data[MAX_DMA_LEN + 2];
+};
+
+
+/*
+ * Functions
+ */
+int nf2u_probe(struct pci_dev *pdev, const struct pci_device_id *id,
+       struct nf2_card_priv *card);
+void nf2u_remove(struct pci_dev *pdev, struct nf2_card_priv *card);
+int nf2c_probe(struct pci_dev *pdev, const struct pci_device_id *id,
+       struct nf2_card_priv *card);
+void nf2c_remove(struct pci_dev *pdev, struct nf2_card_priv *card);
+
+void nf2_set_ethtool_ops(struct net_device *dev);
+
+/*
+ * Variables
+ */
+extern int timeout;
+extern int rx_pool_size;
+extern int tx_pool_size;
+extern int nf2_major;
+extern int nf2_minor;
+
+#endif /* __KERNEL__ */
+
+#endif /* _NF2KERNEL_H */
diff --git a/kernel/mkd.c b/kernel/mkd.c
new file mode 100644
index 0000000..b17638a
--- /dev/null
+++ b/kernel/mkd.c
@@ -0,0 +1,1392 @@
+/*********************************************************************
+ * $Id: mkd.c,v 1.1 2006/10/31 07:28:57 skhay Exp $
+ * File  : mkd.c
+ * Author: Hayden Kwok-Hay So
+ * Date  : 12/15/2005
+ * Description:
+ *   mkd is the thread that is responsible for bridging between
+ * hardware message passing system and the linux kernel.  It is the
+ * main brain of BORPH
+ *********************************************************************/
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <asm/irq.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/sched.h>
+#include <linux/proc_fs.h>
+#define HDEBUG
+//#undef HDEBUG
+#define HDBG_LVL mkd_info->dbg_lvl
+#define HDBG_NAME "mkd"
+#include <linux/hdebug.h>
+#include <linux/kselectmap.h>
+#include <linux/borph.h>
+#ifndef __arch_um__
+#include "xparameters.h"
+#endif
+
+#define USEKTHREAD
+struct pphandler_arg {
+   struct task_struct* task;
+   int devId;
+   uint32_t loc;
+   uint32_t offset;
+   uint32_t size;
+};
+kmem_cache_t* pphandler_arg_cachep;
+
+
+/*****************************************************************
+ * Global Constant Definitions
+ *****************************************************************/
+// #undef USEINTERRUPT
+#define USEINTERRUPT
+
+#define MKD_VER "cvs-$Revision: 1.1 $"
+extern selectmap_t* selectmap_devs;
+static int mkd_interrupt_called = 0;
+
+/* helper functions */
+static inline int selectmap2buf(selectmap_t *dev, uint32_t cnt)
+{
+   PDEBUG(9, "selectmap2buf, try to pull %d bytes\n", cnt);
+   int id = dev->id;
+   unsigned char* bufe = mkd_info->mkd_bufe[id];
+   unsigned char* bufs = mkd_info->mkd_bufs[id];
+   unsigned buffree = mkdbuf_freep(bufs, bufe);
+   int partial_read = 0;
+
+   if (cnt == 0) {
+       return 0;
+   }
+   /* partial read */
+   if (buffree < cnt) {
+       /* can dead lock if uk sending packet > ~1k */
+       PDEBUG(9, "Partial read (dev %d): buffree=%d, cnt=%d\n", 
+              id, buffree, cnt);
+       partial_read = 1;
+       cnt = buffree;
+   }
+   /* we are certain we have at least cnt bytes in kernel buffer */
+   while (cnt--) {
+       selectmap_in_data(dev, *bufe);
+       bufe = mkdbuf_add(bufe, 1);
+   }
+   mkd_info->mkd_bufe[id] = bufe;
+
+   if (partial_read) return -1;
+
+   return 0;
+}
+
+int kernel_file_read(struct file *file, char * buf,
+            size_t count, loff_t offset)
+{
+   mm_segment_t old_fs;
+   int retval = -ENOSYS;
+   if (offset) {
+       if (!file->f_op || !file->f_op->llseek) {
+           PDEBUG(0,"offset=%llu !=0 but no llseek found\n",offset);
+           goto out;
+       }
+       retval = file->f_op->llseek(file, offset, 0 /*SEEK_SET*/);
+       if (retval)
+           goto out;
+   }
+   if (!file->f_op || !file->f_op->read) {
+       retval = -ENOSYS;
+       PDEBUG(0,"NO READ FUNCTION!\n");
+       goto out;
+   }
+   PDEBUG(9,"READ FUNCTION is here, let's read!\n");
+
+   old_fs = get_fs();
+   set_fs(get_ds());
+   retval = file->f_op->read(file, buf, count, &file->f_pos);
+   set_fs(old_fs);
+ out:
+   return retval;
+}
+
+int kernel_write(struct file *file, const char * buf,
+        size_t count, loff_t offset)
+{
+   mm_segment_t old_fs;
+   int retval = -ENOSYS;
+   if (offset) {
+       if (!file->f_op || !file->f_op->llseek) {
+           PDEBUG(0,"offset=%llu !=0 but no llseek found\n",offset);
+           goto out;
+       }
+       retval = file->f_op->llseek(file, offset, 0 /*SEEK_SET*/);
+       if (retval)
+           goto out;
+   }
+   if (!file->f_op || !file->f_op->write) {
+       retval = -ENOSYS;
+       PDEBUG(0,"NO WRITE FUNCTION!\n");
+       goto out;
+   }
+   PDEBUG(9,"WRITE FUNCTION is here, let's write!\n");
+
+   old_fs = get_fs();
+   set_fs(get_ds());
+   retval = file->f_op->write(file, buf, count, &file->f_pos);
+   set_fs(old_fs);
+ out:
+   return retval;
+}
+
+static inline struct file * fcheck_task(struct task_struct* task, 
+                   unsigned int fd)
+{
+         struct file * file = NULL;
+         struct files_struct *files = task->files;
+
+         if (fd < files->max_fds)
+                 file = files->fd[fd];
+         return file;
+}
+
+
+static void mkd_interrupt(int irq, void *dev_id, struct pt_regs *regs) {
+   int i, needmkd;
+   uint32_t reg, d, mask;
+   selectmap_t* dev;
+   struct timeval tv[2];
+
+   if (HDBG_LVL >= 8) {
+       do_gettimeofday(tv);
+   }
+
+   mkd_interrupt_called += 1;
+   /* we need both isr and ier to figure out who calls me
+    * because when a FPGA is unconfigured, it's intr pin
+    * might be high.  Even we can disable that interrupt
+    * via ier, this 1 still shows up at isr.  So we have 
+    * to mask it out ourselves */
+   in_intr_reg(SELMAP_INTR_IPISR, reg);
+   in_intr_reg(SELMAP_INTR_IPIER, d);
+   reg = reg & d;
+
+   mkd_info->selectmap_pending |= reg;
+   /* pull all the bytes into my mkd_buf[id] */
+   needmkd = 0;
+   for (i = 0, mask=0x1UL; i < SELECTMAP_NUM_DEVS; i++, mask <<= 1) {
+       if (reg & mask) {
+           int buffull, oldipier;
+           dev = &selectmap_devs[i];
+           /* disable interrupt */
+           PDEBUG(9, "disable interrupt for device %d\n", i);
+           in_intr_reg(SELMAP_INTR_IPIER, oldipier);
+           out_intr_reg(SELMAP_INTR_IPIER, oldipier & ~mask);
+           /* clear interrupt (first clear the source from
+            * selectmap, then clear ISR on opbipif*/
+           selectmap_out_status(dev, 0x0e000000);
+           out_intr_reg(SELMAP_INTR_IPISR, mask);
+
+           selectmap_in_status(dev, d);
+           d = SELECTMAP_RFIFO_CNT(d);
+
+           buffull = selectmap2buf(dev, d);
+           needmkd = 1;
+           /* renable only if not buffer full*/
+           if (buffull) {
+               // reinstate interrupt, but don't enable it
+               PDEBUG(9, "reinstate interupt\n");
+               mkd_info->fifo_pending |= mask;
+           } else {
+               PDEBUG(9, "reenable interupt\n");
+               mkd_info->fifo_pending &= ~mask;
+               out_intr_reg(SELMAP_INTR_IPIER, oldipier);
+           }
+       }
+   }
+   if (needmkd) {
+       wake_up_interruptible(&mkd_info->mkdrdq);
+   }
+   if (HDBG_LVL >= 8) {
+       do_gettimeofday(tv+1);
+       PDEBUG(8, "ACCT mkd_interrupt:%ld,%ld:%ld,%ld\n", 
+              tv[0].tv_sec, tv[0].tv_usec,tv[1].tv_sec, tv[1].tv_usec);
+   }
+   return;
+}
+
+/**************************** begin ppacket **********************************/
+
+static int selectmap_avail(selectmap_t* dev, int size)
+{
+   int retry = 400, burst;
+   u32 d;
+   while (retry) {
+       selectmap_in_status(dev, d);
+       burst = SELECTMAP_WFIFO_CNT(d);
+       PDEBUG(9, "selectmap_avail: request %d, got %d avail\n",
+              size, burst);
+       if (burst >= size) return 0;
+
+/*     set_current_state(TASK_INTERRUPTIBLE);
+       schedule_timeout(0.01*HZ); */
+       retry -= 1;
+   }
+   return -1;
+}
+
+static int selectmap_sendbuf(selectmap_t* dev, int size, buf_t* buf)
+{
+   int ret, burst;
+
+   PDEBUG(9, "selectmap_sendbuf\n");
+   do {
+       burst = SELECTMAP_FIFO_NUM_BYTES;
+       if (size < burst) burst = size;
+       PDEBUG(9, "Try to get %d bytes space\n", burst);
+       if ((ret = selectmap_avail(dev, burst)) < 0) {
+           return ret;
+       }
+       PDEBUG(9, "Got it, sending data now");
+       size -= burst;
+       do {
+           selectmap_out_data(dev, *buf++);
+       } while (--burst);
+   } while (size);
+   return 0;
+}
+
+static inline void pp_send_readack(unsigned char* buf, int fd, 
+                  int size, int devId)
+{
+   selectmap_t* dev;
+   dev = get_selmapdev(devId);
+   if (!dev) {
+       PDEBUG(0, "pp_send_readack: cannot get dev %d\n", devId);
+       return;
+   }
+
+   PDEBUG(9, "pp_send_readack, size=%d, buf[0,1,2,3]=[%x %x %x %x]\n",
+          size, buf[0], buf[1], buf[2], buf[3]);
+   /* Send header */
+   if (selectmap_avail(dev, 8) < 0) {
+       PDEBUG(9, "timeout selectmap_avail(8)\n");
+   }
+   PDEBUG(9, "pp_send_readack got seleptmap buffer\n");
+   selectmap_out_data(dev, PP_CMD_READACK);
+   selectmap_out_data(dev, (fd >> 16) & 0xFF);
+   selectmap_out_data(dev, (fd >> 8) & 0xFF);
+   selectmap_out_data(dev, fd & 0xFF);
+   selectmap_out_data(dev, (size >> 24) & 0xFF);
+   selectmap_out_data(dev, (size >> 16) & 0xFF);
+   selectmap_out_data(dev, (size >> 8) & 0xFF);
+   selectmap_out_data(dev, size & 0xFF);
+   if (size > 0) {
+       if (selectmap_sendbuf(dev, size, buf)) {
+           printk("Cannot send readack buffer of size %d to dev %d\n",
+                  size, devId);
+       }
+   }
+   put_selmapdev(dev);
+   return;
+}
+
+static inline void pp_send_writeack(int fd, int size, int devId)
+{
+   selectmap_t* dev;
+   PDEBUG(9, "pp_send_writeack, fd=%d, size=%d\n", fd, size);
+
+   dev = get_selmapdev(devId);
+   if (!dev) {
+       PDEBUG(0, "pp_send_writeack: cannot get dev %d\n", devId);
+       return;
+   }
+   selectmap_out_data(dev, PP_CMD_WRITEACK);
+   selectmap_out_data(dev, (fd >> 16) & 0xFF);
+   selectmap_out_data(dev, (fd >> 8) & 0xFF);
+   selectmap_out_data(dev, fd & 0xFF);
+   selectmap_out_data(dev, (size >> 24) & 0xFF);
+   selectmap_out_data(dev, (size >> 16) & 0xFF);
+   selectmap_out_data(dev, (size >> 8) & 0xFF);
+   selectmap_out_data(dev, size & 0xFF);
+
+   put_selmapdev(dev);
+   return;
+}
+
+static int fringe_chksig(void)
+{
+   int signaled = 0;
+   while(signal_pending(current)) {
+       siginfo_t info;
+       unsigned long signr;
+
+       signaled = 1;
+       spin_lock_irq(&current->sigmask_lock);
+       signr = dequeue_signal(&current->blocked, &info);
+       spin_unlock_irq(&current->sigmask_lock);
+ 
+       switch(signr) {
+       case SIGSTOP: case SIGTSTP: case SIGTTIN: case SIGTTOU:
+           PDEBUG(9, "fringe got stopping signal #%lu\n", signr);
+           set_current_state(TASK_STOPPED);
+           schedule();
+           break;
+       case SIGKILL: case SIGINT: case SIGTERM:
+           PDEBUG(9, "fringe got KILL-ing signal %lu\n", signr);
+           return -1;
+       case SIGCONT:
+           PDEBUG(9, "fringe got SIGCONT\n");
+           /* need to repeat the read */
+           break;
+       default:
+           PDEBUG(0, "Unhandled signal %lu received\n", signr);
+           break; 
+       }
+   }
+   return signaled;
+}
+
+static int read_handler_fringe(void* p)
+{
+   struct pphandler_arg* arg;
+   uint32_t loc, offset, size;
+   struct task_struct *task;
+   int retval;
+   char* page;
+   struct files_struct* files;
+   struct file* file; 
+   struct task_list* tskitem;
+   struct borph_info* bi;
+   int signaled;
+   struct timeval tv[4];
+
+   arg = (struct pphandler_arg*) p;
+   loc = arg->loc;
+   offset = arg->offset;
+   size = arg->size;
+   task = arg->task;
+
+   while (!task->did_exec) {
+       schedule_timeout(10);
+   }
+
+   /* make sure we are connected to the same tty we are supposed to
+    * It is like daemonize(), except we want us to be exactly like task */
+   exit_mm(current);
+   current->session = task->session;
+   current->pgrp = task->pgrp;
+   current->tty = task->tty;
+
+   /* Clone my "parent's" fs, files, sighand */
+   exit_fs(current);
+   current->fs = task->fs;
+   atomic_inc(&current->fs->count);
+
+   exit_files(current);
+        current->files = task->files;
+   atomic_inc(&current->files->count);
+
+   exit_sighand(current);
+   current->sig = task->sig;
+   atomic_inc(&current->sig->count);
+
+   /* It is a mystery here:
+    * For some reason, the task->blocked is set to everything but SIGKILL
+    * the *first time*, and only the first time. we get to this point,
+    * regardless of whether task->did_exec is set.
+    *
+    * The second time around we get to this point, task->blocked is always
+    * automatically set to the default of all zero (except sig 64).
+    * 
+    * I have no idea why is it the case.  The odd thing is, if I enable
+    * BORPH debugging level to 9, when tons of debugging messages are
+    * printed for each packet received, somehow this odd "all-blocked" 
+    * behavior never shows up.  It is highly likely something to
+    * do with scheduling or some magic signal handling code that
+    * I still haven't figured all out.
+    *
+    * For now, I am giving up and manually set current->block to
+    * empty
+    *
+    * Hayden So (8/1/06)
+    * [for reference here are the old code ]
+    * memcpy(&current->blocked, &task->blocked, sizeof(sigset_t));
+    * printk("MYDEBUG: current->blocked: [1 0] = [0x%lx 0x%lx]\n", current->blocked.sig[1], current->blocked.sig[0]);
+    * printk("       : task->blocked: [1 0] = [0x%lx 0x%lx]\n", task->blocked.sig[1], task->blocked.sig[0]);
+    * printk("       : task->did_exec = %d\n", task->did_exec);
+    */
+   sigemptyset(&current->blocked);
+   flush_signals(current);
+   recalc_sigpending(current);
+
+   reparent_to_init();
+
+   /* this is essentially fget except it doesn't use current */
+   retval = -EINVAL;
+   files = task->files;
+   read_lock(&files->file_lock);
+   file = fcheck_task(task, loc);
+   if (!file) {
+       PDEBUG(0, "invalid loc %d in pp_read_hander (file not found)\n", loc);
+       read_unlock(&files->file_lock);
+       goto out_freearg;
+   }
+   get_file(file);
+   read_unlock(&files->file_lock);
+
+   if (!(page = (char*) __get_free_page(GFP_KERNEL)))
+       goto out_putfile;
+
+   retval = -ENOMEM;
+   tskitem = kmem_cache_alloc(task_list_cachep, GFP_KERNEL);
+   if (!tskitem) {
+       goto out_freepage;
+   }
+   tskitem->tsk = current;
+   tskitem->data = arg;
+
+   bi = task->borph_info;
+   write_lock(&bi->hcptr_lock);
+   list_add(&tskitem->tsk_list, &bi->hcptr);
+   bi->fringes[loc] = tskitem;
+   write_unlock(&bi->hcptr_lock);
+
+   /**************************************************
+    * Main Reading Loop 
+    *************************************************/
+ loop:
+   PDEBUG(9, "Reading from pid=%d, fd=%d, offset=%d, size=%d\n",
+          task->pid, loc, offset, size);
+   do {
+       /* if a read is interrupted by harmless
+          signal, we repeat the read automatically */
+       if (HDBG_LVL >= 8) {
+           do_gettimeofday(tv);
+       }
+       retval = kernel_file_read(file, page, size, offset);
+       if (HDBG_LVL >= 8) {
+           do_gettimeofday(tv+1);
+       }
+       PDEBUG(9, "kernel_file_read returns %d bytes\n", retval);
+       signaled = fringe_chksig();
+       if (signaled < 0)
+           goto out;
+   } while (signaled);
+   /* task might have died while we were blocked on the read */
+   if (!task->pid) goto out;
+
+   /* send read ack */
+   if (HDBG_LVL >= 8) {
+       do_gettimeofday(tv+2);
+   }
+   pp_send_readack(page, loc, retval, arg->devId);
+   if (HDBG_LVL >= 8) {
+       do_gettimeofday(tv+3);
+       PDEBUG(8, "ACCT read_handler_fringe:%ld,%ld:%ld,%ld:%ld,%ld:%ld,%ld\n",
+              tv[0].tv_sec,tv[0].tv_usec,tv[1].tv_sec,tv[1].tv_usec,
+              tv[2].tv_sec,tv[2].tv_usec,tv[3].tv_sec,tv[3].tv_usec);
+   }
+
+   write_lock(&tskitem->data_lock);
+   kmem_cache_free(pphandler_arg_cachep, arg);
+   tskitem->data = NULL;
+   arg = NULL;
+   write_unlock(&tskitem->data_lock);
+   /**************************************************
+    * Now go to sleep to standby for next read
+    *************************************************/
+
+   for (;;) {
+       set_current_state(TASK_INTERRUPTIBLE);
+       if (!tskitem->data) {
+           schedule();
+       }
+       __set_current_state(TASK_RUNNING);
+       
+       if (fringe_chksig() < 0)
+           goto out;
+       if (tskitem->data) {
+           arg = (struct pphandler_arg*) tskitem->data;
+           if (loc != arg->loc || task != arg->task ) {
+               printk("read_fringe woken up with invalid arg:\n");
+               printk(" arg->loc = %d, loc = %d\n", arg->loc, loc);
+               printk(" arg->task = %p, task = %p\n", arg->task, task);
+               retval = -EINVAL;
+               goto out;
+           }
+           offset = arg->offset;
+           size = arg->size;
+           goto loop;
+       }
+   }
+   
+ out:
+   tskitem->tsk = NULL;
+   tskitem->data = NULL;
+   write_lock(&bi->hcptr_lock);
+   list_del_init(&tskitem->tsk_list);
+   bi->fringes[loc] = NULL;
+   write_unlock(&bi->hcptr_lock);
+   kmem_cache_free(task_list_cachep, tskitem);
+ out_freepage:
+   free_page((unsigned long)page);
+ out_putfile:
+   put_filp(file);
+ out_freearg:
+   if (arg) {
+       kmem_cache_free(pphandler_arg_cachep, arg);
+   }
+   return retval;
+}
+
+/* in this hacky version, loc# always means fd# */
+static void pp_read_handler(unsigned char* buf, struct task_struct* task, 
+               int devId)
+{
+   uint32_t loc, offset, size;
+   struct pphandler_arg* arg;
+   struct borph_info* bi;
+   struct task_list* tskitem;
+   if (!task || !task->borph_info) {
+       PDEBUG(0, "pp_read_handler error: task==null\n");
+       return;
+   }
+   bi = task->borph_info;
+
+   loc = mkdbuf_getword(devId, 0) & 0xFFFFFF;
+   offset = mkdbuf_getword(devId, 4);
+   size = mkdbuf_getword(devId, 8);
+   IncrBufS(devId, 12);
+
+   arg = kmem_cache_alloc(pphandler_arg_cachep, GFP_KERNEL);
+   if (!arg) {
+       printk("no mem when getting arg!\n");
+       return;
+   }
+   arg->task = task;
+   arg->devId = devId;
+   arg->loc = loc;
+   arg->offset = offset;
+   arg->size = size;
+#ifdef USEKTHREAD
+   if (loc >= 0 && loc < NR_OPEN_DEFAULT) {
+       read_lock(&bi->hcptr_lock);
+       tskitem = bi->fringes[loc];
+       if (tskitem && tskitem->tsk) {
+           write_lock(&tskitem->data_lock);
+           tskitem->data = arg;
+           write_unlock(&tskitem->data_lock);
+           wake_up_process(tskitem->tsk);
+       } else {
+           kernel_thread(read_handler_fringe, arg, CLONE_FS | CLONE_FILES | CLONE_SIGHAND);
+       }
+       read_unlock(&bi->hcptr_lock);
+   } else {
+       printk("Invalid loc=%d in pp_read_handler\n", loc);
+   }
+#else
+   read_handler_helper(arg);
+   kmem_cache_free(pphandler_arg_cachep, arg);
+#endif
+   return;
+}
+
+/*
+ * We are gauranteed that our packet is contiguous in buf
+ */
+static void pp_write_handler(unsigned char* buf, struct task_struct* task, 
+                int devId)
+{
+   uint32_t loc, offset, size;
+   buf_t* payload;
+   int retval;
+   struct files_struct* files;
+   struct file* file;
+   struct timeval tv[2];
+
+   if (!task) {
+       PDEBUG(0, "pp_write_handler error: task==null\n");
+       return;
+   }
+
+   loc = be32_to_cpup((__u32*) buf) & 0xFFFFFF;
+   offset = be32_to_cpup((__u32*) (buf + 4));
+   size = be32_to_cpup((__u32*) (buf + 8));
+   payload = buf+12;
+
+   PDEBUG(9, "Writing to pid=%d, fd=%d, offset=%d, size=%d, payload=[%x %x %x %x]\n",
+          task->pid, loc, offset, size, buf[12], buf[13], buf[14], buf[15]);
+   /* this is similar fget except it writes and doesn't use current */
+   files = task->files;
+   write_lock(&files->file_lock);
+   file = fcheck_task(task, loc);
+   if (!file) {
+       PDEBUG(0, "invalid loc %d in pp_write_handler\n", loc);
+       goto out;
+   }
+   get_file(file);
+   write_unlock(&files->file_lock);
+
+   PDEBUG(9, "just before we call kernel_write: file=%p,"
+          "buf=[%x %x %x %x], size=%d, offset=%d", file, 
+          payload[0], payload[1], payload[2], payload[3], 
+          size, offset);
+   if (HDBG_LVL >= 8) {
+       do_gettimeofday(tv+0);
+   }
+   retval = kernel_write(file, payload, size, offset);
+   if (HDBG_LVL >= 8) {
+       do_gettimeofday(tv+1);
+       PDEBUG(8, "ACCT pp_write_handler:%ld,%ld:%ld,%ld\n",
+              tv[0].tv_sec,tv[0].tv_usec,tv[1].tv_sec,tv[1].tv_usec);
+
+   }
+   PDEBUG(9, "kernel_write returns %d\n", retval);
+
+// pp_send_writeack(loc, retval, devId);
+   put_filp(file);
+ out:
+   /* pull packet from mkd_buf[id]*/
+   IncrBufS(devId, 12+size);
+}
+
+static void pp_exit_handler(struct task_struct* task, int devId)
+{
+   int exit_code;
+   struct siginfo info;
+   if (!task) goto out;
+
+   exit_code = mkdbuf_getword(devId, 1) & 0xFFFF;
+   PDEBUG(9, "exit code = %d\n", exit_code);
+   info.si_signo = SIGKILL;
+   info.si_errno = (1 << 16) | exit_code;
+   info.si_code = SI_KERNEL;
+   info.si_pid = 0;
+   info.si_uid = 0;
+   send_sig_info(SIGKILL, &info, task);
+ out:
+   IncrBufS(devId, 5);
+}
+
+/* Note, we don't have semaphore on selectmap dev here 
+ * return 0 on success
+ *        1 if we see partial packet
+ *        2 if buffer is empty
+ *        <0 on error
+ *       -1: misc error
+ *       -2: invalid command
+ */
+static int handle_ppacket(int devId)
+{
+   struct phyhwr* hwr;
+   // int id = dev->id;
+   unsigned char* bufs;
+   unsigned char* bufe;
+   unsigned char* end;
+   unsigned char c;
+   int buflen;
+   struct hwr_addr a;
+   int size;
+   int retval = 0;
+
+   /* get lock on mkd_buf before we access any mkd_buf*/
+   if ((retval = down_interruptible(&mkd_info->bufrsem[devId])) != 0) {
+       printk("Failed to get semaphore bufrsem: retval=%d\n", retval);
+       return 1;
+   }
+   retval = 0;
+
+   bufs = mkd_info->mkd_bufs[devId];
+   bufe = mkd_info->mkd_bufe[devId];
+   buflen = (bufe < bufs)?(bufe + (PAGE_SIZE / 4) - bufs):(bufe-bufs);
+   if (buflen <= 0) {
+       retval = 2;
+       goto out;
+   }
+
+   a.addr = devId;
+   a.class = HAC_BEE2FPGA;
+   hwr = get_hwr(&a);
+   if (!hwr) {
+       PDEBUG(0, "cannot get hwr %d\n", devId);
+       retval = -1;
+       goto out;
+   }
+
+   if (HDBG_LVL >= 8) {
+       struct timeval tv;
+       do_gettimeofday(&tv);
+       PDEBUG(8, "ACCT handle_ppacket:%ld,%ld\n",tv.tv_sec,tv.tv_usec);
+   }
+   c = *bufs;
+   switch(c) {
+   case PP_CMD_READ :
+       PDEBUG(9, "received packet PP_CMD_READ.\n");
+       retval = 1;
+       if (buflen >= 12) {
+           pp_read_handler(bufs, hwr->task, devId);
+           retval = 0;
+       }
+       break;
+   case PP_CMD_READACK :
+       /*  as if I am interrupt handler */
+       PDEBUG(9, "received packet PP_CMD_READACK. Wakeup waiting process\n");
+       if (buflen < 8) {
+           PDEBUG(9, "buflen < 8, packet ignored for now\n");
+           retval = 1;
+           break;
+       }
+       size = mkdbuf_getword(devId, 4);
+       if (buflen < 8 + size) {
+           PDEBUG(9, "readack packet payload not ready, ignored (buflen=%d, size=%d)\n", buflen, size);
+           retval = 1;
+           break;
+       }
+
+       up(&mkd_info->bufrsem[devId]);
+       __put_hwr(hwr);
+       wake_up_interruptible(&mkd_info->bufrdq[devId]);
+       return 1;
+   case PP_CMD_WRITEACK :
+       /*  as if I am interrupt handler */
+       PDEBUG(9, "received packet PP_CMD_WRITEACK. Wakeup waiting process\n");
+       if (buflen < 8) {
+           PDEBUG(9, "buflen < 8, packet ignored for now\n");
+           retval = 1;
+           break;
+       }
+       up(&mkd_info->bufrsem[devId]);
+       __put_hwr(hwr);
+       wake_up_interruptible(&mkd_info->bufrdq[devId]);
+       return 1;
+   case PP_CMD_WRITE :
+       PDEBUG(9, "received packet PP_CMD_WRITE.\n");
+       PDEBUG(10, "buf dump:\n");
+       PDEBUG(10, " [%02x %02x %02x %02x %02x %02x %02x %02x "
+              "%02x %02x %02x %02x %02x %02x %02x %02x]\n", 
+              bufs[0], bufs[1], bufs[2], bufs[3], 
+              bufs[4], bufs[5], bufs[6], bufs[7], 
+              bufs[8], bufs[9], bufs[10], bufs[11], 
+              bufs[12], bufs[13], bufs[14], bufs[15]);
+       if (buflen < 12) {
+           PDEBUG(9, "bunlen < 12, packet ignored for now\n");
+           retval = 1;
+           break;
+       }
+       size = mkdbuf_getword(devId, 8);
+       if (buflen < 12 + size) {
+           PDEBUG(9, "packet payload not ready, ignored (buflen=%d, size=%d)\n", buflen, size);
+           retval = 1;
+           break;
+       }
+
+       /* copy to contigous page before calling handler */
+       end = mkdbuf_add(bufs, 12 + size);
+       if (end < bufs) {
+           buf_t* origin = mkd_info->mkd_buf[devId];
+           int clen = origin + (PAGE_SIZE / 4) - bufs;
+           buf_t* b = (buf_t*)get_free_page(GFP_KERNEL);
+           PDEBUG(5, "Wrap around in packet buffer: origin=%p, end=%p, bufs=%p, clen=%d, size=%d\n", origin, end, bufs, clen, size);
+           memcpy(b, bufs, clen);
+           memcpy(b+clen, origin, size + 12 - clen);
+           pp_write_handler(b, hwr->task, devId);
+           free_page((unsigned long) b);
+       } else {
+           pp_write_handler(bufs, hwr->task, devId);
+       }
+       break;
+   case PP_CMD_EXIT:
+       PDEBUG(9, "got PP_CMD_EXIT\n");
+       if (buflen < 5) {
+           PDEBUG(9, "packet payload not ready, ignored (buflen=%d)\n", buflen);
+       }
+       pp_exit_handler(hwr->task, devId);
+       break;
+   default:
+       printk("Unknown packet command %d\n", c);
+       /* kill the task */
+       force_sig(SIGKILL, hwr->task);
+       
+       {
+           buf_t* p;
+           int i;
+           printk("bufs = 0x%p, bufe = 0x%p, buflen=%d\n", 
+              bufs, bufe, buflen);
+           printk("buf dump:\n");
+           for (p = mkd_info->mkd_buf[devId], i = 0; 
+            i < 1024; i += 8, p += 8) {
+           printk("%p  %02x %02x %02x %02x %02x %02x %02x %02x\n", p, p[0],p[1],p[2],p[3],p[4],p[5],p[6],p[7]);
+           }
+       }
+       retval = -1;
+   }
+   __put_hwr(hwr);
+ out:
+   up(&mkd_info->bufrsem[devId]);
+   return retval;
+}
+
+/************ end ppacket ********************************************/
+
+/* NOT USED FOR INTERRUPT CASE */
+static inline int handle_selectmap_dev(int devnum)
+{
+   selectmap_t *dev;
+   uint32_t status, cnt;
+   int retval;
+
+   dev = get_selmapdev(devnum);
+   if (!dev) {
+       return -1;
+   }
+
+   selectmap_in_status(dev, status);
+   cnt = SELECTMAP_RFIFO_CNT(status);
+   if (cnt && (cnt <= mkdbuf_free(dev->id))) {
+       PDEBUG(9, "selectmap %d has %d bytes available\n", 
+              devnum, cnt);
+       selectmap2buf(dev, cnt);
+       put_selmapdev(dev);
+       
+       PDEBUG(9, "BEFORE: bufs=0x%p bufe=0x%p\n", 
+              mkd_info->mkd_bufs[dev->id], 
+              mkd_info->mkd_bufe[dev->id]);
+       do { /* nothing */
+       } while ((retval = handle_ppacket(dev->id)) == 0);
+       PDEBUG(9, "AFTER: bufs=0x%p bufe=0x%p\n", 
+              mkd_info->mkd_bufs[dev->id], 
+              mkd_info->mkd_bufe[dev->id]);
+   }
+   put_selmapdev(dev);
+
+   return retval;
+}
+
+static inline void poll_selectmap(void)
+{
+   int devnum;
+   struct hwr_addr a;
+   a.class = HAC_BEE2FPGA;
+   PDEBUG(10, "polling selectmap\n");
+   for (devnum = 0; devnum < SELECTMAP_NUM_DEVS; devnum++) {
+       a.addr = devnum;
+       if (hwr_inuse(&a) <= 0) 
+           continue;
+       if (handle_selectmap_dev(devnum)) continue;
+   }
+}
+
+/*
+ * this is used in interrupted version
+ * instead of randomly polling, we chenck the 
+ * pending flag in mkd_info , which is set by interrpt 
+ * handler
+ */
+static inline void handle_selectmap(void)
+{
+   int i, ret;
+   unsigned mask = 1UL;
+   uint32_t d;
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       if (mkd_info->selectmap_pending & mask) {
+           mkd_info->selectmap_pending &= ~mask;
+           do { /* nothing */
+           } while ((ret = handle_ppacket(i)) == 0);
+           
+           // re-enable interrupt to make sure we 
+           // get interrupt when the remaining of
+           // packet arrives
+           in_intr_reg(SELMAP_INTR_IPIER, d);
+           if (!(d & mask)) {
+               PDEBUG(10, "Reenable interrupt for device %d\n", i);
+               out_intr_reg(SELMAP_INTR_IPIER, d | mask);
+           }
+       }
+       mask = mask << 1;
+   }
+}
+
+
+/*
+ * proc entries for debug
+ */
+
+static struct proc_dir_entry *p_borph_dir, *p_allmkdbuf;
+static struct proc_dir_entry *p_empty[SELECTMAP_NUM_DEVS];
+static struct proc_dir_entry *p_mkdbuf[SELECTMAP_NUM_DEVS];
+static struct proc_dir_entry *p_dbg_lvl;
+static struct proc_dir_entry *p_bversion;
+#if SELECTMAP_NUM_DEVS == 5
+static char* str_empty[SELECTMAP_NUM_DEVS] = {"empty_mkdbuf0", "empty_mkdbuf1", "empty_mkdbuf2", "empty_mkdbuf3", "empty_mkdbuf4"};
+static char* str_mkdbuf[SELECTMAP_NUM_DEVS] = {"mkdbuf0", "mkdbuf1", "mkdbuf2", "mkdbuf3", "mkdbuf4"};
+#else
+static char* str_empty[SELECTMAP_NUM_DEVS] = {"empty_mkdbuf0", "empty_mkdbuf1", "empty_mkdbuf2", "empty_mkdbuf3"};
+static char* str_mkdbuf[SELECTMAP_NUM_DEVS] = {"mkdbuf0", "mkdbuf1", "mkdbuf2", "mkdbuf3"};
+#endif
+static int proc_empty_mkdbuf_write(struct file *file,
+                  const char *buffer,
+                  unsigned long count, 
+                  void *data)
+{
+   char c;
+   int id = (int) data;
+   if (!mkd_info)
+       return -EBUSY;
+
+        MOD_INC_USE_COUNT;
+   if (copy_from_user(&c, buffer, 1)) {
+       MOD_DEC_USE_COUNT;
+       return -EFAULT;
+   }
+   if (c == '1') {
+       mkd_info->mkd_bufs[id] = mkd_info->mkd_bufe[id];
+   }
+   MOD_DEC_USE_COUNT;
+   return count;
+}
+
+static int proc_mkdbuf_write(struct file *file, const char *buffer,
+                unsigned long count, void *data)
+{
+   int id, len;
+   buf_t *start, *next, *bufe, *bufs;
+   if (!mkd_info)
+       return -EBUSY;
+
+        MOD_INC_USE_COUNT;
+   id = (int) data;
+   
+   start = mkd_info->mkd_buf[id];
+   bufe = mkd_info->mkd_bufe[id];
+   bufs = mkd_info->mkd_bufs[id];
+   printk("proc_mkdbuf_write id=%d bufe=0x%p\n", id, bufe);
+   /* I'm lazy */
+   if (!access_ok(VERIFY_READ, buffer, count)) {
+                MOD_DEC_USE_COUNT;
+       return -EFAULT;
+   }
+   next = bufe;
+   
+   next = ((((unsigned long) bufe) + 1) % (PAGE_SIZE/4)) + start;
+   len = count;
+   while (next != bufs && len--) {
+       __get_user(*bufe, buffer++);
+       printk("buf = 0x%X\n", *bufe);
+       bufe = next;
+       next = ((((unsigned long) bufe) + 1) % (PAGE_SIZE/4)) + start;
+   }
+
+   mkd_info->mkd_bufe[id] = bufe;
+   printk("proc_mkdbuf_write exit, bufe=0x%p\n", bufe);
+   MOD_DEC_USE_COUNT;
+   return count;
+}
+
+static int proc_allmkdbuf_read(char *page, char **start,
+                            off_t off, int count, 
+                            int *eof, void *data)
+{
+   if (!mkd_info)
+       return -EBUSY;
+
+        MOD_INC_USE_COUNT;
+        memcpy(page, mkd_info->mkd_buf[0], PAGE_SIZE);
+        MOD_DEC_USE_COUNT;
+
+        return PAGE_SIZE;
+}
+
+static int proc_dbglvl_read(char *page, char **start,
+                 off_t off, int count, 
+                 int *eof, void *data)
+{
+   if (!mkd_info)
+       return -EBUSY;
+
+        MOD_INC_USE_COUNT;
+   sprintf(page, "%d\n", mkd_info->dbg_lvl);
+        MOD_DEC_USE_COUNT;
+
+        return strlen(page);
+}
+
+static int proc_dbglvl_write(struct file *file,
+                const char *buffer,
+                unsigned long count, 
+                void *data)
+{
+   char c;
+   if (!mkd_info)
+       return -EBUSY;
+
+        MOD_INC_USE_COUNT;
+   if (copy_from_user(&c, buffer, 1)) {
+       MOD_DEC_USE_COUNT;
+       return -EFAULT;
+   }
+   if ('0' <= c && c <= '9') {
+       mkd_info->dbg_lvl = (c - '0');
+   }
+   MOD_DEC_USE_COUNT;
+   return count;
+}
+
+static int proc_bversion_read(char *page, char **start,
+                            off_t off, int count, 
+                            int *eof, void *data)
+{
+   const char * bver = "1.0-rc4";
+   int bver_len = strlen(bver) + 1;
+        MOD_INC_USE_COUNT;
+        memcpy(page, bver, bver_len);
+        MOD_DEC_USE_COUNT;
+
+        return bver_len;
+}
+
+static int __init proc_mkd_init(void)
+{
+   int retval = -ENOMEM;
+   struct proc_dir_entry *tmp;
+   int i;
+
+   /* main borth proc entry */
+   p_borph_dir = proc_mkdir("borph", NULL);
+        if (p_borph_dir == NULL) {
+                goto out;
+        }
+   /* read all buffers */
+   p_allmkdbuf = create_proc_read_entry("allmkdbuf", 
+                                              0400, p_borph_dir, 
+                                              proc_allmkdbuf_read,
+                                              NULL);
+   if (p_allmkdbuf == NULL) {
+       goto no_allmkdbuf;
+   }
+   p_allmkdbuf->owner = THIS_MODULE;
+
+   /* empty particular mkdbuf */
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       tmp = create_proc_entry(str_empty[i], 0200, p_borph_dir);
+       if(tmp == NULL) {
+           goto partial_empty;
+       }
+       tmp->write_proc = proc_empty_mkdbuf_write;
+       tmp->data = (void*) i;
+       tmp->owner = THIS_MODULE;
+       p_empty[i] = tmp;
+   }
+
+   /* inject bytes into mkd_buf */
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       tmp = create_proc_entry(str_mkdbuf[i], 0200, p_borph_dir);
+       if(tmp == NULL) {
+           goto partial_mkdbuf;
+       }
+       tmp->owner = THIS_MODULE;
+       tmp->write_proc = proc_mkdbuf_write;
+       tmp->data = (void *) i;
+       p_mkdbuf[i] = tmp;
+   }
+
+   /* change borph debugging level */
+   tmp = create_proc_entry("debug", 0666, p_borph_dir);
+   if (tmp == NULL) {
+       goto partial_mkdbuf;
+   }
+   tmp->owner = THIS_MODULE;
+   tmp->read_proc = proc_dbglvl_read;
+   tmp->write_proc = proc_dbglvl_write;
+   tmp->data = NULL;
+   p_dbg_lvl = tmp;
+
+   /* store BORPH specific version information */
+   p_bversion = create_proc_read_entry("version", 
+                                             0444, p_borph_dir, 
+                                             proc_bversion_read,
+                                             NULL);
+   if (p_bversion == NULL) {
+       goto partial_dbglvl;
+   }
+   p_bversion->owner = THIS_MODULE;
+
+   retval = 0;
+   goto out;
+
+ partial_dbglvl:
+   remove_proc_entry("debug", p_dbg_lvl);
+ partial_mkdbuf:
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       if (p_mkdbuf[i]) 
+           remove_proc_entry(str_mkdbuf[i], p_borph_dir);
+   }
+ partial_empty:
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       if (p_empty[i]) 
+           remove_proc_entry(str_empty[i], p_borph_dir);
+   }
+   remove_proc_entry("allmkdbuf", p_borph_dir);
+ no_allmkdbuf:
+   remove_proc_entry("borph", NULL);
+ out:
+   return retval;
+}
+
+static void __exit proc_mkd_exit(void)
+{
+   int i;
+   remove_proc_entry("debug", p_dbg_lvl);
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       if (p_mkdbuf[i]) 
+           remove_proc_entry(str_mkdbuf[i], p_borph_dir);
+   }
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       if (p_empty[i]) 
+           remove_proc_entry(str_empty[i], p_borph_dir);
+   }
+   remove_proc_entry("allmkdbuf", p_borph_dir);
+   remove_proc_entry("borph", NULL);
+}
+
+static void selectmap_flush(void)
+{
+   int devnum;
+   selectmap_t *dev;
+   uint32_t d, old, mask;
+
+   for (devnum = 0, mask = 0x1UL; devnum < SELECTMAP_NUM_DEVS; devnum++, mask <<= 1) {
+       dev = get_selmapdev(devnum);
+       if (!dev) return;
+
+       /* make sure we won't race with interrupt handler */
+       in_intr_reg(SELMAP_INTR_IPIER, old);
+       out_intr_reg(SELMAP_INTR_IPIER, old & ~mask);
+
+       if (mkd_info->fifo_pending & mask) {
+           selectmap_in_status(dev, d);
+           d = SELECTMAP_RFIFO_CNT(d);
+           if (!selectmap2buf(dev, d)) {
+               mkd_info->selectmap_pending |= mask;
+               mkd_info->fifo_pending &= ~mask;
+           }
+       }
+       out_intr_reg(SELMAP_INTR_IPIER, old);
+
+       put_selmapdev(dev);
+   }
+}
+
+/*
+ * Main mkd thread
+ */
+static int mkd(void *dummy)
+{
+   int irq_result, i;
+   uint32_t d;
+
+        MOD_INC_USE_COUNT;
+
+   /* detach myself from calling process (e.g. insmod) */
+   daemonize();
+   reparent_to_init();
+
+   /* my info */
+        sprintf(current->comm, "mkd");
+
+#if 0
+   /* Block all signals except SIGKILL and SIGSTOP */
+   spin_lock_irq(&current->sigmask_lock);
+   siginitsetinv(&current->blocked, sigmask(SIGKILL) | sigmask(SIGSTOP) );
+   recalc_sigpending(current);
+   spin_unlock_irq(&current->sigmask_lock);
+#endif
+   /* Maybe we want to block everything */
+   sigfillset(&current->blocked);
+
+   /* initialize info about myself */
+   mkd_info = (struct mkd_struct *) kmalloc(sizeof(struct mkd_struct), 
+                        GFP_KERNEL);
+   if (mkd_info == NULL) {
+       printk("mkd: no mem\n");
+       return -ENOMEM;
+   }
+   mkd_info->dbg_lvl = 0;
+   PDEBUG(0, "mkd thread enter...\n");
+
+   /* tell my interrupt handler about myself */
+   mkd_info->selectmap_pending = 0;
+   init_waitqueue_head(&(mkd_info->mkdrdq));
+   for (i = 0; i < SELECTMAP_NUM_DEVS; i++) {
+       init_waitqueue_head(&(mkd_info->bufrdq[i]));
+       init_MUTEX(&(mkd_info->bufrsem[i]));
+   }
+
+   /* allocate buffer for packets */
+   mkd_info->mkd_buf[0] = (unsigned char *)get_free_page(GFP_KERNEL);
+   mkd_info->mkd_buf[1] = mkd_info->mkd_buf[0] + (PAGE_SIZE >> 2);
+   mkd_info->mkd_buf[2] = mkd_info->mkd_buf[1] + (PAGE_SIZE >> 2);
+   mkd_info->mkd_buf[3] = mkd_info->mkd_buf[2] + (PAGE_SIZE >> 2);
+   mkd_info->mkd_bufe[0] = mkd_info->mkd_bufs[0] = mkd_info->mkd_buf[0];
+   mkd_info->mkd_bufe[1] = mkd_info->mkd_bufs[1] = mkd_info->mkd_buf[1];
+   mkd_info->mkd_bufe[2] = mkd_info->mkd_bufs[2] = mkd_info->mkd_buf[2];
+   mkd_info->mkd_bufe[3] = mkd_info->mkd_bufs[3] = mkd_info->mkd_buf[3];
+#if SELECTMAP_NUM_DEVS == 5
+   /* The odd 5th selectmap */
+   mkd_info->mkd_buf[4] = (unsigned char *)get_free_page(GFP_KERNEL);
+   mkd_info->mkd_bufe[4] = mkd_info->mkd_bufs[4] = mkd_info->mkd_buf[4];
+   PDEBUG(9, "mkd_bufs[0 1 2 3 4] @ 0x%p 0x%p 0x%p 0x%p 0x%p\n",
+          mkd_info->mkd_bufs[0], mkd_info->mkd_bufs[1], 
+          mkd_info->mkd_bufs[2], mkd_info->mkd_bufs[3],
+          mkd_info->mkd_bufs[4]);
+#else
+   PDEBUG(9, "mkd_bufs[0 1 2 3] @ 0x%p 0x%p 0x%p 0x%p\n",
+          mkd_info->mkd_bufs[0], mkd_info->mkd_bufs[1], 
+          mkd_info->mkd_bufs[2], mkd_info->mkd_bufs[3]);
+#endif
+
+#ifdef USEINTERRUPT
+   /*
+    * Setup Interrupt
+    */
+   PDEBUG(5, "setup interrupt...\n");
+   /* HHH This seems really odd that selectmap interrupt registers
+    * are mapped here.  It is done so during debugging, when mkd is
+    * compiled as a module and loaded independently.
+    * Once mkd is merged to the main tree (and not modularable), all 
+    * these code should go back to kselectmap.c */
+   mkd_info->intrreg = 
+       ioremap(XPAR_OPB_SELECTMAP_0_BASEADDR+0x100, 64);
+   PDEBUG(5, "ipifreg mapped I/O memory at 0x%p)\n", 
+          mkd_info->intrreg);
+   in_intr_reg(SELMAP_INTR_IPISR, d);
+   PDEBUG(10, "INTR_IPISR = 0x%08X\n", d);
+// out_be32(SELMAP_INTR_DIER, 0x4);   // this line caused MACHINE CHECK
+// PDEBUG(5, "done writing to INTR_DIER\n");
+   irq_result = request_irq(SELECTMAP_IRQ, mkd_interrupt,
+                SA_INTERRUPT, "kselectmap",
+                &mkd_info);
+   if (irq_result) {
+       PDEBUG(0, "can't get irq %i\n", SELECTMAP_IRQ);
+       return -EBUSY;
+   }
+   PDEBUG(10, "Now enable interrupt on the device\n");
+   out_intr_reg(SELMAP_INTR_DGIER, 0x80000000);
+   PDEBUG(10, "done writing to INTR_DGIER\n");
+
+   PDEBUG(5, "setup interrupt...done\n");
+#endif
+
+   // loop forever until we have any signal (SIGKILL | SIGSTOP)
+        for(;;) {
+       /* interrupt for selectmap is not quite working
+        * yet.  For now, I'll do slow polling... */
+#undef DEBUGINTERRUPT /* debugging interrupt */
+#if defined(USEINTERRUPT) && !defined(DEBUGINTERRUPT)
+       wait_event_interruptible((mkd_info->mkdrdq), 
+                    (mkd_info->selectmap_pending != 0));
+       // schedule();
+#else
+       set_current_state(TASK_INTERRUPTIBLE);
+       schedule_timeout(50);  // 1000 is about 1 sec
+#endif /* USEINTERRUPT */
+
+       if (signal_pending(current)) {
+           // we got SIGKILL | SIGSTOP
+           break;
+       }
+
+#if defined(USEINTERRUPT) && !defined(DEBUGINTERRUPT) 
+       handle_selectmap();
+       // to make sure the rest of the system can run
+       schedule_timeout(10);
+       /* It might happen that we have a full mkdbuf when 
+        * user FPGA interrupts me.  In this case, the data are
+        * stuck in the user FPGA FIFO.  But then since it will 
+        * not interrupt us anymore, mkd_interrupt will be not 
+        * called.  Therefore, selectmap_flush is called here, 
+        * which takes the roll of what mkd_interrupt should have done
+        */
+       selectmap_flush();
+#else
+       PDEBUG(10, "interrupt has been called %d times\n", mkd_interrupt_called);
+       d = in_be32(SELMAP_INTR_IPISR);
+       PDEBUG(10, "IPISR = 0x%08x\n", d);
+       d = in_be32(SELMAP_INTR_IPIER);
+       PDEBUG(10, "IPIER = 0x%08x\n", d);
+       d = in_be32(SELMAP_INTR_DGIER);
+       PDEBUG(10, "DGIER = 0x%08x\n", d);
+       poll_selectmap();
+#endif /* USEINTERRUPT */
+   }
+
+#ifdef USEINTERRUPT
+   /*
+    * Release Interrupt
+    */
+   PDEBUG(5, "freeing interrupt...\n");
+   free_irq(SELECTMAP_IRQ, &mkd_info);
+#endif
+
+
+   printk("mkd thread exit\n");
+   free_page((unsigned long) mkd_info->mkd_buf[0]);
+#if SELECTMAP_NUM_DEVS == 5
+   free_page((unsigned long) mkd_info->mkd_buf[4]);
+#endif
+   {
+       /* This is very ugly.  We really should move such important
+        * centralized information out of mkd.  It was originally here
+        * only because I was writing mkd as a module for easy 
+        * development */
+       struct mkd_struct * tmpstruct = mkd_info;
+       mkd_info = NULL;
+       kfree(tmpstruct);
+   }
+
+        MOD_DEC_USE_COUNT;
+        return 0;
+}
+
+
+static __init int mkd_init(void)
+{
+   pphandler_arg_cachep = kmem_cache_create("pphandler_arg", 
+                        sizeof(struct pphandler_arg),
+                        0, 0, NULL, NULL);
+   if (!pphandler_arg_cachep) {
+       return -ENOMEM;
+   }
+   proc_mkd_init();
+   kernel_thread(mkd, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGHAND);
+   return 0;
+}
+
+static __exit void mkd_exit(void)
+{
+   proc_mkd_exit();
+}
+
+/*****************************************************************
+ * Module Information (Use only during debugging
+ *****************************************************************/
+MODULE_AUTHOR("Hayden So");
+MODULE_DESCRIPTION("Main mk thread for BORPH");
+MODULE_LICENSE("GPL");
+#if 0
+/*
+ * module parameters
+ */
+static int debug = 0;  /* set to non-0 set mkif into debug mode */
+static int reset = 0;  /* set to 1 cause mkif to reset mk at load time */
+MODULE_PARM (debug, "i");
+MODULE_PARM (reset, "i");
+#endif
+#define MODULE_NAME "mkd"
+module_init(mkd_init);
+module_exit(mkd_exit);
-- 
1.7.5.4

